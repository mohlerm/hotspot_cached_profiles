<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre></pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 #include "classfile/classLoader.hpp"
  27 #include "classfile/javaClasses.hpp"
  28 #include "classfile/systemDictionary.hpp"
  29 #include "classfile/vmSymbols.hpp"
<a name="1" id="anc1"></a><span class="new">  30 #include "ci/ciCacheProfiles.hpp"</span>
  31 #include "code/codeCache.hpp"
  32 #include "code/codeCacheExtensions.hpp"
  33 #include "code/scopeDesc.hpp"
  34 #include "compiler/compileBroker.hpp"
  35 #include "compiler/compileTask.hpp"
  36 #include "gc/shared/gcId.hpp"
  37 #include "gc/shared/gcLocker.inline.hpp"
  38 #include "gc/shared/workgroup.hpp"
  39 #include "interpreter/interpreter.hpp"
  40 #include "interpreter/linkResolver.hpp"
  41 #include "interpreter/oopMapCache.hpp"
  42 #include "jvmtifiles/jvmtiEnv.hpp"
  43 #include "logging/log.hpp"
  44 #include "logging/logConfiguration.hpp"
  45 #include "memory/metaspaceShared.hpp"
  46 #include "memory/oopFactory.hpp"
  47 #include "memory/universe.inline.hpp"
  48 #include "oops/instanceKlass.hpp"
  49 #include "oops/objArrayOop.hpp"
  50 #include "oops/oop.inline.hpp"
  51 #include "oops/symbol.hpp"
  52 #include "oops/verifyOopClosure.hpp"
  53 #include "prims/jvm_misc.hpp"
  54 #include "prims/jvmtiExport.hpp"
  55 #include "prims/jvmtiThreadState.hpp"
  56 #include "prims/privilegedStack.hpp"
  57 #include "runtime/arguments.hpp"
  58 #include "runtime/atomic.inline.hpp"
  59 #include "runtime/biasedLocking.hpp"
  60 #include "runtime/commandLineFlagConstraintList.hpp"
  61 #include "runtime/commandLineFlagRangeList.hpp"
  62 #include "runtime/deoptimization.hpp"
  63 #include "runtime/fprofiler.hpp"
  64 #include "runtime/frame.inline.hpp"
  65 #include "runtime/globals.hpp"
  66 #include "runtime/init.hpp"
  67 #include "runtime/interfaceSupport.hpp"
  68 #include "runtime/java.hpp"
  69 #include "runtime/javaCalls.hpp"
  70 #include "runtime/jniPeriodicChecker.hpp"
  71 #include "runtime/logTimer.hpp"
  72 #include "runtime/memprofiler.hpp"
  73 #include "runtime/mutexLocker.hpp"
  74 #include "runtime/objectMonitor.hpp"
  75 #include "runtime/orderAccess.inline.hpp"
  76 #include "runtime/osThread.hpp"
  77 #include "runtime/safepoint.hpp"
  78 #include "runtime/sharedRuntime.hpp"
  79 #include "runtime/statSampler.hpp"
  80 #include "runtime/stubRoutines.hpp"
  81 #include "runtime/sweeper.hpp"
  82 #include "runtime/task.hpp"
  83 #include "runtime/thread.inline.hpp"
  84 #include "runtime/threadCritical.hpp"
  85 #include "runtime/vframe.hpp"
  86 #include "runtime/vframeArray.hpp"
  87 #include "runtime/vframe_hp.hpp"
  88 #include "runtime/vmThread.hpp"
  89 #include "runtime/vm_operations.hpp"
  90 #include "runtime/vm_version.hpp"
  91 #include "services/attachListener.hpp"
  92 #include "services/management.hpp"
  93 #include "services/memTracker.hpp"
  94 #include "services/threadService.hpp"
  95 #include "trace/traceMacros.hpp"
  96 #include "trace/tracing.hpp"
  97 #include "utilities/defaultStream.hpp"
  98 #include "utilities/dtrace.hpp"
  99 #include "utilities/events.hpp"
 100 #include "utilities/macros.hpp"
 101 #include "utilities/preserveException.hpp"
 102 #if INCLUDE_ALL_GCS
 103 #include "gc/cms/concurrentMarkSweepThread.hpp"
 104 #include "gc/g1/concurrentMarkThread.inline.hpp"
 105 #include "gc/parallel/pcTasks.hpp"
 106 #endif // INCLUDE_ALL_GCS
 107 #if INCLUDE_JVMCI
 108 #include "jvmci/jvmciCompiler.hpp"
 109 #include "jvmci/jvmciRuntime.hpp"
 110 #endif
 111 #ifdef COMPILER1
 112 #include "c1/c1_Compiler.hpp"
 113 #endif
 114 #ifdef COMPILER2
 115 #include "opto/c2compiler.hpp"
 116 #include "opto/idealGraphPrinter.hpp"
 117 #endif
 118 #if INCLUDE_RTM_OPT
 119 #include "runtime/rtmLocking.hpp"
 120 #endif
 121 
 122 #ifdef DTRACE_ENABLED
 123 
 124 // Only bother with this argument setup if dtrace is available
 125 
 126   #define HOTSPOT_THREAD_PROBE_start HOTSPOT_THREAD_START
 127   #define HOTSPOT_THREAD_PROBE_stop HOTSPOT_THREAD_STOP
 128 
 129   #define DTRACE_THREAD_PROBE(probe, javathread)                           \
 130     {                                                                      \
 131       ResourceMark rm(this);                                               \
 132       int len = 0;                                                         \
 133       const char* name = (javathread)-&gt;get_thread_name();                  \
 134       len = strlen(name);                                                  \
 135       HOTSPOT_THREAD_PROBE_##probe(/* probe = start, stop */               \
 136         (char *) name, len,                                                \
 137         java_lang_Thread::thread_id((javathread)-&gt;threadObj()),            \
 138         (uintptr_t) (javathread)-&gt;osthread()-&gt;thread_id(),                 \
 139         java_lang_Thread::is_daemon((javathread)-&gt;threadObj()));           \
 140     }
 141 
 142 #else //  ndef DTRACE_ENABLED
 143 
 144   #define DTRACE_THREAD_PROBE(probe, javathread)
 145 
 146 #endif // ndef DTRACE_ENABLED
 147 
 148 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 149 // Current thread is maintained as a thread-local variable
 150 THREAD_LOCAL_DECL Thread* Thread::_thr_current = NULL;
 151 #endif
 152 
 153 // Class hierarchy
 154 // - Thread
 155 //   - VMThread
 156 //   - WatcherThread
 157 //   - ConcurrentMarkSweepThread
 158 //   - JavaThread
 159 //     - CompilerThread
 160 
 161 // ======= Thread ========
 162 // Support for forcing alignment of thread objects for biased locking
 163 void* Thread::allocate(size_t size, bool throw_excpt, MEMFLAGS flags) {
 164   if (UseBiasedLocking) {
 165     const int alignment = markOopDesc::biased_lock_alignment;
 166     size_t aligned_size = size + (alignment - sizeof(intptr_t));
 167     void* real_malloc_addr = throw_excpt? AllocateHeap(aligned_size, flags, CURRENT_PC)
 168                                           : AllocateHeap(aligned_size, flags, CURRENT_PC,
 169                                                          AllocFailStrategy::RETURN_NULL);
 170     void* aligned_addr     = (void*) align_size_up((intptr_t) real_malloc_addr, alignment);
 171     assert(((uintptr_t) aligned_addr + (uintptr_t) size) &lt;=
 172            ((uintptr_t) real_malloc_addr + (uintptr_t) aligned_size),
 173            "JavaThread alignment code overflowed allocated storage");
 174     if (aligned_addr != real_malloc_addr) {
 175       log_info(biasedlocking)("Aligned thread " INTPTR_FORMAT " to " INTPTR_FORMAT,
 176                               p2i(real_malloc_addr),
 177                               p2i(aligned_addr));
 178     }
 179     ((Thread*) aligned_addr)-&gt;_real_malloc_address = real_malloc_addr;
 180     return aligned_addr;
 181   } else {
 182     return throw_excpt? AllocateHeap(size, flags, CURRENT_PC)
 183                        : AllocateHeap(size, flags, CURRENT_PC, AllocFailStrategy::RETURN_NULL);
 184   }
 185 }
 186 
 187 void Thread::operator delete(void* p) {
 188   if (UseBiasedLocking) {
 189     void* real_malloc_addr = ((Thread*) p)-&gt;_real_malloc_address;
 190     FreeHeap(real_malloc_addr);
 191   } else {
 192     FreeHeap(p);
 193   }
 194 }
 195 
 196 
 197 // Base class for all threads: VMThread, WatcherThread, ConcurrentMarkSweepThread,
 198 // JavaThread
 199 
 200 
 201 Thread::Thread() {
 202   // stack and get_thread
 203   set_stack_base(NULL);
 204   set_stack_size(0);
 205   set_self_raw_id(0);
 206   set_lgrp_id(-1);
 207   DEBUG_ONLY(clear_suspendible_thread();)
 208 
 209   // allocated data structures
 210   set_osthread(NULL);
 211   set_resource_area(new (mtThread)ResourceArea());
 212   DEBUG_ONLY(_current_resource_mark = NULL;)
 213   set_handle_area(new (mtThread) HandleArea(NULL));
 214   set_metadata_handles(new (ResourceObj::C_HEAP, mtClass) GrowableArray&lt;Metadata*&gt;(30, true));
 215   set_active_handles(NULL);
 216   set_free_handle_block(NULL);
 217   set_last_handle_mark(NULL);
 218 
 219   // This initial value ==&gt; never claimed.
 220   _oops_do_parity = 0;
 221 
 222   // the handle mark links itself to last_handle_mark
 223   new HandleMark(this);
 224 
 225   // plain initialization
 226   debug_only(_owned_locks = NULL;)
 227   debug_only(_allow_allocation_count = 0;)
 228   NOT_PRODUCT(_allow_safepoint_count = 0;)
 229   NOT_PRODUCT(_skip_gcalot = false;)
 230   _jvmti_env_iteration_count = 0;
 231   set_allocated_bytes(0);
 232   _vm_operation_started_count = 0;
 233   _vm_operation_completed_count = 0;
 234   _current_pending_monitor = NULL;
 235   _current_pending_monitor_is_from_java = true;
 236   _current_waiting_monitor = NULL;
 237   _num_nested_signal = 0;
 238   omFreeList = NULL;
 239   omFreeCount = 0;
 240   omFreeProvision = 32;
 241   omInUseList = NULL;
 242   omInUseCount = 0;
 243 
 244 #ifdef ASSERT
 245   _visited_for_critical_count = false;
 246 #endif
 247 
 248   _SR_lock = new Monitor(Mutex::suspend_resume, "SR_lock", true,
 249                          Monitor::_safepoint_check_sometimes);
 250   _suspend_flags = 0;
 251 
 252   // thread-specific hashCode stream generator state - Marsaglia shift-xor form
 253   _hashStateX = os::random();
 254   _hashStateY = 842502087;
 255   _hashStateZ = 0x8767;    // (int)(3579807591LL &amp; 0xffff) ;
 256   _hashStateW = 273326509;
 257 
 258   _OnTrap   = 0;
 259   _schedctl = NULL;
 260   _Stalled  = 0;
 261   _TypeTag  = 0x2BAD;
 262 
 263   // Many of the following fields are effectively final - immutable
 264   // Note that nascent threads can't use the Native Monitor-Mutex
 265   // construct until the _MutexEvent is initialized ...
 266   // CONSIDER: instead of using a fixed set of purpose-dedicated ParkEvents
 267   // we might instead use a stack of ParkEvents that we could provision on-demand.
 268   // The stack would act as a cache to avoid calls to ParkEvent::Allocate()
 269   // and ::Release()
 270   _ParkEvent   = ParkEvent::Allocate(this);
 271   _SleepEvent  = ParkEvent::Allocate(this);
 272   _MutexEvent  = ParkEvent::Allocate(this);
 273   _MuxEvent    = ParkEvent::Allocate(this);
 274 
 275 #ifdef CHECK_UNHANDLED_OOPS
 276   if (CheckUnhandledOops) {
 277     _unhandled_oops = new UnhandledOops(this);
 278   }
 279 #endif // CHECK_UNHANDLED_OOPS
 280 #ifdef ASSERT
 281   if (UseBiasedLocking) {
 282     assert((((uintptr_t) this) &amp; (markOopDesc::biased_lock_alignment - 1)) == 0, "forced alignment of thread object failed");
 283     assert(this == _real_malloc_address ||
 284            this == (void*) align_size_up((intptr_t) _real_malloc_address, markOopDesc::biased_lock_alignment),
 285            "bug in forced alignment of thread objects");
 286   }
 287 #endif // ASSERT
 288 }
 289 
 290 void Thread::initialize_thread_current() {
 291 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 292   assert(_thr_current == NULL, "Thread::current already initialized");
 293   _thr_current = this;
 294 #endif
 295   assert(ThreadLocalStorage::thread() == NULL, "ThreadLocalStorage::thread already initialized");
 296   ThreadLocalStorage::set_thread(this);
 297   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 298 }
 299 
 300 void Thread::clear_thread_current() {
 301   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 302 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 303   _thr_current = NULL;
 304 #endif
 305   ThreadLocalStorage::set_thread(NULL);
 306 }
 307 
 308 void Thread::record_stack_base_and_size() {
 309   set_stack_base(os::current_stack_base());
 310   set_stack_size(os::current_stack_size());
 311   // CR 7190089: on Solaris, primordial thread's stack is adjusted
 312   // in initialize_thread(). Without the adjustment, stack size is
 313   // incorrect if stack is set to unlimited (ulimit -s unlimited).
 314   // So far, only Solaris has real implementation of initialize_thread().
 315   //
 316   // set up any platform-specific state.
 317   os::initialize_thread(this);
 318 
 319   // Set stack limits after thread is initialized.
 320   if (is_Java_thread()) {
 321     ((JavaThread*) this)-&gt;set_stack_overflow_limit();
 322     ((JavaThread*) this)-&gt;set_reserved_stack_activation(stack_base());
 323   }
 324 #if INCLUDE_NMT
 325   // record thread's native stack, stack grows downward
 326   MemTracker::record_thread_stack(stack_end(), stack_size());
 327 #endif // INCLUDE_NMT
 328   log_debug(os, thread)("Thread " UINTX_FORMAT " stack dimensions: "
 329     PTR_FORMAT "-" PTR_FORMAT " (" SIZE_FORMAT "k).",
 330     os::current_thread_id(), p2i(stack_base() - stack_size()),
 331     p2i(stack_base()), stack_size()/1024);
 332 }
 333 
 334 
 335 Thread::~Thread() {
 336   // Reclaim the objectmonitors from the omFreeList of the moribund thread.
 337   ObjectSynchronizer::omFlush(this);
 338 
 339   EVENT_THREAD_DESTRUCT(this);
 340 
 341   // stack_base can be NULL if the thread is never started or exited before
 342   // record_stack_base_and_size called. Although, we would like to ensure
 343   // that all started threads do call record_stack_base_and_size(), there is
 344   // not proper way to enforce that.
 345 #if INCLUDE_NMT
 346   if (_stack_base != NULL) {
 347     MemTracker::release_thread_stack(stack_end(), stack_size());
 348 #ifdef ASSERT
 349     set_stack_base(NULL);
 350 #endif
 351   }
 352 #endif // INCLUDE_NMT
 353 
 354   // deallocate data structures
 355   delete resource_area();
 356   // since the handle marks are using the handle area, we have to deallocated the root
 357   // handle mark before deallocating the thread's handle area,
 358   assert(last_handle_mark() != NULL, "check we have an element");
 359   delete last_handle_mark();
 360   assert(last_handle_mark() == NULL, "check we have reached the end");
 361 
 362   // It's possible we can encounter a null _ParkEvent, etc., in stillborn threads.
 363   // We NULL out the fields for good hygiene.
 364   ParkEvent::Release(_ParkEvent); _ParkEvent   = NULL;
 365   ParkEvent::Release(_SleepEvent); _SleepEvent  = NULL;
 366   ParkEvent::Release(_MutexEvent); _MutexEvent  = NULL;
 367   ParkEvent::Release(_MuxEvent); _MuxEvent    = NULL;
 368 
 369   delete handle_area();
 370   delete metadata_handles();
 371 
 372   // osthread() can be NULL, if creation of thread failed.
 373   if (osthread() != NULL) os::free_thread(osthread());
 374 
 375   delete _SR_lock;
 376 
 377   // clear Thread::current if thread is deleting itself.
 378   // Needed to ensure JNI correctly detects non-attached threads.
 379   if (this == Thread::current()) {
 380     clear_thread_current();
 381   }
 382 
 383   CHECK_UNHANDLED_OOPS_ONLY(if (CheckUnhandledOops) delete unhandled_oops();)
 384 }
 385 
 386 // NOTE: dummy function for assertion purpose.
 387 void Thread::run() {
 388   ShouldNotReachHere();
 389 }
 390 
 391 #ifdef ASSERT
 392 // Private method to check for dangling thread pointer
 393 void check_for_dangling_thread_pointer(Thread *thread) {
 394   assert(!thread-&gt;is_Java_thread() || Thread::current() == thread || Threads_lock-&gt;owned_by_self(),
 395          "possibility of dangling Thread pointer");
 396 }
 397 #endif
 398 
 399 ThreadPriority Thread::get_priority(const Thread* const thread) {
 400   ThreadPriority priority;
 401   // Can return an error!
 402   (void)os::get_priority(thread, priority);
 403   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "non-Java priority found");
 404   return priority;
 405 }
 406 
 407 void Thread::set_priority(Thread* thread, ThreadPriority priority) {
 408   debug_only(check_for_dangling_thread_pointer(thread);)
 409   // Can return an error!
 410   (void)os::set_priority(thread, priority);
 411 }
 412 
 413 
 414 void Thread::start(Thread* thread) {
 415   // Start is different from resume in that its safety is guaranteed by context or
 416   // being called from a Java method synchronized on the Thread object.
 417   if (!DisableStartThread) {
 418     if (thread-&gt;is_Java_thread()) {
 419       // Initialize the thread state to RUNNABLE before starting this thread.
 420       // Can not set it after the thread started because we do not know the
 421       // exact thread state at that time. It could be in MONITOR_WAIT or
 422       // in SLEEPING or some other state.
 423       java_lang_Thread::set_thread_status(((JavaThread*)thread)-&gt;threadObj(),
 424                                           java_lang_Thread::RUNNABLE);
 425     }
 426     os::start_thread(thread);
 427   }
 428 }
 429 
 430 // Enqueue a VM_Operation to do the job for us - sometime later
 431 void Thread::send_async_exception(oop java_thread, oop java_throwable) {
 432   VM_ThreadStop* vm_stop = new VM_ThreadStop(java_thread, java_throwable);
 433   VMThread::execute(vm_stop);
 434 }
 435 
 436 
 437 // Check if an external suspend request has completed (or has been
 438 // cancelled). Returns true if the thread is externally suspended and
 439 // false otherwise.
 440 //
 441 // The bits parameter returns information about the code path through
 442 // the routine. Useful for debugging:
 443 //
 444 // set in is_ext_suspend_completed():
 445 // 0x00000001 - routine was entered
 446 // 0x00000010 - routine return false at end
 447 // 0x00000100 - thread exited (return false)
 448 // 0x00000200 - suspend request cancelled (return false)
 449 // 0x00000400 - thread suspended (return true)
 450 // 0x00001000 - thread is in a suspend equivalent state (return true)
 451 // 0x00002000 - thread is native and walkable (return true)
 452 // 0x00004000 - thread is native_trans and walkable (needed retry)
 453 //
 454 // set in wait_for_ext_suspend_completion():
 455 // 0x00010000 - routine was entered
 456 // 0x00020000 - suspend request cancelled before loop (return false)
 457 // 0x00040000 - thread suspended before loop (return true)
 458 // 0x00080000 - suspend request cancelled in loop (return false)
 459 // 0x00100000 - thread suspended in loop (return true)
 460 // 0x00200000 - suspend not completed during retry loop (return false)
 461 
 462 // Helper class for tracing suspend wait debug bits.
 463 //
 464 // 0x00000100 indicates that the target thread exited before it could
 465 // self-suspend which is not a wait failure. 0x00000200, 0x00020000 and
 466 // 0x00080000 each indicate a cancelled suspend request so they don't
 467 // count as wait failures either.
 468 #define DEBUG_FALSE_BITS (0x00000010 | 0x00200000)
 469 
 470 class TraceSuspendDebugBits : public StackObj {
 471  private:
 472   JavaThread * jt;
 473   bool         is_wait;
 474   bool         called_by_wait;  // meaningful when !is_wait
 475   uint32_t *   bits;
 476 
 477  public:
 478   TraceSuspendDebugBits(JavaThread *_jt, bool _is_wait, bool _called_by_wait,
 479                         uint32_t *_bits) {
 480     jt             = _jt;
 481     is_wait        = _is_wait;
 482     called_by_wait = _called_by_wait;
 483     bits           = _bits;
 484   }
 485 
 486   ~TraceSuspendDebugBits() {
 487     if (!is_wait) {
 488 #if 1
 489       // By default, don't trace bits for is_ext_suspend_completed() calls.
 490       // That trace is very chatty.
 491       return;
 492 #else
 493       if (!called_by_wait) {
 494         // If tracing for is_ext_suspend_completed() is enabled, then only
 495         // trace calls to it from wait_for_ext_suspend_completion()
 496         return;
 497       }
 498 #endif
 499     }
 500 
 501     if (AssertOnSuspendWaitFailure || TraceSuspendWaitFailures) {
 502       if (bits != NULL &amp;&amp; (*bits &amp; DEBUG_FALSE_BITS) != 0) {
 503         MutexLocker ml(Threads_lock);  // needed for get_thread_name()
 504         ResourceMark rm;
 505 
 506         tty-&gt;print_cr(
 507                       "Failed wait_for_ext_suspend_completion(thread=%s, debug_bits=%x)",
 508                       jt-&gt;get_thread_name(), *bits);
 509 
 510         guarantee(!AssertOnSuspendWaitFailure, "external suspend wait failed");
 511       }
 512     }
 513   }
 514 };
 515 #undef DEBUG_FALSE_BITS
 516 
 517 
 518 bool JavaThread::is_ext_suspend_completed(bool called_by_wait, int delay,
 519                                           uint32_t *bits) {
 520   TraceSuspendDebugBits tsdb(this, false /* !is_wait */, called_by_wait, bits);
 521 
 522   bool did_trans_retry = false;  // only do thread_in_native_trans retry once
 523   bool do_trans_retry;           // flag to force the retry
 524 
 525   *bits |= 0x00000001;
 526 
 527   do {
 528     do_trans_retry = false;
 529 
 530     if (is_exiting()) {
 531       // Thread is in the process of exiting. This is always checked
 532       // first to reduce the risk of dereferencing a freed JavaThread.
 533       *bits |= 0x00000100;
 534       return false;
 535     }
 536 
 537     if (!is_external_suspend()) {
 538       // Suspend request is cancelled. This is always checked before
 539       // is_ext_suspended() to reduce the risk of a rogue resume
 540       // confusing the thread that made the suspend request.
 541       *bits |= 0x00000200;
 542       return false;
 543     }
 544 
 545     if (is_ext_suspended()) {
 546       // thread is suspended
 547       *bits |= 0x00000400;
 548       return true;
 549     }
 550 
 551     // Now that we no longer do hard suspends of threads running
 552     // native code, the target thread can be changing thread state
 553     // while we are in this routine:
 554     //
 555     //   _thread_in_native -&gt; _thread_in_native_trans -&gt; _thread_blocked
 556     //
 557     // We save a copy of the thread state as observed at this moment
 558     // and make our decision about suspend completeness based on the
 559     // copy. This closes the race where the thread state is seen as
 560     // _thread_in_native_trans in the if-thread_blocked check, but is
 561     // seen as _thread_blocked in if-thread_in_native_trans check.
 562     JavaThreadState save_state = thread_state();
 563 
 564     if (save_state == _thread_blocked &amp;&amp; is_suspend_equivalent()) {
 565       // If the thread's state is _thread_blocked and this blocking
 566       // condition is known to be equivalent to a suspend, then we can
 567       // consider the thread to be externally suspended. This means that
 568       // the code that sets _thread_blocked has been modified to do
 569       // self-suspension if the blocking condition releases. We also
 570       // used to check for CONDVAR_WAIT here, but that is now covered by
 571       // the _thread_blocked with self-suspension check.
 572       //
 573       // Return true since we wouldn't be here unless there was still an
 574       // external suspend request.
 575       *bits |= 0x00001000;
 576       return true;
 577     } else if (save_state == _thread_in_native &amp;&amp; frame_anchor()-&gt;walkable()) {
 578       // Threads running native code will self-suspend on native==&gt;VM/Java
 579       // transitions. If its stack is walkable (should always be the case
 580       // unless this function is called before the actual java_suspend()
 581       // call), then the wait is done.
 582       *bits |= 0x00002000;
 583       return true;
 584     } else if (!called_by_wait &amp;&amp; !did_trans_retry &amp;&amp;
 585                save_state == _thread_in_native_trans &amp;&amp;
 586                frame_anchor()-&gt;walkable()) {
 587       // The thread is transitioning from thread_in_native to another
 588       // thread state. check_safepoint_and_suspend_for_native_trans()
 589       // will force the thread to self-suspend. If it hasn't gotten
 590       // there yet we may have caught the thread in-between the native
 591       // code check above and the self-suspend. Lucky us. If we were
 592       // called by wait_for_ext_suspend_completion(), then it
 593       // will be doing the retries so we don't have to.
 594       //
 595       // Since we use the saved thread state in the if-statement above,
 596       // there is a chance that the thread has already transitioned to
 597       // _thread_blocked by the time we get here. In that case, we will
 598       // make a single unnecessary pass through the logic below. This
 599       // doesn't hurt anything since we still do the trans retry.
 600 
 601       *bits |= 0x00004000;
 602 
 603       // Once the thread leaves thread_in_native_trans for another
 604       // thread state, we break out of this retry loop. We shouldn't
 605       // need this flag to prevent us from getting back here, but
 606       // sometimes paranoia is good.
 607       did_trans_retry = true;
 608 
 609       // We wait for the thread to transition to a more usable state.
 610       for (int i = 1; i &lt;= SuspendRetryCount; i++) {
 611         // We used to do an "os::yield_all(i)" call here with the intention
 612         // that yielding would increase on each retry. However, the parameter
 613         // is ignored on Linux which means the yield didn't scale up. Waiting
 614         // on the SR_lock below provides a much more predictable scale up for
 615         // the delay. It also provides a simple/direct point to check for any
 616         // safepoint requests from the VMThread
 617 
 618         // temporarily drops SR_lock while doing wait with safepoint check
 619         // (if we're a JavaThread - the WatcherThread can also call this)
 620         // and increase delay with each retry
 621         SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 622 
 623         // check the actual thread state instead of what we saved above
 624         if (thread_state() != _thread_in_native_trans) {
 625           // the thread has transitioned to another thread state so
 626           // try all the checks (except this one) one more time.
 627           do_trans_retry = true;
 628           break;
 629         }
 630       } // end retry loop
 631 
 632 
 633     }
 634   } while (do_trans_retry);
 635 
 636   *bits |= 0x00000010;
 637   return false;
 638 }
 639 
 640 // Wait for an external suspend request to complete (or be cancelled).
 641 // Returns true if the thread is externally suspended and false otherwise.
 642 //
 643 bool JavaThread::wait_for_ext_suspend_completion(int retries, int delay,
 644                                                  uint32_t *bits) {
 645   TraceSuspendDebugBits tsdb(this, true /* is_wait */,
 646                              false /* !called_by_wait */, bits);
 647 
 648   // local flag copies to minimize SR_lock hold time
 649   bool is_suspended;
 650   bool pending;
 651   uint32_t reset_bits;
 652 
 653   // set a marker so is_ext_suspend_completed() knows we are the caller
 654   *bits |= 0x00010000;
 655 
 656   // We use reset_bits to reinitialize the bits value at the top of
 657   // each retry loop. This allows the caller to make use of any
 658   // unused bits for their own marking purposes.
 659   reset_bits = *bits;
 660 
 661   {
 662     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
 663     is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 664                                             delay, bits);
 665     pending = is_external_suspend();
 666   }
 667   // must release SR_lock to allow suspension to complete
 668 
 669   if (!pending) {
 670     // A cancelled suspend request is the only false return from
 671     // is_ext_suspend_completed() that keeps us from entering the
 672     // retry loop.
 673     *bits |= 0x00020000;
 674     return false;
 675   }
 676 
 677   if (is_suspended) {
 678     *bits |= 0x00040000;
 679     return true;
 680   }
 681 
 682   for (int i = 1; i &lt;= retries; i++) {
 683     *bits = reset_bits;  // reinit to only track last retry
 684 
 685     // We used to do an "os::yield_all(i)" call here with the intention
 686     // that yielding would increase on each retry. However, the parameter
 687     // is ignored on Linux which means the yield didn't scale up. Waiting
 688     // on the SR_lock below provides a much more predictable scale up for
 689     // the delay. It also provides a simple/direct point to check for any
 690     // safepoint requests from the VMThread
 691 
 692     {
 693       MutexLocker ml(SR_lock());
 694       // wait with safepoint check (if we're a JavaThread - the WatcherThread
 695       // can also call this)  and increase delay with each retry
 696       SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 697 
 698       is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 699                                               delay, bits);
 700 
 701       // It is possible for the external suspend request to be cancelled
 702       // (by a resume) before the actual suspend operation is completed.
 703       // Refresh our local copy to see if we still need to wait.
 704       pending = is_external_suspend();
 705     }
 706 
 707     if (!pending) {
 708       // A cancelled suspend request is the only false return from
 709       // is_ext_suspend_completed() that keeps us from staying in the
 710       // retry loop.
 711       *bits |= 0x00080000;
 712       return false;
 713     }
 714 
 715     if (is_suspended) {
 716       *bits |= 0x00100000;
 717       return true;
 718     }
 719   } // end retry loop
 720 
 721   // thread did not suspend after all our retries
 722   *bits |= 0x00200000;
 723   return false;
 724 }
 725 
 726 #ifndef PRODUCT
 727 void JavaThread::record_jump(address target, address instr, const char* file,
 728                              int line) {
 729 
 730   // This should not need to be atomic as the only way for simultaneous
 731   // updates is via interrupts. Even then this should be rare or non-existent
 732   // and we don't care that much anyway.
 733 
 734   int index = _jmp_ring_index;
 735   _jmp_ring_index = (index + 1) &amp; (jump_ring_buffer_size - 1);
 736   _jmp_ring[index]._target = (intptr_t) target;
 737   _jmp_ring[index]._instruction = (intptr_t) instr;
 738   _jmp_ring[index]._file = file;
 739   _jmp_ring[index]._line = line;
 740 }
 741 #endif // PRODUCT
 742 
 743 // Called by flat profiler
 744 // Callers have already called wait_for_ext_suspend_completion
 745 // The assertion for that is currently too complex to put here:
 746 bool JavaThread::profile_last_Java_frame(frame* _fr) {
 747   bool gotframe = false;
 748   // self suspension saves needed state.
 749   if (has_last_Java_frame() &amp;&amp; _anchor.walkable()) {
 750     *_fr = pd_last_frame();
 751     gotframe = true;
 752   }
 753   return gotframe;
 754 }
 755 
 756 void Thread::interrupt(Thread* thread) {
 757   debug_only(check_for_dangling_thread_pointer(thread);)
 758   os::interrupt(thread);
 759 }
 760 
 761 bool Thread::is_interrupted(Thread* thread, bool clear_interrupted) {
 762   debug_only(check_for_dangling_thread_pointer(thread);)
 763   // Note:  If clear_interrupted==false, this simply fetches and
 764   // returns the value of the field osthread()-&gt;interrupted().
 765   return os::is_interrupted(thread, clear_interrupted);
 766 }
 767 
 768 
 769 // GC Support
 770 bool Thread::claim_oops_do_par_case(int strong_roots_parity) {
 771   jint thread_parity = _oops_do_parity;
 772   if (thread_parity != strong_roots_parity) {
 773     jint res = Atomic::cmpxchg(strong_roots_parity, &amp;_oops_do_parity, thread_parity);
 774     if (res == thread_parity) {
 775       return true;
 776     } else {
 777       guarantee(res == strong_roots_parity, "Or else what?");
 778       return false;
 779     }
 780   }
 781   return false;
 782 }
 783 
 784 void Thread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
 785   active_handles()-&gt;oops_do(f);
 786   // Do oop for ThreadShadow
 787   f-&gt;do_oop((oop*)&amp;_pending_exception);
 788   handle_area()-&gt;oops_do(f);
 789 }
 790 
 791 void Thread::nmethods_do(CodeBlobClosure* cf) {
 792   // no nmethods in a generic thread...
 793 }
 794 
 795 void Thread::metadata_handles_do(void f(Metadata*)) {
 796   // Only walk the Handles in Thread.
 797   if (metadata_handles() != NULL) {
 798     for (int i = 0; i&lt; metadata_handles()-&gt;length(); i++) {
 799       f(metadata_handles()-&gt;at(i));
 800     }
 801   }
 802 }
 803 
 804 void Thread::print_on(outputStream* st) const {
 805   // get_priority assumes osthread initialized
 806   if (osthread() != NULL) {
 807     int os_prio;
 808     if (os::get_native_priority(this, &amp;os_prio) == OS_OK) {
 809       st-&gt;print("os_prio=%d ", os_prio);
 810     }
 811     st-&gt;print("tid=" INTPTR_FORMAT " ", p2i(this));
 812     ext().print_on(st);
 813     osthread()-&gt;print_on(st);
 814   }
 815   debug_only(if (WizardMode) print_owned_locks_on(st);)
 816 }
 817 
 818 // Thread::print_on_error() is called by fatal error handler. Don't use
 819 // any lock or allocate memory.
 820 void Thread::print_on_error(outputStream* st, char* buf, int buflen) const {
 821   if (is_VM_thread())                 st-&gt;print("VMThread");
 822   else if (is_Compiler_thread())      st-&gt;print("CompilerThread");
 823   else if (is_Java_thread())          st-&gt;print("JavaThread");
 824   else if (is_GC_task_thread())       st-&gt;print("GCTaskThread");
 825   else if (is_Watcher_thread())       st-&gt;print("WatcherThread");
 826   else if (is_ConcurrentGC_thread())  st-&gt;print("ConcurrentGCThread");
 827   else                                st-&gt;print("Thread");
 828 
 829   st-&gt;print(" [stack: " PTR_FORMAT "," PTR_FORMAT "]",
 830             p2i(stack_end()), p2i(stack_base()));
 831 
 832   if (osthread()) {
 833     st-&gt;print(" [id=%d]", osthread()-&gt;thread_id());
 834   }
 835 }
 836 
 837 #ifdef ASSERT
 838 void Thread::print_owned_locks_on(outputStream* st) const {
 839   Monitor *cur = _owned_locks;
 840   if (cur == NULL) {
 841     st-&gt;print(" (no locks) ");
 842   } else {
 843     st-&gt;print_cr(" Locks owned:");
 844     while (cur) {
 845       cur-&gt;print_on(st);
 846       cur = cur-&gt;next();
 847     }
 848   }
 849 }
 850 
 851 static int ref_use_count  = 0;
 852 
 853 bool Thread::owns_locks_but_compiled_lock() const {
 854   for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 855     if (cur != Compile_lock) return true;
 856   }
 857   return false;
 858 }
 859 
 860 
 861 #endif
 862 
 863 #ifndef PRODUCT
 864 
 865 // The flag: potential_vm_operation notifies if this particular safepoint state could potential
 866 // invoke the vm-thread (i.e., and oop allocation). In that case, we also have to make sure that
 867 // no threads which allow_vm_block's are held
 868 void Thread::check_for_valid_safepoint_state(bool potential_vm_operation) {
 869   // Check if current thread is allowed to block at a safepoint
 870   if (!(_allow_safepoint_count == 0)) {
 871     fatal("Possible safepoint reached by thread that does not allow it");
 872   }
 873   if (is_Java_thread() &amp;&amp; ((JavaThread*)this)-&gt;thread_state() != _thread_in_vm) {
 874     fatal("LEAF method calling lock?");
 875   }
 876 
 877 #ifdef ASSERT
 878   if (potential_vm_operation &amp;&amp; is_Java_thread()
 879       &amp;&amp; !Universe::is_bootstrapping()) {
 880     // Make sure we do not hold any locks that the VM thread also uses.
 881     // This could potentially lead to deadlocks
 882     for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 883       // Threads_lock is special, since the safepoint synchronization will not start before this is
 884       // acquired. Hence, a JavaThread cannot be holding it at a safepoint. So is VMOperationRequest_lock,
 885       // since it is used to transfer control between JavaThreads and the VMThread
 886       // Do not *exclude* any locks unless you are absolutely sure it is correct. Ask someone else first!
 887       if ((cur-&gt;allow_vm_block() &amp;&amp;
 888            cur != Threads_lock &amp;&amp;
 889            cur != Compile_lock &amp;&amp;               // Temporary: should not be necessary when we get separate compilation
 890            cur != VMOperationRequest_lock &amp;&amp;
 891            cur != VMOperationQueue_lock) ||
 892            cur-&gt;rank() == Mutex::special) {
 893         fatal("Thread holding lock at safepoint that vm can block on: %s", cur-&gt;name());
 894       }
 895     }
 896   }
 897 
 898   if (GCALotAtAllSafepoints) {
 899     // We could enter a safepoint here and thus have a gc
 900     InterfaceSupport::check_gc_alot();
 901   }
 902 #endif
 903 }
 904 #endif
 905 
 906 bool Thread::is_in_stack(address adr) const {
 907   assert(Thread::current() == this, "is_in_stack can only be called from current thread");
 908   address end = os::current_stack_pointer();
 909   // Allow non Java threads to call this without stack_base
 910   if (_stack_base == NULL) return true;
 911   if (stack_base() &gt;= adr &amp;&amp; adr &gt;= end) return true;
 912 
 913   return false;
 914 }
 915 
 916 bool Thread::is_in_usable_stack(address adr) const {
 917   size_t stack_guard_size = os::uses_stack_guard_pages() ? JavaThread::stack_guard_zone_size() : 0;
 918   size_t usable_stack_size = _stack_size - stack_guard_size;
 919 
 920   return ((adr &lt; stack_base()) &amp;&amp; (adr &gt;= stack_base() - usable_stack_size));
 921 }
 922 
 923 
 924 // We had to move these methods here, because vm threads get into ObjectSynchronizer::enter
 925 // However, there is a note in JavaThread::is_lock_owned() about the VM threads not being
 926 // used for compilation in the future. If that change is made, the need for these methods
 927 // should be revisited, and they should be removed if possible.
 928 
 929 bool Thread::is_lock_owned(address adr) const {
 930   return on_local_stack(adr);
 931 }
 932 
 933 bool Thread::set_as_starting_thread() {
 934   // NOTE: this must be called inside the main thread.
 935   return os::create_main_thread((JavaThread*)this);
 936 }
 937 
 938 static void initialize_class(Symbol* class_name, TRAPS) {
 939   Klass* klass = SystemDictionary::resolve_or_fail(class_name, true, CHECK);
 940   InstanceKlass::cast(klass)-&gt;initialize(CHECK);
 941 }
 942 
 943 
 944 // Creates the initial ThreadGroup
 945 static Handle create_initial_thread_group(TRAPS) {
 946   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_ThreadGroup(), true, CHECK_NH);
 947   instanceKlassHandle klass (THREAD, k);
 948 
 949   Handle system_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 950   {
 951     JavaValue result(T_VOID);
 952     JavaCalls::call_special(&amp;result,
 953                             system_instance,
 954                             klass,
 955                             vmSymbols::object_initializer_name(),
 956                             vmSymbols::void_method_signature(),
 957                             CHECK_NH);
 958   }
 959   Universe::set_system_thread_group(system_instance());
 960 
 961   Handle main_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 962   {
 963     JavaValue result(T_VOID);
 964     Handle string = java_lang_String::create_from_str("main", CHECK_NH);
 965     JavaCalls::call_special(&amp;result,
 966                             main_instance,
 967                             klass,
 968                             vmSymbols::object_initializer_name(),
 969                             vmSymbols::threadgroup_string_void_signature(),
 970                             system_instance,
 971                             string,
 972                             CHECK_NH);
 973   }
 974   return main_instance;
 975 }
 976 
 977 // Creates the initial Thread
 978 static oop create_initial_thread(Handle thread_group, JavaThread* thread,
 979                                  TRAPS) {
 980   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK_NULL);
 981   instanceKlassHandle klass (THREAD, k);
 982   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK_NULL);
 983 
 984   java_lang_Thread::set_thread(thread_oop(), thread);
 985   java_lang_Thread::set_priority(thread_oop(), NormPriority);
 986   thread-&gt;set_threadObj(thread_oop());
 987 
 988   Handle string = java_lang_String::create_from_str("main", CHECK_NULL);
 989 
 990   JavaValue result(T_VOID);
 991   JavaCalls::call_special(&amp;result, thread_oop,
 992                           klass,
 993                           vmSymbols::object_initializer_name(),
 994                           vmSymbols::threadgroup_string_void_signature(),
 995                           thread_group,
 996                           string,
 997                           CHECK_NULL);
 998   return thread_oop();
 999 }
1000 
1001 static void call_initializeSystemClass(TRAPS) {
1002   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
1003   instanceKlassHandle klass (THREAD, k);
1004 
1005   JavaValue result(T_VOID);
1006   JavaCalls::call_static(&amp;result, klass, vmSymbols::initializeSystemClass_name(),
1007                          vmSymbols::void_method_signature(), CHECK);
1008 }
1009 
1010 char java_runtime_name[128] = "";
1011 char java_runtime_version[128] = "";
1012 
1013 // extract the JRE name from java.lang.VersionProps.java_runtime_name
1014 static const char* get_java_runtime_name(TRAPS) {
1015   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1016                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1017   fieldDescriptor fd;
1018   bool found = k != NULL &amp;&amp;
1019                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_name_name(),
1020                                                         vmSymbols::string_signature(), &amp;fd);
1021   if (found) {
1022     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1023     if (name_oop == NULL) {
1024       return NULL;
1025     }
1026     const char* name = java_lang_String::as_utf8_string(name_oop,
1027                                                         java_runtime_name,
1028                                                         sizeof(java_runtime_name));
1029     return name;
1030   } else {
1031     return NULL;
1032   }
1033 }
1034 
1035 // extract the JRE version from java.lang.VersionProps.java_runtime_version
1036 static const char* get_java_runtime_version(TRAPS) {
1037   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1038                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1039   fieldDescriptor fd;
1040   bool found = k != NULL &amp;&amp;
1041                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_version_name(),
1042                                                         vmSymbols::string_signature(), &amp;fd);
1043   if (found) {
1044     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1045     if (name_oop == NULL) {
1046       return NULL;
1047     }
1048     const char* name = java_lang_String::as_utf8_string(name_oop,
1049                                                         java_runtime_version,
1050                                                         sizeof(java_runtime_version));
1051     return name;
1052   } else {
1053     return NULL;
1054   }
1055 }
1056 
1057 // General purpose hook into Java code, run once when the VM is initialized.
1058 // The Java library method itself may be changed independently from the VM.
1059 static void call_postVMInitHook(TRAPS) {
1060   Klass* k = SystemDictionary::resolve_or_null(vmSymbols::sun_misc_PostVMInitHook(), THREAD);
1061   instanceKlassHandle klass (THREAD, k);
1062   if (klass.not_null()) {
1063     JavaValue result(T_VOID);
1064     JavaCalls::call_static(&amp;result, klass, vmSymbols::run_method_name(),
1065                            vmSymbols::void_method_signature(),
1066                            CHECK);
1067   }
1068 }
1069 
1070 static void reset_vm_info_property(TRAPS) {
1071   // the vm info string
1072   ResourceMark rm(THREAD);
1073   const char *vm_info = VM_Version::vm_info_string();
1074 
1075   // java.lang.System class
1076   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
1077   instanceKlassHandle klass (THREAD, k);
1078 
1079   // setProperty arguments
1080   Handle key_str    = java_lang_String::create_from_str("java.vm.info", CHECK);
1081   Handle value_str  = java_lang_String::create_from_str(vm_info, CHECK);
1082 
1083   // return value
1084   JavaValue r(T_OBJECT);
1085 
1086   // public static String setProperty(String key, String value);
1087   JavaCalls::call_static(&amp;r,
1088                          klass,
1089                          vmSymbols::setProperty_name(),
1090                          vmSymbols::string_string_string_signature(),
1091                          key_str,
1092                          value_str,
1093                          CHECK);
1094 }
1095 
1096 
1097 void JavaThread::allocate_threadObj(Handle thread_group, const char* thread_name,
1098                                     bool daemon, TRAPS) {
1099   assert(thread_group.not_null(), "thread group should be specified");
1100   assert(threadObj() == NULL, "should only create Java thread object once");
1101 
1102   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK);
1103   instanceKlassHandle klass (THREAD, k);
1104   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK);
1105 
1106   java_lang_Thread::set_thread(thread_oop(), this);
1107   java_lang_Thread::set_priority(thread_oop(), NormPriority);
1108   set_threadObj(thread_oop());
1109 
1110   JavaValue result(T_VOID);
1111   if (thread_name != NULL) {
1112     Handle name = java_lang_String::create_from_str(thread_name, CHECK);
1113     // Thread gets assigned specified name and null target
1114     JavaCalls::call_special(&amp;result,
1115                             thread_oop,
1116                             klass,
1117                             vmSymbols::object_initializer_name(),
1118                             vmSymbols::threadgroup_string_void_signature(),
1119                             thread_group, // Argument 1
1120                             name,         // Argument 2
1121                             THREAD);
1122   } else {
1123     // Thread gets assigned name "Thread-nnn" and null target
1124     // (java.lang.Thread doesn't have a constructor taking only a ThreadGroup argument)
1125     JavaCalls::call_special(&amp;result,
1126                             thread_oop,
1127                             klass,
1128                             vmSymbols::object_initializer_name(),
1129                             vmSymbols::threadgroup_runnable_void_signature(),
1130                             thread_group, // Argument 1
1131                             Handle(),     // Argument 2
1132                             THREAD);
1133   }
1134 
1135 
1136   if (daemon) {
1137     java_lang_Thread::set_daemon(thread_oop());
1138   }
1139 
1140   if (HAS_PENDING_EXCEPTION) {
1141     return;
1142   }
1143 
1144   KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass());
1145   Handle threadObj(THREAD, this-&gt;threadObj());
1146 
1147   JavaCalls::call_special(&amp;result,
1148                           thread_group,
1149                           group,
1150                           vmSymbols::add_method_name(),
1151                           vmSymbols::thread_void_signature(),
1152                           threadObj,          // Arg 1
1153                           THREAD);
1154 }
1155 
1156 // NamedThread --  non-JavaThread subclasses with multiple
1157 // uniquely named instances should derive from this.
1158 NamedThread::NamedThread() : Thread() {
1159   _name = NULL;
1160   _processed_thread = NULL;
1161   _gc_id = GCId::undefined();
1162 }
1163 
1164 NamedThread::~NamedThread() {
1165   if (_name != NULL) {
1166     FREE_C_HEAP_ARRAY(char, _name);
1167     _name = NULL;
1168   }
1169 }
1170 
1171 void NamedThread::set_name(const char* format, ...) {
1172   guarantee(_name == NULL, "Only get to set name once.");
1173   _name = NEW_C_HEAP_ARRAY(char, max_name_len, mtThread);
1174   guarantee(_name != NULL, "alloc failure");
1175   va_list ap;
1176   va_start(ap, format);
1177   jio_vsnprintf(_name, max_name_len, format, ap);
1178   va_end(ap);
1179 }
1180 
1181 void NamedThread::initialize_named_thread() {
1182   set_native_thread_name(name());
1183 }
1184 
1185 void NamedThread::print_on(outputStream* st) const {
1186   st-&gt;print("\"%s\" ", name());
1187   Thread::print_on(st);
1188   st-&gt;cr();
1189 }
1190 
1191 
1192 // ======= WatcherThread ========
1193 
1194 // The watcher thread exists to simulate timer interrupts.  It should
1195 // be replaced by an abstraction over whatever native support for
1196 // timer interrupts exists on the platform.
1197 
1198 WatcherThread* WatcherThread::_watcher_thread   = NULL;
1199 bool WatcherThread::_startable = false;
1200 volatile bool  WatcherThread::_should_terminate = false;
1201 
1202 WatcherThread::WatcherThread() : Thread(), _crash_protection(NULL) {
1203   assert(watcher_thread() == NULL, "we can only allocate one WatcherThread");
1204   if (os::create_thread(this, os::watcher_thread)) {
1205     _watcher_thread = this;
1206 
1207     // Set the watcher thread to the highest OS priority which should not be
1208     // used, unless a Java thread with priority java.lang.Thread.MAX_PRIORITY
1209     // is created. The only normal thread using this priority is the reference
1210     // handler thread, which runs for very short intervals only.
1211     // If the VMThread's priority is not lower than the WatcherThread profiling
1212     // will be inaccurate.
1213     os::set_priority(this, MaxPriority);
1214     if (!DisableStartThread) {
1215       os::start_thread(this);
1216     }
1217   }
1218 }
1219 
1220 int WatcherThread::sleep() const {
1221   // The WatcherThread does not participate in the safepoint protocol
1222   // for the PeriodicTask_lock because it is not a JavaThread.
1223   MutexLockerEx ml(PeriodicTask_lock, Mutex::_no_safepoint_check_flag);
1224 
1225   if (_should_terminate) {
1226     // check for termination before we do any housekeeping or wait
1227     return 0;  // we did not sleep.
1228   }
1229 
1230   // remaining will be zero if there are no tasks,
1231   // causing the WatcherThread to sleep until a task is
1232   // enrolled
1233   int remaining = PeriodicTask::time_to_wait();
1234   int time_slept = 0;
1235 
1236   // we expect this to timeout - we only ever get unparked when
1237   // we should terminate or when a new task has been enrolled
1238   OSThreadWaitState osts(this-&gt;osthread(), false /* not Object.wait() */);
1239 
1240   jlong time_before_loop = os::javaTimeNanos();
1241 
1242   while (true) {
1243     bool timedout = PeriodicTask_lock-&gt;wait(Mutex::_no_safepoint_check_flag,
1244                                             remaining);
1245     jlong now = os::javaTimeNanos();
1246 
1247     if (remaining == 0) {
1248       // if we didn't have any tasks we could have waited for a long time
1249       // consider the time_slept zero and reset time_before_loop
1250       time_slept = 0;
1251       time_before_loop = now;
1252     } else {
1253       // need to recalculate since we might have new tasks in _tasks
1254       time_slept = (int) ((now - time_before_loop) / 1000000);
1255     }
1256 
1257     // Change to task list or spurious wakeup of some kind
1258     if (timedout || _should_terminate) {
1259       break;
1260     }
1261 
1262     remaining = PeriodicTask::time_to_wait();
1263     if (remaining == 0) {
1264       // Last task was just disenrolled so loop around and wait until
1265       // another task gets enrolled
1266       continue;
1267     }
1268 
1269     remaining -= time_slept;
1270     if (remaining &lt;= 0) {
1271       break;
1272     }
1273   }
1274 
1275   return time_slept;
1276 }
1277 
1278 void WatcherThread::run() {
1279   assert(this == watcher_thread(), "just checking");
1280 
1281   this-&gt;record_stack_base_and_size();
1282   this-&gt;set_native_thread_name(this-&gt;name());
1283   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1284   while (true) {
1285     assert(watcher_thread() == Thread::current(), "thread consistency check");
1286     assert(watcher_thread() == this, "thread consistency check");
1287 
1288     // Calculate how long it'll be until the next PeriodicTask work
1289     // should be done, and sleep that amount of time.
1290     int time_waited = sleep();
1291 
1292     if (is_error_reported()) {
1293       // A fatal error has happened, the error handler(VMError::report_and_die)
1294       // should abort JVM after creating an error log file. However in some
1295       // rare cases, the error handler itself might deadlock. Here we try to
1296       // kill JVM if the fatal error handler fails to abort in 2 minutes.
1297       //
1298       // This code is in WatcherThread because WatcherThread wakes up
1299       // periodically so the fatal error handler doesn't need to do anything;
1300       // also because the WatcherThread is less likely to crash than other
1301       // threads.
1302 
1303       for (;;) {
1304         if (!ShowMessageBoxOnError
1305             &amp;&amp; (OnError == NULL || OnError[0] == '\0')
1306             &amp;&amp; Arguments::abort_hook() == NULL) {
1307           os::sleep(this, (jlong)ErrorLogTimeout * 1000, false); // in seconds
1308           fdStream err(defaultStream::output_fd());
1309           err.print_raw_cr("# [ timer expired, abort... ]");
1310           // skip atexit/vm_exit/vm_abort hooks
1311           os::die();
1312         }
1313 
1314         // Wake up 5 seconds later, the fatal handler may reset OnError or
1315         // ShowMessageBoxOnError when it is ready to abort.
1316         os::sleep(this, 5 * 1000, false);
1317       }
1318     }
1319 
1320     if (_should_terminate) {
1321       // check for termination before posting the next tick
1322       break;
1323     }
1324 
1325     PeriodicTask::real_time_tick(time_waited);
1326   }
1327 
1328   // Signal that it is terminated
1329   {
1330     MutexLockerEx mu(Terminator_lock, Mutex::_no_safepoint_check_flag);
1331     _watcher_thread = NULL;
1332     Terminator_lock-&gt;notify();
1333   }
1334 }
1335 
1336 void WatcherThread::start() {
1337   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1338 
1339   if (watcher_thread() == NULL &amp;&amp; _startable) {
1340     _should_terminate = false;
1341     // Create the single instance of WatcherThread
1342     new WatcherThread();
1343   }
1344 }
1345 
1346 void WatcherThread::make_startable() {
1347   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1348   _startable = true;
1349 }
1350 
1351 void WatcherThread::stop() {
1352   {
1353     // Follow normal safepoint aware lock enter protocol since the
1354     // WatcherThread is stopped by another JavaThread.
1355     MutexLocker ml(PeriodicTask_lock);
1356     _should_terminate = true;
1357 
1358     WatcherThread* watcher = watcher_thread();
1359     if (watcher != NULL) {
1360       // unpark the WatcherThread so it can see that it should terminate
1361       watcher-&gt;unpark();
1362     }
1363   }
1364 
1365   MutexLocker mu(Terminator_lock);
1366 
1367   while (watcher_thread() != NULL) {
1368     // This wait should make safepoint checks, wait without a timeout,
1369     // and wait as a suspend-equivalent condition.
1370     //
1371     // Note: If the FlatProfiler is running, then this thread is waiting
1372     // for the WatcherThread to terminate and the WatcherThread, via the
1373     // FlatProfiler task, is waiting for the external suspend request on
1374     // this thread to complete. wait_for_ext_suspend_completion() will
1375     // eventually timeout, but that takes time. Making this wait a
1376     // suspend-equivalent condition solves that timeout problem.
1377     //
1378     Terminator_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
1379                           Mutex::_as_suspend_equivalent_flag);
1380   }
1381 }
1382 
1383 void WatcherThread::unpark() {
1384   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1385   PeriodicTask_lock-&gt;notify();
1386 }
1387 
1388 void WatcherThread::print_on(outputStream* st) const {
1389   st-&gt;print("\"%s\" ", name());
1390   Thread::print_on(st);
1391   st-&gt;cr();
1392 }
1393 
1394 // ======= JavaThread ========
1395 
1396 #if INCLUDE_JVMCI
1397 
1398 jlong* JavaThread::_jvmci_old_thread_counters;
1399 
1400 bool jvmci_counters_include(JavaThread* thread) {
1401   oop threadObj = thread-&gt;threadObj();
1402   return !JVMCICountersExcludeCompiler || !thread-&gt;is_Compiler_thread();
1403 }
1404 
1405 void JavaThread::collect_counters(typeArrayOop array) {
1406   if (JVMCICounterSize &gt; 0) {
1407     MutexLocker tl(Threads_lock);
1408     for (int i = 0; i &lt; array-&gt;length(); i++) {
1409       array-&gt;long_at_put(i, _jvmci_old_thread_counters[i]);
1410     }
1411     for (JavaThread* tp = Threads::first(); tp != NULL; tp = tp-&gt;next()) {
1412       if (jvmci_counters_include(tp)) {
1413         for (int i = 0; i &lt; array-&gt;length(); i++) {
1414           array-&gt;long_at_put(i, array-&gt;long_at(i) + tp-&gt;_jvmci_counters[i]);
1415         }
1416       }
1417     }
1418   }
1419 }
1420 
1421 #endif // INCLUDE_JVMCI
1422 
1423 // A JavaThread is a normal Java thread
1424 
1425 void JavaThread::initialize() {
1426   // Initialize fields
1427 
1428   set_saved_exception_pc(NULL);
1429   set_threadObj(NULL);
1430   _anchor.clear();
1431   set_entry_point(NULL);
1432   set_jni_functions(jni_functions());
1433   set_callee_target(NULL);
1434   set_vm_result(NULL);
1435   set_vm_result_2(NULL);
1436   set_vframe_array_head(NULL);
1437   set_vframe_array_last(NULL);
1438   set_deferred_locals(NULL);
1439   set_deopt_mark(NULL);
1440   set_deopt_nmethod(NULL);
1441   clear_must_deopt_id();
1442   set_monitor_chunks(NULL);
1443   set_next(NULL);
1444   set_thread_state(_thread_new);
1445   _terminated = _not_terminated;
1446   _privileged_stack_top = NULL;
1447   _array_for_gc = NULL;
1448   _suspend_equivalent = false;
1449   _in_deopt_handler = 0;
1450   _doing_unsafe_access = false;
1451   _stack_guard_state = stack_guard_unused;
1452 #if INCLUDE_JVMCI
1453   _pending_monitorenter = false;
1454   _pending_deoptimization = -1;
1455   _pending_failed_speculation = NULL;
1456   _pending_transfer_to_interpreter = false;
1457   _jvmci._alternate_call_target = NULL;
1458   assert(_jvmci._implicit_exception_pc == NULL, "must be");
1459   if (JVMCICounterSize &gt; 0) {
1460     _jvmci_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
1461     memset(_jvmci_counters, 0, sizeof(jlong) * JVMCICounterSize);
1462   } else {
1463     _jvmci_counters = NULL;
1464   }
1465 #endif // INCLUDE_JVMCI
1466   _reserved_stack_activation = NULL;  // stack base not known yet
1467   (void)const_cast&lt;oop&amp;&gt;(_exception_oop = oop(NULL));
1468   _exception_pc  = 0;
1469   _exception_handler_pc = 0;
1470   _is_method_handle_return = 0;
1471   _jvmti_thread_state= NULL;
1472   _should_post_on_exceptions_flag = JNI_FALSE;
1473   _jvmti_get_loaded_classes_closure = NULL;
1474   _interp_only_mode    = 0;
1475   _special_runtime_exit_condition = _no_async_condition;
1476   _pending_async_exception = NULL;
1477   _thread_stat = NULL;
1478   _thread_stat = new ThreadStatistics();
1479   _blocked_on_compilation = false;
1480   _jni_active_critical = 0;
1481   _pending_jni_exception_check_fn = NULL;
1482   _do_not_unlock_if_synchronized = false;
1483   _cached_monitor_info = NULL;
1484   _parker = Parker::Allocate(this);
1485 
1486 #ifndef PRODUCT
1487   _jmp_ring_index = 0;
1488   for (int ji = 0; ji &lt; jump_ring_buffer_size; ji++) {
1489     record_jump(NULL, NULL, NULL, 0);
1490   }
1491 #endif // PRODUCT
1492 
1493   set_thread_profiler(NULL);
1494   if (FlatProfiler::is_active()) {
1495     // This is where we would decide to either give each thread it's own profiler
1496     // or use one global one from FlatProfiler,
1497     // or up to some count of the number of profiled threads, etc.
1498     ThreadProfiler* pp = new ThreadProfiler();
1499     pp-&gt;engage();
1500     set_thread_profiler(pp);
1501   }
1502 
1503   // Setup safepoint state info for this thread
1504   ThreadSafepointState::create(this);
1505 
1506   debug_only(_java_call_counter = 0);
1507 
1508   // JVMTI PopFrame support
1509   _popframe_condition = popframe_inactive;
1510   _popframe_preserved_args = NULL;
1511   _popframe_preserved_args_size = 0;
1512   _frames_to_pop_failed_realloc = 0;
1513 
1514   pd_initialize();
1515 }
1516 
1517 #if INCLUDE_ALL_GCS
1518 SATBMarkQueueSet JavaThread::_satb_mark_queue_set;
1519 DirtyCardQueueSet JavaThread::_dirty_card_queue_set;
1520 #endif // INCLUDE_ALL_GCS
1521 
1522 JavaThread::JavaThread(bool is_attaching_via_jni) :
1523                        Thread()
1524 #if INCLUDE_ALL_GCS
1525                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1526                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1527 #endif // INCLUDE_ALL_GCS
1528 {
1529   initialize();
1530   if (is_attaching_via_jni) {
1531     _jni_attach_state = _attaching_via_jni;
1532   } else {
1533     _jni_attach_state = _not_attaching_via_jni;
1534   }
1535   assert(deferred_card_mark().is_empty(), "Default MemRegion ctor");
1536 }
1537 
1538 bool JavaThread::reguard_stack(address cur_sp) {
1539   if (_stack_guard_state != stack_guard_yellow_reserved_disabled
1540       &amp;&amp; _stack_guard_state != stack_guard_reserved_disabled) {
1541     return true; // Stack already guarded or guard pages not needed.
1542   }
1543 
1544   if (register_stack_overflow()) {
1545     // For those architectures which have separate register and
1546     // memory stacks, we must check the register stack to see if
1547     // it has overflowed.
1548     return false;
1549   }
1550 
1551   // Java code never executes within the yellow zone: the latter is only
1552   // there to provoke an exception during stack banging.  If java code
1553   // is executing there, either StackShadowPages should be larger, or
1554   // some exception code in c1, c2 or the interpreter isn't unwinding
1555   // when it should.
1556   guarantee(cur_sp &gt; stack_reserved_zone_base(),
1557             "not enough space to reguard - increase StackShadowPages");
1558   if (_stack_guard_state == stack_guard_yellow_reserved_disabled) {
1559     enable_stack_yellow_reserved_zone();
1560     if (reserved_stack_activation() != stack_base()) {
1561       set_reserved_stack_activation(stack_base());
1562     }
1563   } else if (_stack_guard_state == stack_guard_reserved_disabled) {
1564     set_reserved_stack_activation(stack_base());
1565     enable_stack_reserved_zone();
1566   }
1567   return true;
1568 }
1569 
1570 bool JavaThread::reguard_stack(void) {
1571   return reguard_stack(os::current_stack_pointer());
1572 }
1573 
1574 
1575 void JavaThread::block_if_vm_exited() {
1576   if (_terminated == _vm_exited) {
1577     // _vm_exited is set at safepoint, and Threads_lock is never released
1578     // we will block here forever
1579     Threads_lock-&gt;lock_without_safepoint_check();
1580     ShouldNotReachHere();
1581   }
1582 }
1583 
1584 
1585 // Remove this ifdef when C1 is ported to the compiler interface.
1586 static void compiler_thread_entry(JavaThread* thread, TRAPS);
1587 static void sweeper_thread_entry(JavaThread* thread, TRAPS);
1588 
1589 JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) :
1590                        Thread()
1591 #if INCLUDE_ALL_GCS
1592                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1593                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1594 #endif // INCLUDE_ALL_GCS
1595 {
1596   initialize();
1597   _jni_attach_state = _not_attaching_via_jni;
1598   set_entry_point(entry_point);
1599   // Create the native thread itself.
1600   // %note runtime_23
1601   os::ThreadType thr_type = os::java_thread;
1602   thr_type = entry_point == &amp;compiler_thread_entry ? os::compiler_thread :
1603                                                      os::java_thread;
1604   os::create_thread(this, thr_type, stack_sz);
1605   // The _osthread may be NULL here because we ran out of memory (too many threads active).
1606   // We need to throw and OutOfMemoryError - however we cannot do this here because the caller
1607   // may hold a lock and all locks must be unlocked before throwing the exception (throwing
1608   // the exception consists of creating the exception object &amp; initializing it, initialization
1609   // will leave the VM via a JavaCall and then all locks must be unlocked).
1610   //
1611   // The thread is still suspended when we reach here. Thread must be explicit started
1612   // by creator! Furthermore, the thread must also explicitly be added to the Threads list
1613   // by calling Threads:add. The reason why this is not done here, is because the thread
1614   // object must be fully initialized (take a look at JVM_Start)
1615 }
1616 
1617 JavaThread::~JavaThread() {
1618 
1619   // JSR166 -- return the parker to the free list
1620   Parker::Release(_parker);
1621   _parker = NULL;
1622 
1623   // Free any remaining  previous UnrollBlock
1624   vframeArray* old_array = vframe_array_last();
1625 
1626   if (old_array != NULL) {
1627     Deoptimization::UnrollBlock* old_info = old_array-&gt;unroll_block();
1628     old_array-&gt;set_unroll_block(NULL);
1629     delete old_info;
1630     delete old_array;
1631   }
1632 
1633   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* deferred = deferred_locals();
1634   if (deferred != NULL) {
1635     // This can only happen if thread is destroyed before deoptimization occurs.
1636     assert(deferred-&gt;length() != 0, "empty array!");
1637     do {
1638       jvmtiDeferredLocalVariableSet* dlv = deferred-&gt;at(0);
1639       deferred-&gt;remove_at(0);
1640       // individual jvmtiDeferredLocalVariableSet are CHeapObj's
1641       delete dlv;
1642     } while (deferred-&gt;length() != 0);
1643     delete deferred;
1644   }
1645 
1646   // All Java related clean up happens in exit
1647   ThreadSafepointState::destroy(this);
1648   if (_thread_profiler != NULL) delete _thread_profiler;
1649   if (_thread_stat != NULL) delete _thread_stat;
1650 
1651 #if INCLUDE_JVMCI
1652   if (JVMCICounterSize &gt; 0) {
1653     if (jvmci_counters_include(this)) {
1654       for (int i = 0; i &lt; JVMCICounterSize; i++) {
1655         _jvmci_old_thread_counters[i] += _jvmci_counters[i];
1656       }
1657     }
1658     FREE_C_HEAP_ARRAY(jlong, _jvmci_counters);
1659   }
1660 #endif // INCLUDE_JVMCI
1661 }
1662 
1663 
1664 // The first routine called by a new Java thread
1665 void JavaThread::run() {
1666   // initialize thread-local alloc buffer related fields
1667   this-&gt;initialize_tlab();
1668 
1669   // used to test validity of stack trace backs
1670   this-&gt;record_base_of_stack_pointer();
1671 
1672   // Record real stack base and size.
1673   this-&gt;record_stack_base_and_size();
1674 
1675   this-&gt;create_stack_guard_pages();
1676 
1677   this-&gt;cache_global_variables();
1678 
1679   // Thread is now sufficient initialized to be handled by the safepoint code as being
1680   // in the VM. Change thread state from _thread_new to _thread_in_vm
1681   ThreadStateTransition::transition_and_fence(this, _thread_new, _thread_in_vm);
1682 
1683   assert(JavaThread::current() == this, "sanity check");
1684   assert(!Thread::current()-&gt;owns_locks(), "sanity check");
1685 
1686   DTRACE_THREAD_PROBE(start, this);
1687 
1688   // This operation might block. We call that after all safepoint checks for a new thread has
1689   // been completed.
1690   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1691 
1692   if (JvmtiExport::should_post_thread_life()) {
1693     JvmtiExport::post_thread_start(this);
1694   }
1695 
1696   EventThreadStart event;
1697   if (event.should_commit()) {
1698     event.set_thread(THREAD_TRACE_ID(this));
1699     event.commit();
1700   }
1701 
1702   // We call another function to do the rest so we are sure that the stack addresses used
1703   // from there will be lower than the stack base just computed
1704   thread_main_inner();
1705 
1706   // Note, thread is no longer valid at this point!
1707 }
1708 
1709 
1710 void JavaThread::thread_main_inner() {
1711   assert(JavaThread::current() == this, "sanity check");
1712   assert(this-&gt;threadObj() != NULL, "just checking");
1713 
1714   // Execute thread entry point unless this thread has a pending exception
1715   // or has been stopped before starting.
1716   // Note: Due to JVM_StopThread we can have pending exceptions already!
1717   if (!this-&gt;has_pending_exception() &amp;&amp;
1718       !java_lang_Thread::is_stillborn(this-&gt;threadObj())) {
1719     {
1720       ResourceMark rm(this);
1721       this-&gt;set_native_thread_name(this-&gt;get_thread_name());
1722     }
1723     HandleMark hm(this);
1724     this-&gt;entry_point()(this, this);
1725   }
1726 
1727   DTRACE_THREAD_PROBE(stop, this);
1728 
1729   this-&gt;exit(false);
1730   delete this;
1731 }
1732 
1733 
1734 static void ensure_join(JavaThread* thread) {
1735   // We do not need to grap the Threads_lock, since we are operating on ourself.
1736   Handle threadObj(thread, thread-&gt;threadObj());
1737   assert(threadObj.not_null(), "java thread object must exist");
1738   ObjectLocker lock(threadObj, thread);
1739   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1740   thread-&gt;clear_pending_exception();
1741   // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.
1742   java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);
1743   // Clear the native thread instance - this makes isAlive return false and allows the join()
1744   // to complete once we've done the notify_all below
1745   java_lang_Thread::set_thread(threadObj(), NULL);
1746   lock.notify_all(thread);
1747   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1748   thread-&gt;clear_pending_exception();
1749 }
1750 
1751 
1752 // For any new cleanup additions, please check to see if they need to be applied to
1753 // cleanup_failed_attach_current_thread as well.
1754 void JavaThread::exit(bool destroy_vm, ExitType exit_type) {
1755   assert(this == JavaThread::current(), "thread consistency check");
1756 
1757   HandleMark hm(this);
1758   Handle uncaught_exception(this, this-&gt;pending_exception());
1759   this-&gt;clear_pending_exception();
1760   Handle threadObj(this, this-&gt;threadObj());
1761   assert(threadObj.not_null(), "Java thread object should be created");
1762 
1763   if (get_thread_profiler() != NULL) {
1764     get_thread_profiler()-&gt;disengage();
1765     ResourceMark rm;
1766     get_thread_profiler()-&gt;print(get_thread_name());
1767   }
1768 
1769 
1770   // FIXIT: This code should be moved into else part, when reliable 1.2/1.3 check is in place
1771   {
1772     EXCEPTION_MARK;
1773 
1774     CLEAR_PENDING_EXCEPTION;
1775   }
1776   if (!destroy_vm) {
1777     if (uncaught_exception.not_null()) {
1778       EXCEPTION_MARK;
1779       // Call method Thread.dispatchUncaughtException().
1780       KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1781       JavaValue result(T_VOID);
1782       JavaCalls::call_virtual(&amp;result,
1783                               threadObj, thread_klass,
1784                               vmSymbols::dispatchUncaughtException_name(),
1785                               vmSymbols::throwable_void_signature(),
1786                               uncaught_exception,
1787                               THREAD);
1788       if (HAS_PENDING_EXCEPTION) {
1789         ResourceMark rm(this);
1790         jio_fprintf(defaultStream::error_stream(),
1791                     "\nException: %s thrown from the UncaughtExceptionHandler"
1792                     " in thread \"%s\"\n",
1793                     pending_exception()-&gt;klass()-&gt;external_name(),
1794                     get_thread_name());
1795         CLEAR_PENDING_EXCEPTION;
1796       }
1797     }
1798 
1799     // Called before the java thread exit since we want to read info
1800     // from java_lang_Thread object
1801     EventThreadEnd event;
1802     if (event.should_commit()) {
1803       event.set_thread(THREAD_TRACE_ID(this));
1804       event.commit();
1805     }
1806 
1807     // Call after last event on thread
1808     EVENT_THREAD_EXIT(this);
1809 
1810     // Call Thread.exit(). We try 3 times in case we got another Thread.stop during
1811     // the execution of the method. If that is not enough, then we don't really care. Thread.stop
1812     // is deprecated anyhow.
1813     if (!is_Compiler_thread()) {
1814       int count = 3;
1815       while (java_lang_Thread::threadGroup(threadObj()) != NULL &amp;&amp; (count-- &gt; 0)) {
1816         EXCEPTION_MARK;
1817         JavaValue result(T_VOID);
1818         KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1819         JavaCalls::call_virtual(&amp;result,
1820                                 threadObj, thread_klass,
1821                                 vmSymbols::exit_method_name(),
1822                                 vmSymbols::void_method_signature(),
1823                                 THREAD);
1824         CLEAR_PENDING_EXCEPTION;
1825       }
1826     }
1827     // notify JVMTI
1828     if (JvmtiExport::should_post_thread_life()) {
1829       JvmtiExport::post_thread_end(this);
1830     }
1831 
1832     // We have notified the agents that we are exiting, before we go on,
1833     // we must check for a pending external suspend request and honor it
1834     // in order to not surprise the thread that made the suspend request.
1835     while (true) {
1836       {
1837         MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1838         if (!is_external_suspend()) {
1839           set_terminated(_thread_exiting);
1840           ThreadService::current_thread_exiting(this);
1841           break;
1842         }
1843         // Implied else:
1844         // Things get a little tricky here. We have a pending external
1845         // suspend request, but we are holding the SR_lock so we
1846         // can't just self-suspend. So we temporarily drop the lock
1847         // and then self-suspend.
1848       }
1849 
1850       ThreadBlockInVM tbivm(this);
1851       java_suspend_self();
1852 
1853       // We're done with this suspend request, but we have to loop around
1854       // and check again. Eventually we will get SR_lock without a pending
1855       // external suspend request and will be able to mark ourselves as
1856       // exiting.
1857     }
1858     // no more external suspends are allowed at this point
1859   } else {
1860     // before_exit() has already posted JVMTI THREAD_END events
1861   }
1862 
1863   // Notify waiters on thread object. This has to be done after exit() is called
1864   // on the thread (if the thread is the last thread in a daemon ThreadGroup the
1865   // group should have the destroyed bit set before waiters are notified).
1866   ensure_join(this);
1867   assert(!this-&gt;has_pending_exception(), "ensure_join should have cleared");
1868 
1869   // 6282335 JNI DetachCurrentThread spec states that all Java monitors
1870   // held by this thread must be released. The spec does not distinguish
1871   // between JNI-acquired and regular Java monitors. We can only see
1872   // regular Java monitors here if monitor enter-exit matching is broken.
1873   //
1874   // Optionally release any monitors for regular JavaThread exits. This
1875   // is provided as a work around for any bugs in monitor enter-exit
1876   // matching. This can be expensive so it is not enabled by default.
1877   //
1878   // ensure_join() ignores IllegalThreadStateExceptions, and so does
1879   // ObjectSynchronizer::release_monitors_owned_by_thread().
1880   if (exit_type == jni_detach || ObjectMonitor::Knob_ExitRelease) {
1881     // Sanity check even though JNI DetachCurrentThread() would have
1882     // returned JNI_ERR if there was a Java frame. JavaThread exit
1883     // should be done executing Java code by the time we get here.
1884     assert(!this-&gt;has_last_Java_frame(),
1885            "should not have a Java frame when detaching or exiting");
1886     ObjectSynchronizer::release_monitors_owned_by_thread(this);
1887     assert(!this-&gt;has_pending_exception(), "release_monitors should have cleared");
1888   }
1889 
1890   // These things needs to be done while we are still a Java Thread. Make sure that thread
1891   // is in a consistent state, in case GC happens
1892   assert(_privileged_stack_top == NULL, "must be NULL when we get here");
1893 
1894   if (active_handles() != NULL) {
1895     JNIHandleBlock* block = active_handles();
1896     set_active_handles(NULL);
1897     JNIHandleBlock::release_block(block);
1898   }
1899 
1900   if (free_handle_block() != NULL) {
1901     JNIHandleBlock* block = free_handle_block();
1902     set_free_handle_block(NULL);
1903     JNIHandleBlock::release_block(block);
1904   }
1905 
1906   // These have to be removed while this is still a valid thread.
1907   remove_stack_guard_pages();
1908 
1909   if (UseTLAB) {
1910     tlab().make_parsable(true);  // retire TLAB
1911   }
1912 
1913   if (JvmtiEnv::environments_might_exist()) {
1914     JvmtiExport::cleanup_thread(this);
1915   }
1916 
1917   // We must flush any deferred card marks before removing a thread from
1918   // the list of active threads.
1919   Universe::heap()-&gt;flush_deferred_store_barrier(this);
1920   assert(deferred_card_mark().is_empty(), "Should have been flushed");
1921 
1922 #if INCLUDE_ALL_GCS
1923   // We must flush the G1-related buffers before removing a thread
1924   // from the list of active threads. We must do this after any deferred
1925   // card marks have been flushed (above) so that any entries that are
1926   // added to the thread's dirty card queue as a result are not lost.
1927   if (UseG1GC) {
1928     flush_barrier_queues();
1929   }
1930 #endif // INCLUDE_ALL_GCS
1931 
1932   log_info(os, thread)("JavaThread %s (tid: " UINTX_FORMAT ").",
1933     exit_type == JavaThread::normal_exit ? "exiting" : "detaching",
1934     os::current_thread_id());
1935 
1936   // Remove from list of active threads list, and notify VM thread if we are the last non-daemon thread
1937   Threads::remove(this);
1938 }
1939 
1940 #if INCLUDE_ALL_GCS
1941 // Flush G1-related queues.
1942 void JavaThread::flush_barrier_queues() {
1943   satb_mark_queue().flush();
1944   dirty_card_queue().flush();
1945 }
1946 
1947 void JavaThread::initialize_queues() {
1948   assert(!SafepointSynchronize::is_at_safepoint(),
1949          "we should not be at a safepoint");
1950 
1951   SATBMarkQueue&amp; satb_queue = satb_mark_queue();
1952   SATBMarkQueueSet&amp; satb_queue_set = satb_mark_queue_set();
1953   // The SATB queue should have been constructed with its active
1954   // field set to false.
1955   assert(!satb_queue.is_active(), "SATB queue should not be active");
1956   assert(satb_queue.is_empty(), "SATB queue should be empty");
1957   // If we are creating the thread during a marking cycle, we should
1958   // set the active field of the SATB queue to true.
1959   if (satb_queue_set.is_active()) {
1960     satb_queue.set_active(true);
1961   }
1962 
1963   DirtyCardQueue&amp; dirty_queue = dirty_card_queue();
1964   // The dirty card queue should have been constructed with its
1965   // active field set to true.
1966   assert(dirty_queue.is_active(), "dirty card queue should be active");
1967 }
1968 #endif // INCLUDE_ALL_GCS
1969 
1970 void JavaThread::cleanup_failed_attach_current_thread() {
1971   if (get_thread_profiler() != NULL) {
1972     get_thread_profiler()-&gt;disengage();
1973     ResourceMark rm;
1974     get_thread_profiler()-&gt;print(get_thread_name());
1975   }
1976 
1977   if (active_handles() != NULL) {
1978     JNIHandleBlock* block = active_handles();
1979     set_active_handles(NULL);
1980     JNIHandleBlock::release_block(block);
1981   }
1982 
1983   if (free_handle_block() != NULL) {
1984     JNIHandleBlock* block = free_handle_block();
1985     set_free_handle_block(NULL);
1986     JNIHandleBlock::release_block(block);
1987   }
1988 
1989   // These have to be removed while this is still a valid thread.
1990   remove_stack_guard_pages();
1991 
1992   if (UseTLAB) {
1993     tlab().make_parsable(true);  // retire TLAB, if any
1994   }
1995 
1996 #if INCLUDE_ALL_GCS
1997   if (UseG1GC) {
1998     flush_barrier_queues();
1999   }
2000 #endif // INCLUDE_ALL_GCS
2001 
2002   Threads::remove(this);
2003   delete this;
2004 }
2005 
2006 
2007 
2008 
2009 JavaThread* JavaThread::active() {
2010   Thread* thread = Thread::current();
2011   if (thread-&gt;is_Java_thread()) {
2012     return (JavaThread*) thread;
2013   } else {
2014     assert(thread-&gt;is_VM_thread(), "this must be a vm thread");
2015     VM_Operation* op = ((VMThread*) thread)-&gt;vm_operation();
2016     JavaThread *ret=op == NULL ? NULL : (JavaThread *)op-&gt;calling_thread();
2017     assert(ret-&gt;is_Java_thread(), "must be a Java thread");
2018     return ret;
2019   }
2020 }
2021 
2022 bool JavaThread::is_lock_owned(address adr) const {
2023   if (Thread::is_lock_owned(adr)) return true;
2024 
2025   for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2026     if (chunk-&gt;contains(adr)) return true;
2027   }
2028 
2029   return false;
2030 }
2031 
2032 
2033 void JavaThread::add_monitor_chunk(MonitorChunk* chunk) {
2034   chunk-&gt;set_next(monitor_chunks());
2035   set_monitor_chunks(chunk);
2036 }
2037 
2038 void JavaThread::remove_monitor_chunk(MonitorChunk* chunk) {
2039   guarantee(monitor_chunks() != NULL, "must be non empty");
2040   if (monitor_chunks() == chunk) {
2041     set_monitor_chunks(chunk-&gt;next());
2042   } else {
2043     MonitorChunk* prev = monitor_chunks();
2044     while (prev-&gt;next() != chunk) prev = prev-&gt;next();
2045     prev-&gt;set_next(chunk-&gt;next());
2046   }
2047 }
2048 
2049 // JVM support.
2050 
2051 // Note: this function shouldn't block if it's called in
2052 // _thread_in_native_trans state (such as from
2053 // check_special_condition_for_native_trans()).
2054 void JavaThread::check_and_handle_async_exceptions(bool check_unsafe_error) {
2055 
2056   if (has_last_Java_frame() &amp;&amp; has_async_condition()) {
2057     // If we are at a polling page safepoint (not a poll return)
2058     // then we must defer async exception because live registers
2059     // will be clobbered by the exception path. Poll return is
2060     // ok because the call we a returning from already collides
2061     // with exception handling registers and so there is no issue.
2062     // (The exception handling path kills call result registers but
2063     //  this is ok since the exception kills the result anyway).
2064 
2065     if (is_at_poll_safepoint()) {
2066       // if the code we are returning to has deoptimized we must defer
2067       // the exception otherwise live registers get clobbered on the
2068       // exception path before deoptimization is able to retrieve them.
2069       //
2070       RegisterMap map(this, false);
2071       frame caller_fr = last_frame().sender(&amp;map);
2072       assert(caller_fr.is_compiled_frame(), "what?");
2073       if (caller_fr.is_deoptimized_frame()) {
2074         log_info(exceptions)("deferred async exception at compiled safepoint");
2075         return;
2076       }
2077     }
2078   }
2079 
2080   JavaThread::AsyncRequests condition = clear_special_runtime_exit_condition();
2081   if (condition == _no_async_condition) {
2082     // Conditions have changed since has_special_runtime_exit_condition()
2083     // was called:
2084     // - if we were here only because of an external suspend request,
2085     //   then that was taken care of above (or cancelled) so we are done
2086     // - if we were here because of another async request, then it has
2087     //   been cleared between the has_special_runtime_exit_condition()
2088     //   and now so again we are done
2089     return;
2090   }
2091 
2092   // Check for pending async. exception
2093   if (_pending_async_exception != NULL) {
2094     // Only overwrite an already pending exception, if it is not a threadDeath.
2095     if (!has_pending_exception() || !pending_exception()-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2096 
2097       // We cannot call Exceptions::_throw(...) here because we cannot block
2098       set_pending_exception(_pending_async_exception, __FILE__, __LINE__);
2099 
2100       if (log_is_enabled(Info, exceptions)) {
2101         ResourceMark rm;
2102         outputStream* logstream = LogHandle(exceptions)::info_stream();
2103         logstream-&gt;print("Async. exception installed at runtime exit (" INTPTR_FORMAT ")", p2i(this));
2104           if (has_last_Java_frame()) {
2105             frame f = last_frame();
2106            logstream-&gt;print(" (pc: " INTPTR_FORMAT " sp: " INTPTR_FORMAT " )", p2i(f.pc()), p2i(f.sp()));
2107           }
2108         logstream-&gt;print_cr(" of type: %s", _pending_async_exception-&gt;klass()-&gt;external_name());
2109       }
2110       _pending_async_exception = NULL;
2111       clear_has_async_exception();
2112     }
2113   }
2114 
2115   if (check_unsafe_error &amp;&amp;
2116       condition == _async_unsafe_access_error &amp;&amp; !has_pending_exception()) {
2117     condition = _no_async_condition;  // done
2118     switch (thread_state()) {
2119     case _thread_in_vm: {
2120       JavaThread* THREAD = this;
2121       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2122     }
2123     case _thread_in_native: {
2124       ThreadInVMfromNative tiv(this);
2125       JavaThread* THREAD = this;
2126       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2127     }
2128     case _thread_in_Java: {
2129       ThreadInVMfromJava tiv(this);
2130       JavaThread* THREAD = this;
2131       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in a recent unsafe memory access operation in compiled Java code");
2132     }
2133     default:
2134       ShouldNotReachHere();
2135     }
2136   }
2137 
2138   assert(condition == _no_async_condition || has_pending_exception() ||
2139          (!check_unsafe_error &amp;&amp; condition == _async_unsafe_access_error),
2140          "must have handled the async condition, if no exception");
2141 }
2142 
2143 void JavaThread::handle_special_runtime_exit_condition(bool check_asyncs) {
2144   //
2145   // Check for pending external suspend. Internal suspend requests do
2146   // not use handle_special_runtime_exit_condition().
2147   // If JNIEnv proxies are allowed, don't self-suspend if the target
2148   // thread is not the current thread. In older versions of jdbx, jdbx
2149   // threads could call into the VM with another thread's JNIEnv so we
2150   // can be here operating on behalf of a suspended thread (4432884).
2151   bool do_self_suspend = is_external_suspend_with_lock();
2152   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || this == JavaThread::current())) {
2153     //
2154     // Because thread is external suspended the safepoint code will count
2155     // thread as at a safepoint. This can be odd because we can be here
2156     // as _thread_in_Java which would normally transition to _thread_blocked
2157     // at a safepoint. We would like to mark the thread as _thread_blocked
2158     // before calling java_suspend_self like all other callers of it but
2159     // we must then observe proper safepoint protocol. (We can't leave
2160     // _thread_blocked with a safepoint in progress). However we can be
2161     // here as _thread_in_native_trans so we can't use a normal transition
2162     // constructor/destructor pair because they assert on that type of
2163     // transition. We could do something like:
2164     //
2165     // JavaThreadState state = thread_state();
2166     // set_thread_state(_thread_in_vm);
2167     // {
2168     //   ThreadBlockInVM tbivm(this);
2169     //   java_suspend_self()
2170     // }
2171     // set_thread_state(_thread_in_vm_trans);
2172     // if (safepoint) block;
2173     // set_thread_state(state);
2174     //
2175     // but that is pretty messy. Instead we just go with the way the
2176     // code has worked before and note that this is the only path to
2177     // java_suspend_self that doesn't put the thread in _thread_blocked
2178     // mode.
2179 
2180     frame_anchor()-&gt;make_walkable(this);
2181     java_suspend_self();
2182 
2183     // We might be here for reasons in addition to the self-suspend request
2184     // so check for other async requests.
2185   }
2186 
2187   if (check_asyncs) {
2188     check_and_handle_async_exceptions();
2189   }
2190 }
2191 
2192 void JavaThread::send_thread_stop(oop java_throwable)  {
2193   assert(Thread::current()-&gt;is_VM_thread(), "should be in the vm thread");
2194   assert(Threads_lock-&gt;is_locked(), "Threads_lock should be locked by safepoint code");
2195   assert(SafepointSynchronize::is_at_safepoint(), "all threads are stopped");
2196 
2197   // Do not throw asynchronous exceptions against the compiler thread
2198   // (the compiler thread should not be a Java thread -- fix in 1.4.2)
2199   if (!can_call_java()) return;
2200 
2201   {
2202     // Actually throw the Throwable against the target Thread - however
2203     // only if there is no thread death exception installed already.
2204     if (_pending_async_exception == NULL || !_pending_async_exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2205       // If the topmost frame is a runtime stub, then we are calling into
2206       // OptoRuntime from compiled code. Some runtime stubs (new, monitor_exit..)
2207       // must deoptimize the caller before continuing, as the compiled  exception handler table
2208       // may not be valid
2209       if (has_last_Java_frame()) {
2210         frame f = last_frame();
2211         if (f.is_runtime_frame() || f.is_safepoint_blob_frame()) {
2212           // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2213           RegisterMap reg_map(this, UseBiasedLocking);
2214           frame compiled_frame = f.sender(&amp;reg_map);
2215           if (!StressCompiledExceptionHandlers &amp;&amp; compiled_frame.can_be_deoptimized()) {
2216             Deoptimization::deoptimize(this, compiled_frame, &amp;reg_map);
2217           }
2218         }
2219       }
2220 
2221       // Set async. pending exception in thread.
2222       set_pending_async_exception(java_throwable);
2223 
2224       if (log_is_enabled(Info, exceptions)) {
2225          ResourceMark rm;
2226         log_info(exceptions)("Pending Async. exception installed of type: %s",
2227                              InstanceKlass::cast(_pending_async_exception-&gt;klass())-&gt;external_name());
2228       }
2229       // for AbortVMOnException flag
2230       Exceptions::debug_check_abort(_pending_async_exception-&gt;klass()-&gt;external_name());
2231     }
2232   }
2233 
2234 
2235   // Interrupt thread so it will wake up from a potential wait()
2236   Thread::interrupt(this);
2237 }
2238 
2239 // External suspension mechanism.
2240 //
2241 // Tell the VM to suspend a thread when ever it knows that it does not hold on
2242 // to any VM_locks and it is at a transition
2243 // Self-suspension will happen on the transition out of the vm.
2244 // Catch "this" coming in from JNIEnv pointers when the thread has been freed
2245 //
2246 // Guarantees on return:
2247 //   + Target thread will not execute any new bytecode (that's why we need to
2248 //     force a safepoint)
2249 //   + Target thread will not enter any new monitors
2250 //
2251 void JavaThread::java_suspend() {
2252   { MutexLocker mu(Threads_lock);
2253     if (!Threads::includes(this) || is_exiting() || this-&gt;threadObj() == NULL) {
2254       return;
2255     }
2256   }
2257 
2258   { MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2259     if (!is_external_suspend()) {
2260       // a racing resume has cancelled us; bail out now
2261       return;
2262     }
2263 
2264     // suspend is done
2265     uint32_t debug_bits = 0;
2266     // Warning: is_ext_suspend_completed() may temporarily drop the
2267     // SR_lock to allow the thread to reach a stable thread state if
2268     // it is currently in a transient thread state.
2269     if (is_ext_suspend_completed(false /* !called_by_wait */,
2270                                  SuspendRetryDelay, &amp;debug_bits)) {
2271       return;
2272     }
2273   }
2274 
2275   VM_ForceSafepoint vm_suspend;
2276   VMThread::execute(&amp;vm_suspend);
2277 }
2278 
2279 // Part II of external suspension.
2280 // A JavaThread self suspends when it detects a pending external suspend
2281 // request. This is usually on transitions. It is also done in places
2282 // where continuing to the next transition would surprise the caller,
2283 // e.g., monitor entry.
2284 //
2285 // Returns the number of times that the thread self-suspended.
2286 //
2287 // Note: DO NOT call java_suspend_self() when you just want to block current
2288 //       thread. java_suspend_self() is the second stage of cooperative
2289 //       suspension for external suspend requests and should only be used
2290 //       to complete an external suspend request.
2291 //
2292 int JavaThread::java_suspend_self() {
2293   int ret = 0;
2294 
2295   // we are in the process of exiting so don't suspend
2296   if (is_exiting()) {
2297     clear_external_suspend();
2298     return ret;
2299   }
2300 
2301   assert(_anchor.walkable() ||
2302          (is_Java_thread() &amp;&amp; !((JavaThread*)this)-&gt;has_last_Java_frame()),
2303          "must have walkable stack");
2304 
2305   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2306 
2307   assert(!this-&gt;is_ext_suspended(),
2308          "a thread trying to self-suspend should not already be suspended");
2309 
2310   if (this-&gt;is_suspend_equivalent()) {
2311     // If we are self-suspending as a result of the lifting of a
2312     // suspend equivalent condition, then the suspend_equivalent
2313     // flag is not cleared until we set the ext_suspended flag so
2314     // that wait_for_ext_suspend_completion() returns consistent
2315     // results.
2316     this-&gt;clear_suspend_equivalent();
2317   }
2318 
2319   // A racing resume may have cancelled us before we grabbed SR_lock
2320   // above. Or another external suspend request could be waiting for us
2321   // by the time we return from SR_lock()-&gt;wait(). The thread
2322   // that requested the suspension may already be trying to walk our
2323   // stack and if we return now, we can change the stack out from under
2324   // it. This would be a "bad thing (TM)" and cause the stack walker
2325   // to crash. We stay self-suspended until there are no more pending
2326   // external suspend requests.
2327   while (is_external_suspend()) {
2328     ret++;
2329     this-&gt;set_ext_suspended();
2330 
2331     // _ext_suspended flag is cleared by java_resume()
2332     while (is_ext_suspended()) {
2333       this-&gt;SR_lock()-&gt;wait(Mutex::_no_safepoint_check_flag);
2334     }
2335   }
2336 
2337   return ret;
2338 }
2339 
2340 #ifdef ASSERT
2341 // verify the JavaThread has not yet been published in the Threads::list, and
2342 // hence doesn't need protection from concurrent access at this stage
2343 void JavaThread::verify_not_published() {
2344   if (!Threads_lock-&gt;owned_by_self()) {
2345     MutexLockerEx ml(Threads_lock,  Mutex::_no_safepoint_check_flag);
2346     assert(!Threads::includes(this),
2347            "java thread shouldn't have been published yet!");
2348   } else {
2349     assert(!Threads::includes(this),
2350            "java thread shouldn't have been published yet!");
2351   }
2352 }
2353 #endif
2354 
2355 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2356 // progress or when _suspend_flags is non-zero.
2357 // Current thread needs to self-suspend if there is a suspend request and/or
2358 // block if a safepoint is in progress.
2359 // Async exception ISN'T checked.
2360 // Note only the ThreadInVMfromNative transition can call this function
2361 // directly and when thread state is _thread_in_native_trans
2362 void JavaThread::check_safepoint_and_suspend_for_native_trans(JavaThread *thread) {
2363   assert(thread-&gt;thread_state() == _thread_in_native_trans, "wrong state");
2364 
2365   JavaThread *curJT = JavaThread::current();
2366   bool do_self_suspend = thread-&gt;is_external_suspend();
2367 
2368   assert(!curJT-&gt;has_last_Java_frame() || curJT-&gt;frame_anchor()-&gt;walkable(), "Unwalkable stack in native-&gt;vm transition");
2369 
2370   // If JNIEnv proxies are allowed, don't self-suspend if the target
2371   // thread is not the current thread. In older versions of jdbx, jdbx
2372   // threads could call into the VM with another thread's JNIEnv so we
2373   // can be here operating on behalf of a suspended thread (4432884).
2374   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || curJT == thread)) {
2375     JavaThreadState state = thread-&gt;thread_state();
2376 
2377     // We mark this thread_blocked state as a suspend-equivalent so
2378     // that a caller to is_ext_suspend_completed() won't be confused.
2379     // The suspend-equivalent state is cleared by java_suspend_self().
2380     thread-&gt;set_suspend_equivalent();
2381 
2382     // If the safepoint code sees the _thread_in_native_trans state, it will
2383     // wait until the thread changes to other thread state. There is no
2384     // guarantee on how soon we can obtain the SR_lock and complete the
2385     // self-suspend request. It would be a bad idea to let safepoint wait for
2386     // too long. Temporarily change the state to _thread_blocked to
2387     // let the VM thread know that this thread is ready for GC. The problem
2388     // of changing thread state is that safepoint could happen just after
2389     // java_suspend_self() returns after being resumed, and VM thread will
2390     // see the _thread_blocked state. We must check for safepoint
2391     // after restoring the state and make sure we won't leave while a safepoint
2392     // is in progress.
2393     thread-&gt;set_thread_state(_thread_blocked);
2394     thread-&gt;java_suspend_self();
2395     thread-&gt;set_thread_state(state);
2396     // Make sure new state is seen by VM thread
2397     if (os::is_MP()) {
2398       if (UseMembar) {
2399         // Force a fence between the write above and read below
2400         OrderAccess::fence();
2401       } else {
2402         // Must use this rather than serialization page in particular on Windows
2403         InterfaceSupport::serialize_memory(thread);
2404       }
2405     }
2406   }
2407 
2408   if (SafepointSynchronize::do_call_back()) {
2409     // If we are safepointing, then block the caller which may not be
2410     // the same as the target thread (see above).
2411     SafepointSynchronize::block(curJT);
2412   }
2413 
2414   if (thread-&gt;is_deopt_suspend()) {
2415     thread-&gt;clear_deopt_suspend();
2416     RegisterMap map(thread, false);
2417     frame f = thread-&gt;last_frame();
2418     while (f.id() != thread-&gt;must_deopt_id() &amp;&amp; ! f.is_first_frame()) {
2419       f = f.sender(&amp;map);
2420     }
2421     if (f.id() == thread-&gt;must_deopt_id()) {
2422       thread-&gt;clear_must_deopt_id();
2423       f.deoptimize(thread);
2424     } else {
2425       fatal("missed deoptimization!");
2426     }
2427   }
2428 }
2429 
2430 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2431 // progress or when _suspend_flags is non-zero.
2432 // Current thread needs to self-suspend if there is a suspend request and/or
2433 // block if a safepoint is in progress.
2434 // Also check for pending async exception (not including unsafe access error).
2435 // Note only the native==&gt;VM/Java barriers can call this function and when
2436 // thread state is _thread_in_native_trans.
2437 void JavaThread::check_special_condition_for_native_trans(JavaThread *thread) {
2438   check_safepoint_and_suspend_for_native_trans(thread);
2439 
2440   if (thread-&gt;has_async_exception()) {
2441     // We are in _thread_in_native_trans state, don't handle unsafe
2442     // access error since that may block.
2443     thread-&gt;check_and_handle_async_exceptions(false);
2444   }
2445 }
2446 
2447 // This is a variant of the normal
2448 // check_special_condition_for_native_trans with slightly different
2449 // semantics for use by critical native wrappers.  It does all the
2450 // normal checks but also performs the transition back into
2451 // thread_in_Java state.  This is required so that critical natives
2452 // can potentially block and perform a GC if they are the last thread
2453 // exiting the GCLocker.
2454 void JavaThread::check_special_condition_for_native_trans_and_transition(JavaThread *thread) {
2455   check_special_condition_for_native_trans(thread);
2456 
2457   // Finish the transition
2458   thread-&gt;set_thread_state(_thread_in_Java);
2459 
2460   if (thread-&gt;do_critical_native_unlock()) {
2461     ThreadInVMfromJavaNoAsyncException tiv(thread);
2462     GCLocker::unlock_critical(thread);
2463     thread-&gt;clear_critical_native_unlock();
2464   }
2465 }
2466 
2467 // We need to guarantee the Threads_lock here, since resumes are not
2468 // allowed during safepoint synchronization
2469 // Can only resume from an external suspension
2470 void JavaThread::java_resume() {
2471   assert_locked_or_safepoint(Threads_lock);
2472 
2473   // Sanity check: thread is gone, has started exiting or the thread
2474   // was not externally suspended.
2475   if (!Threads::includes(this) || is_exiting() || !is_external_suspend()) {
2476     return;
2477   }
2478 
2479   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2480 
2481   clear_external_suspend();
2482 
2483   if (is_ext_suspended()) {
2484     clear_ext_suspended();
2485     SR_lock()-&gt;notify_all();
2486   }
2487 }
2488 
2489 size_t JavaThread::_stack_red_zone_size = 0;
2490 size_t JavaThread::_stack_yellow_zone_size = 0;
2491 size_t JavaThread::_stack_reserved_zone_size = 0;
2492 size_t JavaThread::_stack_shadow_zone_size = 0;
2493 
2494 void JavaThread::create_stack_guard_pages() {
2495   if (!os::uses_stack_guard_pages() || _stack_guard_state != stack_guard_unused) { return; }
2496   address low_addr = stack_end();
2497   size_t len = stack_guard_zone_size();
2498 
2499   int allocate = os::allocate_stack_guard_pages();
2500   // warning("Guarding at " PTR_FORMAT " for len " SIZE_FORMAT "\n", low_addr, len);
2501 
2502   if (allocate &amp;&amp; !os::create_stack_guard_pages((char *) low_addr, len)) {
2503     log_warning(os, thread)("Attempt to allocate stack guard pages failed.");
2504     return;
2505   }
2506 
2507   if (os::guard_memory((char *) low_addr, len)) {
2508     _stack_guard_state = stack_guard_enabled;
2509   } else {
2510     log_warning(os, thread)("Attempt to protect stack guard pages failed ("
2511       PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2512     if (os::uncommit_memory((char *) low_addr, len)) {
2513       log_warning(os, thread)("Attempt to deallocate stack guard pages failed.");
2514     }
2515     return;
2516   }
2517 
2518   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages activated: "
2519     PTR_FORMAT "-" PTR_FORMAT ".",
2520     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2521 
2522 }
2523 
2524 void JavaThread::remove_stack_guard_pages() {
2525   assert(Thread::current() == this, "from different thread");
2526   if (_stack_guard_state == stack_guard_unused) return;
2527   address low_addr = stack_end();
2528   size_t len = stack_guard_zone_size();
2529 
2530   if (os::allocate_stack_guard_pages()) {
2531     if (os::remove_stack_guard_pages((char *) low_addr, len)) {
2532       _stack_guard_state = stack_guard_unused;
2533     } else {
2534       log_warning(os, thread)("Attempt to deallocate stack guard pages failed ("
2535         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2536       return;
2537     }
2538   } else {
2539     if (_stack_guard_state == stack_guard_unused) return;
2540     if (os::unguard_memory((char *) low_addr, len)) {
2541       _stack_guard_state = stack_guard_unused;
2542     } else {
2543       log_warning(os, thread)("Attempt to unprotect stack guard pages failed ("
2544         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2545       return;
2546     }
2547   }
2548 
2549   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages removed: "
2550     PTR_FORMAT "-" PTR_FORMAT ".",
2551     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2552 
2553 }
2554 
2555 void JavaThread::enable_stack_reserved_zone() {
2556   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2557   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2558 
2559   // The base notation is from the stack's point of view, growing downward.
2560   // We need to adjust it to work correctly with guard_memory()
2561   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2562 
2563   guarantee(base &lt; stack_base(),"Error calculating stack reserved zone");
2564   guarantee(base &lt; os::current_stack_pointer(),"Error calculating stack reserved zone");
2565 
2566   if (os::guard_memory((char *) base, stack_reserved_zone_size())) {
2567     _stack_guard_state = stack_guard_enabled;
2568   } else {
2569     warning("Attempt to guard stack reserved zone failed.");
2570   }
2571   enable_register_stack_guard();
2572 }
2573 
2574 void JavaThread::disable_stack_reserved_zone() {
2575   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2576   assert(_stack_guard_state != stack_guard_reserved_disabled, "already disabled");
2577 
2578   // Simply return if called for a thread that does not use guard pages.
2579   if (_stack_guard_state == stack_guard_unused) return;
2580 
2581   // The base notation is from the stack's point of view, growing downward.
2582   // We need to adjust it to work correctly with guard_memory()
2583   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2584 
2585   if (os::unguard_memory((char *)base, stack_reserved_zone_size())) {
2586     _stack_guard_state = stack_guard_reserved_disabled;
2587   } else {
2588     warning("Attempt to unguard stack reserved zone failed.");
2589   }
2590   disable_register_stack_guard();
2591 }
2592 
2593 void JavaThread::enable_stack_yellow_reserved_zone() {
2594   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2595   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2596 
2597   // The base notation is from the stacks point of view, growing downward.
2598   // We need to adjust it to work correctly with guard_memory()
2599   address base = stack_red_zone_base();
2600 
2601   guarantee(base &lt; stack_base(), "Error calculating stack yellow zone");
2602   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack yellow zone");
2603 
2604   if (os::guard_memory((char *) base, stack_yellow_reserved_zone_size())) {
2605     _stack_guard_state = stack_guard_enabled;
2606   } else {
2607     warning("Attempt to guard stack yellow zone failed.");
2608   }
2609   enable_register_stack_guard();
2610 }
2611 
2612 void JavaThread::disable_stack_yellow_reserved_zone() {
2613   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2614   assert(_stack_guard_state != stack_guard_yellow_reserved_disabled, "already disabled");
2615 
2616   // Simply return if called for a thread that does not use guard pages.
2617   if (_stack_guard_state == stack_guard_unused) return;
2618 
2619   // The base notation is from the stacks point of view, growing downward.
2620   // We need to adjust it to work correctly with guard_memory()
2621   address base = stack_red_zone_base();
2622 
2623   if (os::unguard_memory((char *)base, stack_yellow_reserved_zone_size())) {
2624     _stack_guard_state = stack_guard_yellow_reserved_disabled;
2625   } else {
2626     warning("Attempt to unguard stack yellow zone failed.");
2627   }
2628   disable_register_stack_guard();
2629 }
2630 
2631 void JavaThread::enable_stack_red_zone() {
2632   // The base notation is from the stacks point of view, growing downward.
2633   // We need to adjust it to work correctly with guard_memory()
2634   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2635   address base = stack_red_zone_base() - stack_red_zone_size();
2636 
2637   guarantee(base &lt; stack_base(), "Error calculating stack red zone");
2638   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack red zone");
2639 
2640   if (!os::guard_memory((char *) base, stack_red_zone_size())) {
2641     warning("Attempt to guard stack red zone failed.");
2642   }
2643 }
2644 
2645 void JavaThread::disable_stack_red_zone() {
2646   // The base notation is from the stacks point of view, growing downward.
2647   // We need to adjust it to work correctly with guard_memory()
2648   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2649   address base = stack_red_zone_base() - stack_red_zone_size();
2650   if (!os::unguard_memory((char *)base, stack_red_zone_size())) {
2651     warning("Attempt to unguard stack red zone failed.");
2652   }
2653 }
2654 
2655 void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {
2656   // ignore is there is no stack
2657   if (!has_last_Java_frame()) return;
2658   // traverse the stack frames. Starts from top frame.
2659   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2660     frame* fr = fst.current();
2661     f(fr, fst.register_map());
2662   }
2663 }
2664 
2665 
2666 #ifndef PRODUCT
2667 // Deoptimization
2668 // Function for testing deoptimization
2669 void JavaThread::deoptimize() {
2670   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2671   StackFrameStream fst(this, UseBiasedLocking);
2672   bool deopt = false;           // Dump stack only if a deopt actually happens.
2673   bool only_at = strlen(DeoptimizeOnlyAt) &gt; 0;
2674   // Iterate over all frames in the thread and deoptimize
2675   for (; !fst.is_done(); fst.next()) {
2676     if (fst.current()-&gt;can_be_deoptimized()) {
2677 
2678       if (only_at) {
2679         // Deoptimize only at particular bcis.  DeoptimizeOnlyAt
2680         // consists of comma or carriage return separated numbers so
2681         // search for the current bci in that string.
2682         address pc = fst.current()-&gt;pc();
2683         nmethod* nm =  (nmethod*) fst.current()-&gt;cb();
2684         ScopeDesc* sd = nm-&gt;scope_desc_at(pc);
2685         char buffer[8];
2686         jio_snprintf(buffer, sizeof(buffer), "%d", sd-&gt;bci());
2687         size_t len = strlen(buffer);
2688         const char * found = strstr(DeoptimizeOnlyAt, buffer);
2689         while (found != NULL) {
2690           if ((found[len] == ',' || found[len] == '\n' || found[len] == '\0') &amp;&amp;
2691               (found == DeoptimizeOnlyAt || found[-1] == ',' || found[-1] == '\n')) {
2692             // Check that the bci found is bracketed by terminators.
2693             break;
2694           }
2695           found = strstr(found + 1, buffer);
2696         }
2697         if (!found) {
2698           continue;
2699         }
2700       }
2701 
2702       if (DebugDeoptimization &amp;&amp; !deopt) {
2703         deopt = true; // One-time only print before deopt
2704         tty-&gt;print_cr("[BEFORE Deoptimization]");
2705         trace_frames();
2706         trace_stack();
2707       }
2708       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2709     }
2710   }
2711 
2712   if (DebugDeoptimization &amp;&amp; deopt) {
2713     tty-&gt;print_cr("[AFTER Deoptimization]");
2714     trace_frames();
2715   }
2716 }
2717 
2718 
2719 // Make zombies
2720 void JavaThread::make_zombies() {
2721   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2722     if (fst.current()-&gt;can_be_deoptimized()) {
2723       // it is a Java nmethod
2724       nmethod* nm = CodeCache::find_nmethod(fst.current()-&gt;pc());
2725       nm-&gt;make_not_entrant();
2726     }
2727   }
2728 }
2729 #endif // PRODUCT
2730 
2731 
2732 void JavaThread::deoptimized_wrt_marked_nmethods() {
2733   if (!has_last_Java_frame()) return;
2734   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2735   StackFrameStream fst(this, UseBiasedLocking);
2736   for (; !fst.is_done(); fst.next()) {
2737     if (fst.current()-&gt;should_be_deoptimized()) {
2738       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2739     }
2740   }
2741 }
2742 
2743 
2744 // If the caller is a NamedThread, then remember, in the current scope,
2745 // the given JavaThread in its _processed_thread field.
2746 class RememberProcessedThread: public StackObj {
2747   NamedThread* _cur_thr;
2748  public:
2749   RememberProcessedThread(JavaThread* jthr) {
2750     Thread* thread = Thread::current();
2751     if (thread-&gt;is_Named_thread()) {
2752       _cur_thr = (NamedThread *)thread;
2753       _cur_thr-&gt;set_processed_thread(jthr);
2754     } else {
2755       _cur_thr = NULL;
2756     }
2757   }
2758 
2759   ~RememberProcessedThread() {
2760     if (_cur_thr) {
2761       _cur_thr-&gt;set_processed_thread(NULL);
2762     }
2763   }
2764 };
2765 
2766 void JavaThread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
2767   // Verify that the deferred card marks have been flushed.
2768   assert(deferred_card_mark().is_empty(), "Should be empty during GC");
2769 
2770   // The ThreadProfiler oops_do is done from FlatProfiler::oops_do
2771   // since there may be more than one thread using each ThreadProfiler.
2772 
2773   // Traverse the GCHandles
2774   Thread::oops_do(f, cld_f, cf);
2775 
2776   JVMCI_ONLY(f-&gt;do_oop((oop*)&amp;_pending_failed_speculation);)
2777 
2778   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2779          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2780 
2781   if (has_last_Java_frame()) {
2782     // Record JavaThread to GC thread
2783     RememberProcessedThread rpt(this);
2784 
2785     // Traverse the privileged stack
2786     if (_privileged_stack_top != NULL) {
2787       _privileged_stack_top-&gt;oops_do(f);
2788     }
2789 
2790     // traverse the registered growable array
2791     if (_array_for_gc != NULL) {
2792       for (int index = 0; index &lt; _array_for_gc-&gt;length(); index++) {
2793         f-&gt;do_oop(_array_for_gc-&gt;adr_at(index));
2794       }
2795     }
2796 
2797     // Traverse the monitor chunks
2798     for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2799       chunk-&gt;oops_do(f);
2800     }
2801 
2802     // Traverse the execution stack
2803     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2804       fst.current()-&gt;oops_do(f, cld_f, cf, fst.register_map());
2805     }
2806   }
2807 
2808   // callee_target is never live across a gc point so NULL it here should
2809   // it still contain a methdOop.
2810 
2811   set_callee_target(NULL);
2812 
2813   assert(vframe_array_head() == NULL, "deopt in progress at a safepoint!");
2814   // If we have deferred set_locals there might be oops waiting to be
2815   // written
2816   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* list = deferred_locals();
2817   if (list != NULL) {
2818     for (int i = 0; i &lt; list-&gt;length(); i++) {
2819       list-&gt;at(i)-&gt;oops_do(f);
2820     }
2821   }
2822 
2823   // Traverse instance variables at the end since the GC may be moving things
2824   // around using this function
2825   f-&gt;do_oop((oop*) &amp;_threadObj);
2826   f-&gt;do_oop((oop*) &amp;_vm_result);
2827   f-&gt;do_oop((oop*) &amp;_exception_oop);
2828   f-&gt;do_oop((oop*) &amp;_pending_async_exception);
2829 
2830   if (jvmti_thread_state() != NULL) {
2831     jvmti_thread_state()-&gt;oops_do(f);
2832   }
2833 }
2834 
2835 void JavaThread::nmethods_do(CodeBlobClosure* cf) {
2836   Thread::nmethods_do(cf);  // (super method is a no-op)
2837 
2838   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2839          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2840 
2841   if (has_last_Java_frame()) {
2842     // Traverse the execution stack
2843     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2844       fst.current()-&gt;nmethods_do(cf);
2845     }
2846   }
2847 }
2848 
2849 void JavaThread::metadata_do(void f(Metadata*)) {
2850   if (has_last_Java_frame()) {
2851     // Traverse the execution stack to call f() on the methods in the stack
2852     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2853       fst.current()-&gt;metadata_do(f);
2854     }
2855   } else if (is_Compiler_thread()) {
2856     // need to walk ciMetadata in current compile tasks to keep alive.
2857     CompilerThread* ct = (CompilerThread*)this;
2858     if (ct-&gt;env() != NULL) {
2859       ct-&gt;env()-&gt;metadata_do(f);
2860     }
2861     if (ct-&gt;task() != NULL) {
2862       ct-&gt;task()-&gt;metadata_do(f);
2863     }
2864   }
2865 }
2866 
2867 // Printing
2868 const char* _get_thread_state_name(JavaThreadState _thread_state) {
2869   switch (_thread_state) {
2870   case _thread_uninitialized:     return "_thread_uninitialized";
2871   case _thread_new:               return "_thread_new";
2872   case _thread_new_trans:         return "_thread_new_trans";
2873   case _thread_in_native:         return "_thread_in_native";
2874   case _thread_in_native_trans:   return "_thread_in_native_trans";
2875   case _thread_in_vm:             return "_thread_in_vm";
2876   case _thread_in_vm_trans:       return "_thread_in_vm_trans";
2877   case _thread_in_Java:           return "_thread_in_Java";
2878   case _thread_in_Java_trans:     return "_thread_in_Java_trans";
2879   case _thread_blocked:           return "_thread_blocked";
2880   case _thread_blocked_trans:     return "_thread_blocked_trans";
2881   default:                        return "unknown thread state";
2882   }
2883 }
2884 
2885 #ifndef PRODUCT
2886 void JavaThread::print_thread_state_on(outputStream *st) const {
2887   st-&gt;print_cr("   JavaThread state: %s", _get_thread_state_name(_thread_state));
2888 };
2889 void JavaThread::print_thread_state() const {
2890   print_thread_state_on(tty);
2891 }
2892 #endif // PRODUCT
2893 
2894 // Called by Threads::print() for VM_PrintThreads operation
2895 void JavaThread::print_on(outputStream *st) const {
2896   st-&gt;print("\"%s\" ", get_thread_name());
2897   oop thread_oop = threadObj();
2898   if (thread_oop != NULL) {
2899     st-&gt;print("#" INT64_FORMAT " ", java_lang_Thread::thread_id(thread_oop));
2900     if (java_lang_Thread::is_daemon(thread_oop))  st-&gt;print("daemon ");
2901     st-&gt;print("prio=%d ", java_lang_Thread::priority(thread_oop));
2902   }
2903   Thread::print_on(st);
2904   // print guess for valid stack memory region (assume 4K pages); helps lock debugging
2905   st-&gt;print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &amp; ~right_n_bits(12));
2906   if (thread_oop != NULL) {
2907     st-&gt;print_cr("   java.lang.Thread.State: %s", java_lang_Thread::thread_status_name(thread_oop));
2908   }
2909 #ifndef PRODUCT
2910   print_thread_state_on(st);
2911   _safepoint_state-&gt;print_on(st);
2912 #endif // PRODUCT
2913   if (is_Compiler_thread()) {
2914     CompilerThread* ct = (CompilerThread*)this;
2915     if (ct-&gt;task() != NULL) {
2916       st-&gt;print("   Compiling: ");
2917       ct-&gt;task()-&gt;print(st, NULL, true, false);
2918     } else {
2919       st-&gt;print("   No compile task");
2920     }
2921     st-&gt;cr();
2922   }
2923 }
2924 
2925 void JavaThread::print_name_on_error(outputStream* st, char *buf, int buflen) const {
2926   st-&gt;print("%s", get_thread_name_string(buf, buflen));
2927 }
2928 
2929 // Called by fatal error handler. The difference between this and
2930 // JavaThread::print() is that we can't grab lock or allocate memory.
2931 void JavaThread::print_on_error(outputStream* st, char *buf, int buflen) const {
2932   st-&gt;print("JavaThread \"%s\"", get_thread_name_string(buf, buflen));
2933   oop thread_obj = threadObj();
2934   if (thread_obj != NULL) {
2935     if (java_lang_Thread::is_daemon(thread_obj)) st-&gt;print(" daemon");
2936   }
2937   st-&gt;print(" [");
2938   st-&gt;print("%s", _get_thread_state_name(_thread_state));
2939   if (osthread()) {
2940     st-&gt;print(", id=%d", osthread()-&gt;thread_id());
2941   }
2942   st-&gt;print(", stack(" PTR_FORMAT "," PTR_FORMAT ")",
2943             p2i(stack_end()), p2i(stack_base()));
2944   st-&gt;print("]");
2945   return;
2946 }
2947 
2948 // Verification
2949 
2950 static void frame_verify(frame* f, const RegisterMap *map) { f-&gt;verify(map); }
2951 
2952 void JavaThread::verify() {
2953   // Verify oops in the thread.
2954   oops_do(&amp;VerifyOopClosure::verify_oop, NULL, NULL);
2955 
2956   // Verify the stack frames.
2957   frames_do(frame_verify);
2958 }
2959 
2960 // CR 6300358 (sub-CR 2137150)
2961 // Most callers of this method assume that it can't return NULL but a
2962 // thread may not have a name whilst it is in the process of attaching to
2963 // the VM - see CR 6412693, and there are places where a JavaThread can be
2964 // seen prior to having it's threadObj set (eg JNI attaching threads and
2965 // if vm exit occurs during initialization). These cases can all be accounted
2966 // for such that this method never returns NULL.
2967 const char* JavaThread::get_thread_name() const {
2968 #ifdef ASSERT
2969   // early safepoints can hit while current thread does not yet have TLS
2970   if (!SafepointSynchronize::is_at_safepoint()) {
2971     Thread *cur = Thread::current();
2972     if (!(cur-&gt;is_Java_thread() &amp;&amp; cur == this)) {
2973       // Current JavaThreads are allowed to get their own name without
2974       // the Threads_lock.
2975       assert_locked_or_safepoint(Threads_lock);
2976     }
2977   }
2978 #endif // ASSERT
2979   return get_thread_name_string();
2980 }
2981 
2982 // Returns a non-NULL representation of this thread's name, or a suitable
2983 // descriptive string if there is no set name
2984 const char* JavaThread::get_thread_name_string(char* buf, int buflen) const {
2985   const char* name_str;
2986   oop thread_obj = threadObj();
2987   if (thread_obj != NULL) {
2988     oop name = java_lang_Thread::name(thread_obj);
2989     if (name != NULL) {
2990       if (buf == NULL) {
2991         name_str = java_lang_String::as_utf8_string(name);
2992       } else {
2993         name_str = java_lang_String::as_utf8_string(name, buf, buflen);
2994       }
2995     } else if (is_attaching_via_jni()) { // workaround for 6412693 - see 6404306
2996       name_str = "&lt;no-name - thread is attaching&gt;";
2997     } else {
2998       name_str = Thread::name();
2999     }
3000   } else {
3001     name_str = Thread::name();
3002   }
3003   assert(name_str != NULL, "unexpected NULL thread name");
3004   return name_str;
3005 }
3006 
3007 
3008 const char* JavaThread::get_threadgroup_name() const {
3009   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3010   oop thread_obj = threadObj();
3011   if (thread_obj != NULL) {
3012     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3013     if (thread_group != NULL) {
3014       // ThreadGroup.name can be null
3015       return java_lang_ThreadGroup::name(thread_group);
3016     }
3017   }
3018   return NULL;
3019 }
3020 
3021 const char* JavaThread::get_parent_name() const {
3022   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3023   oop thread_obj = threadObj();
3024   if (thread_obj != NULL) {
3025     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3026     if (thread_group != NULL) {
3027       oop parent = java_lang_ThreadGroup::parent(thread_group);
3028       if (parent != NULL) {
3029         // ThreadGroup.name can be null
3030         return java_lang_ThreadGroup::name(parent);
3031       }
3032     }
3033   }
3034   return NULL;
3035 }
3036 
3037 ThreadPriority JavaThread::java_priority() const {
3038   oop thr_oop = threadObj();
3039   if (thr_oop == NULL) return NormPriority; // Bootstrapping
3040   ThreadPriority priority = java_lang_Thread::priority(thr_oop);
3041   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "sanity check");
3042   return priority;
3043 }
3044 
3045 void JavaThread::prepare(jobject jni_thread, ThreadPriority prio) {
3046 
3047   assert(Threads_lock-&gt;owner() == Thread::current(), "must have threads lock");
3048   // Link Java Thread object &lt;-&gt; C++ Thread
3049 
3050   // Get the C++ thread object (an oop) from the JNI handle (a jthread)
3051   // and put it into a new Handle.  The Handle "thread_oop" can then
3052   // be used to pass the C++ thread object to other methods.
3053 
3054   // Set the Java level thread object (jthread) field of the
3055   // new thread (a JavaThread *) to C++ thread object using the
3056   // "thread_oop" handle.
3057 
3058   // Set the thread field (a JavaThread *) of the
3059   // oop representing the java_lang_Thread to the new thread (a JavaThread *).
3060 
3061   Handle thread_oop(Thread::current(),
3062                     JNIHandles::resolve_non_null(jni_thread));
3063   assert(InstanceKlass::cast(thread_oop-&gt;klass())-&gt;is_linked(),
3064          "must be initialized");
3065   set_threadObj(thread_oop());
3066   java_lang_Thread::set_thread(thread_oop(), this);
3067 
3068   if (prio == NoPriority) {
3069     prio = java_lang_Thread::priority(thread_oop());
3070     assert(prio != NoPriority, "A valid priority should be present");
3071   }
3072 
3073   // Push the Java priority down to the native thread; needs Threads_lock
3074   Thread::set_priority(this, prio);
3075 
3076   prepare_ext();
3077 
3078   // Add the new thread to the Threads list and set it in motion.
3079   // We must have threads lock in order to call Threads::add.
3080   // It is crucial that we do not block before the thread is
3081   // added to the Threads list for if a GC happens, then the java_thread oop
3082   // will not be visited by GC.
3083   Threads::add(this);
3084 }
3085 
3086 oop JavaThread::current_park_blocker() {
3087   // Support for JSR-166 locks
3088   oop thread_oop = threadObj();
3089   if (thread_oop != NULL &amp;&amp;
3090       JDK_Version::current().supports_thread_park_blocker()) {
3091     return java_lang_Thread::park_blocker(thread_oop);
3092   }
3093   return NULL;
3094 }
3095 
3096 
3097 void JavaThread::print_stack_on(outputStream* st) {
3098   if (!has_last_Java_frame()) return;
3099   ResourceMark rm;
3100   HandleMark   hm;
3101 
3102   RegisterMap reg_map(this);
3103   vframe* start_vf = last_java_vframe(&amp;reg_map);
3104   int count = 0;
3105   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3106     if (f-&gt;is_java_frame()) {
3107       javaVFrame* jvf = javaVFrame::cast(f);
3108       java_lang_Throwable::print_stack_element(st, jvf-&gt;method(), jvf-&gt;bci());
3109 
3110       // Print out lock information
3111       if (JavaMonitorsInStackTrace) {
3112         jvf-&gt;print_lock_info_on(st, count);
3113       }
3114     } else {
3115       // Ignore non-Java frames
3116     }
3117 
3118     // Bail-out case for too deep stacks
3119     count++;
3120     if (MaxJavaStackTraceDepth == count) return;
3121   }
3122 }
3123 
3124 
3125 // JVMTI PopFrame support
3126 void JavaThread::popframe_preserve_args(ByteSize size_in_bytes, void* start) {
3127   assert(_popframe_preserved_args == NULL, "should not wipe out old PopFrame preserved arguments");
3128   if (in_bytes(size_in_bytes) != 0) {
3129     _popframe_preserved_args = NEW_C_HEAP_ARRAY(char, in_bytes(size_in_bytes), mtThread);
3130     _popframe_preserved_args_size = in_bytes(size_in_bytes);
3131     Copy::conjoint_jbytes(start, _popframe_preserved_args, _popframe_preserved_args_size);
3132   }
3133 }
3134 
3135 void* JavaThread::popframe_preserved_args() {
3136   return _popframe_preserved_args;
3137 }
3138 
3139 ByteSize JavaThread::popframe_preserved_args_size() {
3140   return in_ByteSize(_popframe_preserved_args_size);
3141 }
3142 
3143 WordSize JavaThread::popframe_preserved_args_size_in_words() {
3144   int sz = in_bytes(popframe_preserved_args_size());
3145   assert(sz % wordSize == 0, "argument size must be multiple of wordSize");
3146   return in_WordSize(sz / wordSize);
3147 }
3148 
3149 void JavaThread::popframe_free_preserved_args() {
3150   assert(_popframe_preserved_args != NULL, "should not free PopFrame preserved arguments twice");
3151   FREE_C_HEAP_ARRAY(char, (char*) _popframe_preserved_args);
3152   _popframe_preserved_args = NULL;
3153   _popframe_preserved_args_size = 0;
3154 }
3155 
3156 #ifndef PRODUCT
3157 
3158 void JavaThread::trace_frames() {
3159   tty-&gt;print_cr("[Describe stack]");
3160   int frame_no = 1;
3161   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
3162     tty-&gt;print("  %d. ", frame_no++);
3163     fst.current()-&gt;print_value_on(tty, this);
3164     tty-&gt;cr();
3165   }
3166 }
3167 
3168 class PrintAndVerifyOopClosure: public OopClosure {
3169  protected:
3170   template &lt;class T&gt; inline void do_oop_work(T* p) {
3171     oop obj = oopDesc::load_decode_heap_oop(p);
3172     if (obj == NULL) return;
3173     tty-&gt;print(INTPTR_FORMAT ": ", p2i(p));
3174     if (obj-&gt;is_oop_or_null()) {
3175       if (obj-&gt;is_objArray()) {
3176         tty-&gt;print_cr("valid objArray: " INTPTR_FORMAT, p2i(obj));
3177       } else {
3178         obj-&gt;print();
3179       }
3180     } else {
3181       tty-&gt;print_cr("invalid oop: " INTPTR_FORMAT, p2i(obj));
3182     }
3183     tty-&gt;cr();
3184   }
3185  public:
3186   virtual void do_oop(oop* p) { do_oop_work(p); }
3187   virtual void do_oop(narrowOop* p)  { do_oop_work(p); }
3188 };
3189 
3190 
3191 static void oops_print(frame* f, const RegisterMap *map) {
3192   PrintAndVerifyOopClosure print;
3193   f-&gt;print_value();
3194   f-&gt;oops_do(&amp;print, NULL, NULL, (RegisterMap*)map);
3195 }
3196 
3197 // Print our all the locations that contain oops and whether they are
3198 // valid or not.  This useful when trying to find the oldest frame
3199 // where an oop has gone bad since the frame walk is from youngest to
3200 // oldest.
3201 void JavaThread::trace_oops() {
3202   tty-&gt;print_cr("[Trace oops]");
3203   frames_do(oops_print);
3204 }
3205 
3206 
3207 #ifdef ASSERT
3208 // Print or validate the layout of stack frames
3209 void JavaThread::print_frame_layout(int depth, bool validate_only) {
3210   ResourceMark rm;
3211   PRESERVE_EXCEPTION_MARK;
3212   FrameValues values;
3213   int frame_no = 0;
3214   for (StackFrameStream fst(this, false); !fst.is_done(); fst.next()) {
3215     fst.current()-&gt;describe(values, ++frame_no);
3216     if (depth == frame_no) break;
3217   }
3218   if (validate_only) {
3219     values.validate();
3220   } else {
3221     tty-&gt;print_cr("[Describe stack layout]");
3222     values.print(this);
3223   }
3224 }
3225 #endif
3226 
3227 void JavaThread::trace_stack_from(vframe* start_vf) {
3228   ResourceMark rm;
3229   int vframe_no = 1;
3230   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3231     if (f-&gt;is_java_frame()) {
3232       javaVFrame::cast(f)-&gt;print_activation(vframe_no++);
3233     } else {
3234       f-&gt;print();
3235     }
3236     if (vframe_no &gt; StackPrintLimit) {
3237       tty-&gt;print_cr("...&lt;more frames&gt;...");
3238       return;
3239     }
3240   }
3241 }
3242 
3243 
3244 void JavaThread::trace_stack() {
3245   if (!has_last_Java_frame()) return;
3246   ResourceMark rm;
3247   HandleMark   hm;
3248   RegisterMap reg_map(this);
3249   trace_stack_from(last_java_vframe(&amp;reg_map));
3250 }
3251 
3252 
3253 #endif // PRODUCT
3254 
3255 
3256 javaVFrame* JavaThread::last_java_vframe(RegisterMap *reg_map) {
3257   assert(reg_map != NULL, "a map must be given");
3258   frame f = last_frame();
3259   for (vframe* vf = vframe::new_vframe(&amp;f, reg_map, this); vf; vf = vf-&gt;sender()) {
3260     if (vf-&gt;is_java_frame()) return javaVFrame::cast(vf);
3261   }
3262   return NULL;
3263 }
3264 
3265 
3266 Klass* JavaThread::security_get_caller_class(int depth) {
3267   vframeStream vfst(this);
3268   vfst.security_get_caller_frame(depth);
3269   if (!vfst.at_end()) {
3270     return vfst.method()-&gt;method_holder();
3271   }
3272   return NULL;
3273 }
3274 
3275 static void compiler_thread_entry(JavaThread* thread, TRAPS) {
3276   assert(thread-&gt;is_Compiler_thread(), "must be compiler thread");
3277   CompileBroker::compiler_thread_loop();
3278 }
3279 
3280 static void sweeper_thread_entry(JavaThread* thread, TRAPS) {
3281   NMethodSweeper::sweeper_loop();
3282 }
3283 
3284 // Create a CompilerThread
3285 CompilerThread::CompilerThread(CompileQueue* queue,
3286                                CompilerCounters* counters)
3287                                : JavaThread(&amp;compiler_thread_entry) {
3288   _env   = NULL;
3289   _log   = NULL;
3290   _task  = NULL;
3291   _queue = queue;
3292   _counters = counters;
3293   _buffer_blob = NULL;
3294   _compiler = NULL;
3295 
3296 #ifndef PRODUCT
3297   _ideal_graph_printer = NULL;
3298 #endif
3299 }
3300 
3301 bool CompilerThread::can_call_java() const {
3302   return _compiler != NULL &amp;&amp; _compiler-&gt;is_jvmci();
3303 }
3304 
3305 // Create sweeper thread
3306 CodeCacheSweeperThread::CodeCacheSweeperThread()
3307 : JavaThread(&amp;sweeper_thread_entry) {
3308   _scanned_nmethod = NULL;
3309 }
3310 void CodeCacheSweeperThread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
3311   JavaThread::oops_do(f, cld_f, cf);
3312   if (_scanned_nmethod != NULL &amp;&amp; cf != NULL) {
3313     // Safepoints can occur when the sweeper is scanning an nmethod so
3314     // process it here to make sure it isn't unloaded in the middle of
3315     // a scan.
3316     cf-&gt;do_code_blob(_scanned_nmethod);
3317   }
3318 }
3319 
3320 
3321 // ======= Threads ========
3322 
3323 // The Threads class links together all active threads, and provides
3324 // operations over all threads.  It is protected by its own Mutex
3325 // lock, which is also used in other contexts to protect thread
3326 // operations from having the thread being operated on from exiting
3327 // and going away unexpectedly (e.g., safepoint synchronization)
3328 
3329 JavaThread* Threads::_thread_list = NULL;
3330 int         Threads::_number_of_threads = 0;
3331 int         Threads::_number_of_non_daemon_threads = 0;
3332 int         Threads::_return_code = 0;
3333 int         Threads::_thread_claim_parity = 0;
3334 size_t      JavaThread::_stack_size_at_create = 0;
3335 #ifdef ASSERT
3336 bool        Threads::_vm_complete = false;
3337 #endif
3338 
3339 // All JavaThreads
3340 #define ALL_JAVA_THREADS(X) for (JavaThread* X = _thread_list; X; X = X-&gt;next())
3341 
3342 // All JavaThreads + all non-JavaThreads (i.e., every thread in the system)
3343 void Threads::threads_do(ThreadClosure* tc) {
3344   assert_locked_or_safepoint(Threads_lock);
3345   // ALL_JAVA_THREADS iterates through all JavaThreads
3346   ALL_JAVA_THREADS(p) {
3347     tc-&gt;do_thread(p);
3348   }
3349   // Someday we could have a table or list of all non-JavaThreads.
3350   // For now, just manually iterate through them.
3351   tc-&gt;do_thread(VMThread::vm_thread());
3352   Universe::heap()-&gt;gc_threads_do(tc);
3353   WatcherThread *wt = WatcherThread::watcher_thread();
3354   // Strictly speaking, the following NULL check isn't sufficient to make sure
3355   // the data for WatcherThread is still valid upon being examined. However,
3356   // considering that WatchThread terminates when the VM is on the way to
3357   // exit at safepoint, the chance of the above is extremely small. The right
3358   // way to prevent termination of WatcherThread would be to acquire
3359   // Terminator_lock, but we can't do that without violating the lock rank
3360   // checking in some cases.
3361   if (wt != NULL) {
3362     tc-&gt;do_thread(wt);
3363   }
3364 
3365   // If CompilerThreads ever become non-JavaThreads, add them here
3366 }
3367 
3368 void Threads::initialize_java_lang_classes(JavaThread* main_thread, TRAPS) {
3369   TraceStartupTime timer("Initialize java.lang classes");
3370 
3371   if (EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3372     create_vm_init_libraries();
3373   }
3374 
3375   initialize_class(vmSymbols::java_lang_String(), CHECK);
3376 
3377   // Inject CompactStrings value after the static initializers for String ran.
3378   java_lang_String::set_compact_strings(CompactStrings);
3379 
3380   // Initialize java_lang.System (needed before creating the thread)
3381   initialize_class(vmSymbols::java_lang_System(), CHECK);
3382   // The VM creates &amp; returns objects of this class. Make sure it's initialized.
3383   initialize_class(vmSymbols::java_lang_Class(), CHECK);
3384   initialize_class(vmSymbols::java_lang_ThreadGroup(), CHECK);
3385   Handle thread_group = create_initial_thread_group(CHECK);
3386   Universe::set_main_thread_group(thread_group());
3387   initialize_class(vmSymbols::java_lang_Thread(), CHECK);
3388   oop thread_object = create_initial_thread(thread_group, main_thread, CHECK);
3389   main_thread-&gt;set_threadObj(thread_object);
3390   // Set thread status to running since main thread has
3391   // been started and running.
3392   java_lang_Thread::set_thread_status(thread_object,
3393                                       java_lang_Thread::RUNNABLE);
3394 
3395   // The VM preresolves methods to these classes. Make sure that they get initialized
3396   initialize_class(vmSymbols::java_lang_reflect_Method(), CHECK);
3397   initialize_class(vmSymbols::java_lang_ref_Finalizer(), CHECK);
3398   call_initializeSystemClass(CHECK);
3399 
3400   // get the Java runtime name after java.lang.System is initialized
3401   JDK_Version::set_runtime_name(get_java_runtime_name(THREAD));
3402   JDK_Version::set_runtime_version(get_java_runtime_version(THREAD));
3403 
3404   // an instance of OutOfMemory exception has been allocated earlier
3405   initialize_class(vmSymbols::java_lang_OutOfMemoryError(), CHECK);
3406   initialize_class(vmSymbols::java_lang_NullPointerException(), CHECK);
3407   initialize_class(vmSymbols::java_lang_ClassCastException(), CHECK);
3408   initialize_class(vmSymbols::java_lang_ArrayStoreException(), CHECK);
3409   initialize_class(vmSymbols::java_lang_ArithmeticException(), CHECK);
3410   initialize_class(vmSymbols::java_lang_StackOverflowError(), CHECK);
3411   initialize_class(vmSymbols::java_lang_IllegalMonitorStateException(), CHECK);
3412   initialize_class(vmSymbols::java_lang_IllegalArgumentException(), CHECK);
3413 }
3414 
3415 void Threads::initialize_jsr292_core_classes(TRAPS) {
3416   TraceStartupTime timer("Initialize java.lang.invoke classes");
3417 
3418   initialize_class(vmSymbols::java_lang_invoke_MethodHandle(), CHECK);
3419   initialize_class(vmSymbols::java_lang_invoke_MemberName(), CHECK);
3420   initialize_class(vmSymbols::java_lang_invoke_MethodHandleNatives(), CHECK);
3421 }
3422 
3423 jint Threads::create_vm(JavaVMInitArgs* args, bool* canTryAgain) {
3424   extern void JDK_Version_init();
3425 
3426   // Preinitialize version info.
3427   VM_Version::early_initialize();
3428 
3429   // Check version
3430   if (!is_supported_jni_version(args-&gt;version)) return JNI_EVERSION;
3431 
3432   // Initialize library-based TLS
3433   ThreadLocalStorage::init();
3434 
3435   // Initialize the output stream module
3436   ostream_init();
3437 
3438   // Process java launcher properties.
3439   Arguments::process_sun_java_launcher_properties(args);
3440 
3441   // Initialize the os module
3442   os::init();
3443 
3444   // Record VM creation timing statistics
3445   TraceVmCreationTime create_vm_timer;
3446   create_vm_timer.start();
3447 
3448   // Initialize system properties.
3449   Arguments::init_system_properties();
3450 
3451   // So that JDK version can be used as a discriminator when parsing arguments
3452   JDK_Version_init();
3453 
3454   // Update/Initialize System properties after JDK version number is known
3455   Arguments::init_version_specific_system_properties();
3456 
3457   // Make sure to initialize log configuration *before* parsing arguments
3458   LogConfiguration::initialize(create_vm_timer.begin_time());
3459 
3460   // Parse arguments
3461   jint parse_result = Arguments::parse(args);
3462   if (parse_result != JNI_OK) return parse_result;
3463 
3464   os::init_before_ergo();
3465 
3466   jint ergo_result = Arguments::apply_ergo();
3467   if (ergo_result != JNI_OK) return ergo_result;
3468 
3469   // Final check of all ranges after ergonomics which may change values.
3470   if (!CommandLineFlagRangeList::check_ranges()) {
3471     return JNI_EINVAL;
3472   }
3473 
3474   // Final check of all 'AfterErgo' constraints after ergonomics which may change values.
3475   bool constraint_result = CommandLineFlagConstraintList::check_constraints(CommandLineFlagConstraint::AfterErgo);
3476   if (!constraint_result) {
3477     return JNI_EINVAL;
3478   }
3479 
3480   if (PauseAtStartup) {
3481     os::pause();
3482   }
3483 
3484   HOTSPOT_VM_INIT_BEGIN();
3485 
3486   // Timing (must come after argument parsing)
3487   TraceStartupTime timer("Create VM");
3488 
3489   // Initialize the os module after parsing the args
3490   jint os_init_2_result = os::init_2();
3491   if (os_init_2_result != JNI_OK) return os_init_2_result;
3492 
3493   jint adjust_after_os_result = Arguments::adjust_after_os();
3494   if (adjust_after_os_result != JNI_OK) return adjust_after_os_result;
3495 
3496   // Initialize output stream logging
3497   ostream_init_log();
3498 
3499   // Convert -Xrun to -agentlib: if there is no JVM_OnLoad
3500   // Must be before create_vm_init_agents()
3501   if (Arguments::init_libraries_at_startup()) {
3502     convert_vm_init_libraries_to_agents();
3503   }
3504 
3505   // Launch -agentlib/-agentpath and converted -Xrun agents
3506   if (Arguments::init_agents_at_startup()) {
3507     create_vm_init_agents();
3508   }
3509 
3510   // Initialize Threads state
3511   _thread_list = NULL;
3512   _number_of_threads = 0;
3513   _number_of_non_daemon_threads = 0;
3514 
3515   // Initialize global data structures and create system classes in heap
3516   vm_init_globals();
3517 
3518 #if INCLUDE_JVMCI
3519   if (JVMCICounterSize &gt; 0) {
3520     JavaThread::_jvmci_old_thread_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
3521     memset(JavaThread::_jvmci_old_thread_counters, 0, sizeof(jlong) * JVMCICounterSize);
3522   } else {
3523     JavaThread::_jvmci_old_thread_counters = NULL;
3524   }
3525 #endif // INCLUDE_JVMCI
3526 
3527   // Attach the main thread to this os thread
3528   JavaThread* main_thread = new JavaThread();
3529   main_thread-&gt;set_thread_state(_thread_in_vm);
3530   main_thread-&gt;initialize_thread_current();
3531   // must do this before set_active_handles
3532   main_thread-&gt;record_stack_base_and_size();
3533   main_thread-&gt;set_active_handles(JNIHandleBlock::allocate_block());
3534 
3535   if (!main_thread-&gt;set_as_starting_thread()) {
3536     vm_shutdown_during_initialization(
3537                                       "Failed necessary internal allocation. Out of swap space");
3538     delete main_thread;
3539     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3540     return JNI_ENOMEM;
3541   }
3542 
3543   // Enable guard page *after* os::create_main_thread(), otherwise it would
3544   // crash Linux VM, see notes in os_linux.cpp.
3545   main_thread-&gt;create_stack_guard_pages();
3546 
3547   // Initialize Java-Level synchronization subsystem
3548   ObjectMonitor::Initialize();
3549 
3550   // Initialize global modules
3551   jint status = init_globals();
3552   if (status != JNI_OK) {
3553     delete main_thread;
3554     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3555     return status;
3556   }
3557 
3558   if (TRACE_INITIALIZE() != JNI_OK) {
3559     vm_exit_during_initialization("Failed to initialize tracing backend");
3560   }
3561 
3562   // Should be done after the heap is fully created
3563   main_thread-&gt;cache_global_variables();
3564 
3565   HandleMark hm;
3566 
3567   { MutexLocker mu(Threads_lock);
3568     Threads::add(main_thread);
3569   }
3570 
3571   // Any JVMTI raw monitors entered in onload will transition into
3572   // real raw monitor. VM is setup enough here for raw monitor enter.
3573   JvmtiExport::transition_pending_onload_raw_monitors();
3574 
3575   // Create the VMThread
3576   { TraceStartupTime timer("Start VMThread");
3577 
3578   VMThread::create();
3579     Thread* vmthread = VMThread::vm_thread();
3580 
3581     if (!os::create_thread(vmthread, os::vm_thread)) {
3582       vm_exit_during_initialization("Cannot create VM thread. "
3583                                     "Out of system resources.");
3584     }
3585 
3586     // Wait for the VM thread to become ready, and VMThread::run to initialize
3587     // Monitors can have spurious returns, must always check another state flag
3588     {
3589       MutexLocker ml(Notify_lock);
3590       os::start_thread(vmthread);
3591       while (vmthread-&gt;active_handles() == NULL) {
3592         Notify_lock-&gt;wait();
3593       }
3594     }
3595   }
3596 
3597   assert(Universe::is_fully_initialized(), "not initialized");
3598   if (VerifyDuringStartup) {
3599     // Make sure we're starting with a clean slate.
3600     VM_Verify verify_op;
3601     VMThread::execute(&amp;verify_op);
3602   }
3603 
3604   Thread* THREAD = Thread::current();
3605 
3606   // At this point, the Universe is initialized, but we have not executed
3607   // any byte code.  Now is a good time (the only time) to dump out the
3608   // internal state of the JVM for sharing.
3609   if (DumpSharedSpaces) {
3610     MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);
3611     ShouldNotReachHere();
3612   }
3613 
3614   // Always call even when there are not JVMTI environments yet, since environments
3615   // may be attached late and JVMTI must track phases of VM execution
3616   JvmtiExport::enter_start_phase();
3617 
3618   // Notify JVMTI agents that VM has started (JNI is up) - nop if no agents.
3619   JvmtiExport::post_vm_start();
3620 
3621   initialize_java_lang_classes(main_thread, CHECK_JNI_ERR);
3622 
3623   // We need this for ClassDataSharing - the initial vm.info property is set
3624   // with the default value of CDS "sharing" which may be reset through
3625   // command line options.
3626   reset_vm_info_property(CHECK_JNI_ERR);
3627 
3628   quicken_jni_functions();
3629 
3630   // No more stub generation allowed after that point.
3631   StubCodeDesc::freeze();
3632 
3633   // Set flag that basic initialization has completed. Used by exceptions and various
3634   // debug stuff, that does not work until all basic classes have been initialized.
3635   set_init_completed();
3636 
3637   LogConfiguration::post_initialize();
3638   Metaspace::post_initialize();
3639 
3640   HOTSPOT_VM_INIT_END();
3641 
3642   // record VM initialization completion time
3643 #if INCLUDE_MANAGEMENT
3644   Management::record_vm_init_completed();
3645 #endif // INCLUDE_MANAGEMENT
3646 
3647   // Compute system loader. Note that this has to occur after set_init_completed, since
3648   // valid exceptions may be thrown in the process.
3649   // Note that we do not use CHECK_0 here since we are inside an EXCEPTION_MARK and
3650   // set_init_completed has just been called, causing exceptions not to be shortcut
3651   // anymore. We call vm_exit_during_initialization directly instead.
3652   SystemDictionary::compute_java_system_loader(CHECK_(JNI_ERR));
3653 
3654 #if INCLUDE_ALL_GCS
3655   // Support for ConcurrentMarkSweep. This should be cleaned up
3656   // and better encapsulated. The ugly nested if test would go away
3657   // once things are properly refactored. XXX YSR
3658   if (UseConcMarkSweepGC || UseG1GC) {
3659     if (UseConcMarkSweepGC) {
3660       ConcurrentMarkSweepThread::makeSurrogateLockerThread(CHECK_JNI_ERR);
3661     } else {
3662       ConcurrentMarkThread::makeSurrogateLockerThread(CHECK_JNI_ERR);
3663     }
3664   }
3665 #endif // INCLUDE_ALL_GCS
3666 
3667   // Always call even when there are not JVMTI environments yet, since environments
3668   // may be attached late and JVMTI must track phases of VM execution
3669   JvmtiExport::enter_live_phase();
3670 
3671   // Signal Dispatcher needs to be started before VMInit event is posted
3672   os::signal_init();
3673 
3674   // Start Attach Listener if +StartAttachListener or it can't be started lazily
3675   if (!DisableAttachMechanism) {
3676     AttachListener::vm_start();
3677     if (StartAttachListener || AttachListener::init_at_startup()) {
3678       AttachListener::init();
3679     }
3680   }
3681 
3682   // Launch -Xrun agents
3683   // Must be done in the JVMTI live phase so that for backward compatibility the JDWP
3684   // back-end can launch with -Xdebug -Xrunjdwp.
3685   if (!EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3686     create_vm_init_libraries();
3687   }
3688 
3689   // Notify JVMTI agents that VM initialization is complete - nop if no agents.
3690   JvmtiExport::post_vm_initialized();
3691 
3692   if (TRACE_START() != JNI_OK) {
3693     vm_exit_during_initialization("Failed to start tracing backend.");
3694   }
3695 
3696   if (CleanChunkPoolAsync) {
3697     Chunk::start_chunk_pool_cleaner_task();
3698   }
3699 
3700 #if INCLUDE_JVMCI
3701   if (EnableJVMCI) {
3702     const char* jvmciCompiler = Arguments::PropertyList_get_value(Arguments::system_properties(), "jvmci.compiler");
3703     if (jvmciCompiler != NULL) {
3704       JVMCIRuntime::save_compiler(jvmciCompiler);
3705     }
3706   }
3707 #endif // INCLUDE_JVMCI
3708 
3709   // initialize compiler(s)
3710 #if defined(COMPILER1) || defined(COMPILER2) || defined(SHARK) || INCLUDE_JVMCI
3711   CompileBroker::compilation_init(CHECK_JNI_ERR);
<a name="2" id="anc2"></a><span class="new">3712   // if used, invoke initialization of CacheProfiles</span>
<span class="new">3713   if(CacheProfiles &amp;&amp; !ciCacheProfiles::is_initialized()) {</span>
<span class="new">3714     ciCacheProfiles::initialize(THREAD);</span>
<span class="new">3715   }</span>
3716 #endif
3717 
3718   // Pre-initialize some JSR292 core classes to avoid deadlock during class loading.
3719   // It is done after compilers are initialized, because otherwise compilations of
3720   // signature polymorphic MH intrinsics can be missed
3721   // (see SystemDictionary::find_method_handle_intrinsic).
3722   initialize_jsr292_core_classes(CHECK_JNI_ERR);
3723 
3724 #if INCLUDE_MANAGEMENT
3725   Management::initialize(THREAD);
3726 
3727   if (HAS_PENDING_EXCEPTION) {
3728     // management agent fails to start possibly due to
3729     // configuration problem and is responsible for printing
3730     // stack trace if appropriate. Simply exit VM.
3731     vm_exit(1);
3732   }
3733 #endif // INCLUDE_MANAGEMENT
3734 
3735   if (Arguments::has_profile())       FlatProfiler::engage(main_thread, true);
3736   if (MemProfiling)                   MemProfiler::engage();
3737   StatSampler::engage();
3738   if (CheckJNICalls)                  JniPeriodicChecker::engage();
3739 
3740   BiasedLocking::init();
3741 
3742 #if INCLUDE_RTM_OPT
3743   RTMLockingCounters::init();
3744 #endif
3745 
3746   if (JDK_Version::current().post_vm_init_hook_enabled()) {
3747     call_postVMInitHook(THREAD);
3748     // The Java side of PostVMInitHook.run must deal with all
3749     // exceptions and provide means of diagnosis.
3750     if (HAS_PENDING_EXCEPTION) {
3751       CLEAR_PENDING_EXCEPTION;
3752     }
3753   }
3754 
3755   {
3756     MutexLocker ml(PeriodicTask_lock);
3757     // Make sure the WatcherThread can be started by WatcherThread::start()
3758     // or by dynamic enrollment.
3759     WatcherThread::make_startable();
3760     // Start up the WatcherThread if there are any periodic tasks
3761     // NOTE:  All PeriodicTasks should be registered by now. If they
3762     //   aren't, late joiners might appear to start slowly (we might
3763     //   take a while to process their first tick).
3764     if (PeriodicTask::num_tasks() &gt; 0) {
3765       WatcherThread::start();
3766     }
3767   }
3768 
3769   CodeCacheExtensions::complete_step(CodeCacheExtensionsSteps::CreateVM);
3770 
3771   create_vm_timer.end();
3772 #ifdef ASSERT
3773   _vm_complete = true;
3774 #endif
3775   return JNI_OK;
3776 }
3777 
3778 // type for the Agent_OnLoad and JVM_OnLoad entry points
3779 extern "C" {
3780   typedef jint (JNICALL *OnLoadEntry_t)(JavaVM *, char *, void *);
3781 }
3782 // Find a command line agent library and return its entry point for
3783 //         -agentlib:  -agentpath:   -Xrun
3784 // num_symbol_entries must be passed-in since only the caller knows the number of symbols in the array.
3785 static OnLoadEntry_t lookup_on_load(AgentLibrary* agent,
3786                                     const char *on_load_symbols[],
3787                                     size_t num_symbol_entries) {
3788   OnLoadEntry_t on_load_entry = NULL;
3789   void *library = NULL;
3790 
3791   if (!agent-&gt;valid()) {
3792     char buffer[JVM_MAXPATHLEN];
3793     char ebuf[1024] = "";
3794     const char *name = agent-&gt;name();
3795     const char *msg = "Could not find agent library ";
3796 
3797     // First check to see if agent is statically linked into executable
3798     if (os::find_builtin_agent(agent, on_load_symbols, num_symbol_entries)) {
3799       library = agent-&gt;os_lib();
3800     } else if (agent-&gt;is_absolute_path()) {
3801       library = os::dll_load(name, ebuf, sizeof ebuf);
3802       if (library == NULL) {
3803         const char *sub_msg = " in absolute path, with error: ";
3804         size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3805         char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3806         jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3807         // If we can't find the agent, exit.
3808         vm_exit_during_initialization(buf, NULL);
3809         FREE_C_HEAP_ARRAY(char, buf);
3810       }
3811     } else {
3812       // Try to load the agent from the standard dll directory
3813       if (os::dll_build_name(buffer, sizeof(buffer), Arguments::get_dll_dir(),
3814                              name)) {
3815         library = os::dll_load(buffer, ebuf, sizeof ebuf);
3816       }
3817       if (library == NULL) { // Try the local directory
3818         char ns[1] = {0};
3819         if (os::dll_build_name(buffer, sizeof(buffer), ns, name)) {
3820           library = os::dll_load(buffer, ebuf, sizeof ebuf);
3821         }
3822         if (library == NULL) {
3823           const char *sub_msg = " on the library path, with error: ";
3824           size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3825           char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3826           jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3827           // If we can't find the agent, exit.
3828           vm_exit_during_initialization(buf, NULL);
3829           FREE_C_HEAP_ARRAY(char, buf);
3830         }
3831       }
3832     }
3833     agent-&gt;set_os_lib(library);
3834     agent-&gt;set_valid();
3835   }
3836 
3837   // Find the OnLoad function.
3838   on_load_entry =
3839     CAST_TO_FN_PTR(OnLoadEntry_t, os::find_agent_function(agent,
3840                                                           false,
3841                                                           on_load_symbols,
3842                                                           num_symbol_entries));
3843   return on_load_entry;
3844 }
3845 
3846 // Find the JVM_OnLoad entry point
3847 static OnLoadEntry_t lookup_jvm_on_load(AgentLibrary* agent) {
3848   const char *on_load_symbols[] = JVM_ONLOAD_SYMBOLS;
3849   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3850 }
3851 
3852 // Find the Agent_OnLoad entry point
3853 static OnLoadEntry_t lookup_agent_on_load(AgentLibrary* agent) {
3854   const char *on_load_symbols[] = AGENT_ONLOAD_SYMBOLS;
3855   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3856 }
3857 
3858 // For backwards compatibility with -Xrun
3859 // Convert libraries with no JVM_OnLoad, but which have Agent_OnLoad to be
3860 // treated like -agentpath:
3861 // Must be called before agent libraries are created
3862 void Threads::convert_vm_init_libraries_to_agents() {
3863   AgentLibrary* agent;
3864   AgentLibrary* next;
3865 
3866   for (agent = Arguments::libraries(); agent != NULL; agent = next) {
3867     next = agent-&gt;next();  // cache the next agent now as this agent may get moved off this list
3868     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
3869 
3870     // If there is an JVM_OnLoad function it will get called later,
3871     // otherwise see if there is an Agent_OnLoad
3872     if (on_load_entry == NULL) {
3873       on_load_entry = lookup_agent_on_load(agent);
3874       if (on_load_entry != NULL) {
3875         // switch it to the agent list -- so that Agent_OnLoad will be called,
3876         // JVM_OnLoad won't be attempted and Agent_OnUnload will
3877         Arguments::convert_library_to_agent(agent);
3878       } else {
3879         vm_exit_during_initialization("Could not find JVM_OnLoad or Agent_OnLoad function in the library", agent-&gt;name());
3880       }
3881     }
3882   }
3883 }
3884 
3885 // Create agents for -agentlib:  -agentpath:  and converted -Xrun
3886 // Invokes Agent_OnLoad
3887 // Called very early -- before JavaThreads exist
3888 void Threads::create_vm_init_agents() {
3889   extern struct JavaVM_ main_vm;
3890   AgentLibrary* agent;
3891 
3892   JvmtiExport::enter_onload_phase();
3893 
3894   for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3895     OnLoadEntry_t  on_load_entry = lookup_agent_on_load(agent);
3896 
3897     if (on_load_entry != NULL) {
3898       // Invoke the Agent_OnLoad function
3899       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
3900       if (err != JNI_OK) {
3901         vm_exit_during_initialization("agent library failed to init", agent-&gt;name());
3902       }
3903     } else {
3904       vm_exit_during_initialization("Could not find Agent_OnLoad function in the agent library", agent-&gt;name());
3905     }
3906   }
3907   JvmtiExport::enter_primordial_phase();
3908 }
3909 
3910 extern "C" {
3911   typedef void (JNICALL *Agent_OnUnload_t)(JavaVM *);
3912 }
3913 
3914 void Threads::shutdown_vm_agents() {
3915   // Send any Agent_OnUnload notifications
3916   const char *on_unload_symbols[] = AGENT_ONUNLOAD_SYMBOLS;
3917   size_t num_symbol_entries = ARRAY_SIZE(on_unload_symbols);
3918   extern struct JavaVM_ main_vm;
3919   for (AgentLibrary* agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3920 
3921     // Find the Agent_OnUnload function.
3922     Agent_OnUnload_t unload_entry = CAST_TO_FN_PTR(Agent_OnUnload_t,
3923                                                    os::find_agent_function(agent,
3924                                                    false,
3925                                                    on_unload_symbols,
3926                                                    num_symbol_entries));
3927 
3928     // Invoke the Agent_OnUnload function
3929     if (unload_entry != NULL) {
3930       JavaThread* thread = JavaThread::current();
3931       ThreadToNativeFromVM ttn(thread);
3932       HandleMark hm(thread);
3933       (*unload_entry)(&amp;main_vm);
3934     }
3935   }
3936 }
3937 
3938 // Called for after the VM is initialized for -Xrun libraries which have not been converted to agent libraries
3939 // Invokes JVM_OnLoad
3940 void Threads::create_vm_init_libraries() {
3941   extern struct JavaVM_ main_vm;
3942   AgentLibrary* agent;
3943 
3944   for (agent = Arguments::libraries(); agent != NULL; agent = agent-&gt;next()) {
3945     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
3946 
3947     if (on_load_entry != NULL) {
3948       // Invoke the JVM_OnLoad function
3949       JavaThread* thread = JavaThread::current();
3950       ThreadToNativeFromVM ttn(thread);
3951       HandleMark hm(thread);
3952       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
3953       if (err != JNI_OK) {
3954         vm_exit_during_initialization("-Xrun library failed to init", agent-&gt;name());
3955       }
3956     } else {
3957       vm_exit_during_initialization("Could not find JVM_OnLoad function in -Xrun library", agent-&gt;name());
3958     }
3959   }
3960 }
3961 
3962 JavaThread* Threads::find_java_thread_from_java_tid(jlong java_tid) {
3963   assert(Threads_lock-&gt;owned_by_self(), "Must hold Threads_lock");
3964 
3965   JavaThread* java_thread = NULL;
3966   // Sequential search for now.  Need to do better optimization later.
3967   for (JavaThread* thread = Threads::first(); thread != NULL; thread = thread-&gt;next()) {
3968     oop tobj = thread-&gt;threadObj();
3969     if (!thread-&gt;is_exiting() &amp;&amp;
3970         tobj != NULL &amp;&amp;
3971         java_tid == java_lang_Thread::thread_id(tobj)) {
3972       java_thread = thread;
3973       break;
3974     }
3975   }
3976   return java_thread;
3977 }
3978 
3979 
3980 // Last thread running calls java.lang.Shutdown.shutdown()
3981 void JavaThread::invoke_shutdown_hooks() {
3982   HandleMark hm(this);
3983 
3984   // We could get here with a pending exception, if so clear it now.
3985   if (this-&gt;has_pending_exception()) {
3986     this-&gt;clear_pending_exception();
3987   }
3988 
3989   EXCEPTION_MARK;
3990   Klass* k =
3991     SystemDictionary::resolve_or_null(vmSymbols::java_lang_Shutdown(),
3992                                       THREAD);
3993   if (k != NULL) {
3994     // SystemDictionary::resolve_or_null will return null if there was
3995     // an exception.  If we cannot load the Shutdown class, just don't
3996     // call Shutdown.shutdown() at all.  This will mean the shutdown hooks
3997     // and finalizers (if runFinalizersOnExit is set) won't be run.
3998     // Note that if a shutdown hook was registered or runFinalizersOnExit
3999     // was called, the Shutdown class would have already been loaded
4000     // (Runtime.addShutdownHook and runFinalizersOnExit will load it).
4001     instanceKlassHandle shutdown_klass (THREAD, k);
4002     JavaValue result(T_VOID);
4003     JavaCalls::call_static(&amp;result,
4004                            shutdown_klass,
4005                            vmSymbols::shutdown_method_name(),
4006                            vmSymbols::void_method_signature(),
4007                            THREAD);
4008   }
4009   CLEAR_PENDING_EXCEPTION;
4010 }
4011 
4012 // Threads::destroy_vm() is normally called from jni_DestroyJavaVM() when
4013 // the program falls off the end of main(). Another VM exit path is through
4014 // vm_exit() when the program calls System.exit() to return a value or when
4015 // there is a serious error in VM. The two shutdown paths are not exactly
4016 // the same, but they share Shutdown.shutdown() at Java level and before_exit()
4017 // and VM_Exit op at VM level.
4018 //
4019 // Shutdown sequence:
4020 //   + Shutdown native memory tracking if it is on
4021 //   + Wait until we are the last non-daemon thread to execute
4022 //     &lt;-- every thing is still working at this moment --&gt;
4023 //   + Call java.lang.Shutdown.shutdown(), which will invoke Java level
4024 //        shutdown hooks, run finalizers if finalization-on-exit
4025 //   + Call before_exit(), prepare for VM exit
4026 //      &gt; run VM level shutdown hooks (they are registered through JVM_OnExit(),
4027 //        currently the only user of this mechanism is File.deleteOnExit())
4028 //      &gt; stop flat profiler, StatSampler, watcher thread, CMS threads,
4029 //        post thread end and vm death events to JVMTI,
4030 //        stop signal thread
4031 //   + Call JavaThread::exit(), it will:
4032 //      &gt; release JNI handle blocks, remove stack guard pages
4033 //      &gt; remove this thread from Threads list
4034 //     &lt;-- no more Java code from this thread after this point --&gt;
4035 //   + Stop VM thread, it will bring the remaining VM to a safepoint and stop
4036 //     the compiler threads at safepoint
4037 //     &lt;-- do not use anything that could get blocked by Safepoint --&gt;
4038 //   + Disable tracing at JNI/JVM barriers
4039 //   + Set _vm_exited flag for threads that are still running native code
4040 //   + Delete this thread
4041 //   + Call exit_globals()
4042 //      &gt; deletes tty
4043 //      &gt; deletes PerfMemory resources
4044 //   + Return to caller
4045 
4046 bool Threads::destroy_vm() {
4047   JavaThread* thread = JavaThread::current();
4048 
4049 #ifdef ASSERT
4050   _vm_complete = false;
4051 #endif
4052   // Wait until we are the last non-daemon thread to execute
4053   { MutexLocker nu(Threads_lock);
4054     while (Threads::number_of_non_daemon_threads() &gt; 1)
4055       // This wait should make safepoint checks, wait without a timeout,
4056       // and wait as a suspend-equivalent condition.
4057       //
4058       // Note: If the FlatProfiler is running and this thread is waiting
4059       // for another non-daemon thread to finish, then the FlatProfiler
4060       // is waiting for the external suspend request on this thread to
4061       // complete. wait_for_ext_suspend_completion() will eventually
4062       // timeout, but that takes time. Making this wait a suspend-
4063       // equivalent condition solves that timeout problem.
4064       //
4065       Threads_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
4066                          Mutex::_as_suspend_equivalent_flag);
4067   }
4068 
4069   // Hang forever on exit if we are reporting an error.
4070   if (ShowMessageBoxOnError &amp;&amp; is_error_reported()) {
4071     os::infinite_sleep();
4072   }
4073   os::wait_for_keypress_at_exit();
4074 
4075   // run Java level shutdown hooks
4076   thread-&gt;invoke_shutdown_hooks();
4077 
4078   before_exit(thread);
4079 
4080   thread-&gt;exit(true);
4081 
4082   // Stop VM thread.
4083   {
4084     // 4945125 The vm thread comes to a safepoint during exit.
4085     // GC vm_operations can get caught at the safepoint, and the
4086     // heap is unparseable if they are caught. Grab the Heap_lock
4087     // to prevent this. The GC vm_operations will not be able to
4088     // queue until after the vm thread is dead. After this point,
4089     // we'll never emerge out of the safepoint before the VM exits.
4090 
4091     MutexLocker ml(Heap_lock);
4092 
4093     VMThread::wait_for_vm_thread_exit();
4094     assert(SafepointSynchronize::is_at_safepoint(), "VM thread should exit at Safepoint");
4095     VMThread::destroy();
4096   }
4097 
4098   // clean up ideal graph printers
4099 #if defined(COMPILER2) &amp;&amp; !defined(PRODUCT)
4100   IdealGraphPrinter::clean_up();
4101 #endif
4102 
4103   // Now, all Java threads are gone except daemon threads. Daemon threads
4104   // running Java code or in VM are stopped by the Safepoint. However,
4105   // daemon threads executing native code are still running.  But they
4106   // will be stopped at native=&gt;Java/VM barriers. Note that we can't
4107   // simply kill or suspend them, as it is inherently deadlock-prone.
4108 
4109   VM_Exit::set_vm_exited();
4110 
4111   notify_vm_shutdown();
4112 
4113   delete thread;
4114 
4115 #if INCLUDE_JVMCI
4116   if (JVMCICounterSize &gt; 0) {
4117     FREE_C_HEAP_ARRAY(jlong, JavaThread::_jvmci_old_thread_counters);
4118   }
4119 #endif
4120 
4121   // exit_globals() will delete tty
4122   exit_globals();
4123 
4124   LogConfiguration::finalize();
4125 
4126   return true;
4127 }
4128 
4129 
4130 jboolean Threads::is_supported_jni_version_including_1_1(jint version) {
4131   if (version == JNI_VERSION_1_1) return JNI_TRUE;
4132   return is_supported_jni_version(version);
4133 }
4134 
4135 
4136 jboolean Threads::is_supported_jni_version(jint version) {
4137   if (version == JNI_VERSION_1_2) return JNI_TRUE;
4138   if (version == JNI_VERSION_1_4) return JNI_TRUE;
4139   if (version == JNI_VERSION_1_6) return JNI_TRUE;
4140   if (version == JNI_VERSION_1_8) return JNI_TRUE;
4141   if (version == JNI_VERSION_9) return JNI_TRUE;
4142   return JNI_FALSE;
4143 }
4144 
4145 
4146 void Threads::add(JavaThread* p, bool force_daemon) {
4147   // The threads lock must be owned at this point
4148   assert_locked_or_safepoint(Threads_lock);
4149 
4150   // See the comment for this method in thread.hpp for its purpose and
4151   // why it is called here.
4152   p-&gt;initialize_queues();
4153   p-&gt;set_next(_thread_list);
4154   _thread_list = p;
4155   _number_of_threads++;
4156   oop threadObj = p-&gt;threadObj();
4157   bool daemon = true;
4158   // Bootstrapping problem: threadObj can be null for initial
4159   // JavaThread (or for threads attached via JNI)
4160   if ((!force_daemon) &amp;&amp; (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj))) {
4161     _number_of_non_daemon_threads++;
4162     daemon = false;
4163   }
4164 
4165   ThreadService::add_thread(p, daemon);
4166 
4167   // Possible GC point.
4168   Events::log(p, "Thread added: " INTPTR_FORMAT, p2i(p));
4169 }
4170 
4171 void Threads::remove(JavaThread* p) {
4172   // Extra scope needed for Thread_lock, so we can check
4173   // that we do not remove thread without safepoint code notice
4174   { MutexLocker ml(Threads_lock);
4175 
4176     assert(includes(p), "p must be present");
4177 
4178     JavaThread* current = _thread_list;
4179     JavaThread* prev    = NULL;
4180 
4181     while (current != p) {
4182       prev    = current;
4183       current = current-&gt;next();
4184     }
4185 
4186     if (prev) {
4187       prev-&gt;set_next(current-&gt;next());
4188     } else {
4189       _thread_list = p-&gt;next();
4190     }
4191     _number_of_threads--;
4192     oop threadObj = p-&gt;threadObj();
4193     bool daemon = true;
4194     if (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj)) {
4195       _number_of_non_daemon_threads--;
4196       daemon = false;
4197 
4198       // Only one thread left, do a notify on the Threads_lock so a thread waiting
4199       // on destroy_vm will wake up.
4200       if (number_of_non_daemon_threads() == 1) {
4201         Threads_lock-&gt;notify_all();
4202       }
4203     }
4204     ThreadService::remove_thread(p, daemon);
4205 
4206     // Make sure that safepoint code disregard this thread. This is needed since
4207     // the thread might mess around with locks after this point. This can cause it
4208     // to do callbacks into the safepoint code. However, the safepoint code is not aware
4209     // of this thread since it is removed from the queue.
4210     p-&gt;set_terminated_value();
4211   } // unlock Threads_lock
4212 
4213   // Since Events::log uses a lock, we grab it outside the Threads_lock
4214   Events::log(p, "Thread exited: " INTPTR_FORMAT, p2i(p));
4215 }
4216 
4217 // Threads_lock must be held when this is called (or must be called during a safepoint)
4218 bool Threads::includes(JavaThread* p) {
4219   assert(Threads_lock-&gt;is_locked(), "sanity check");
4220   ALL_JAVA_THREADS(q) {
4221     if (q == p) {
4222       return true;
4223     }
4224   }
4225   return false;
4226 }
4227 
4228 // Operations on the Threads list for GC.  These are not explicitly locked,
4229 // but the garbage collector must provide a safe context for them to run.
4230 // In particular, these things should never be called when the Threads_lock
4231 // is held by some other thread. (Note: the Safepoint abstraction also
4232 // uses the Threads_lock to guarantee this property. It also makes sure that
4233 // all threads gets blocked when exiting or starting).
4234 
4235 void Threads::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
4236   ALL_JAVA_THREADS(p) {
4237     p-&gt;oops_do(f, cld_f, cf);
4238   }
4239   VMThread::vm_thread()-&gt;oops_do(f, cld_f, cf);
4240 }
4241 
4242 void Threads::change_thread_claim_parity() {
4243   // Set the new claim parity.
4244   assert(_thread_claim_parity &gt;= 0 &amp;&amp; _thread_claim_parity &lt;= 2,
4245          "Not in range.");
4246   _thread_claim_parity++;
4247   if (_thread_claim_parity == 3) _thread_claim_parity = 1;
4248   assert(_thread_claim_parity &gt;= 1 &amp;&amp; _thread_claim_parity &lt;= 2,
4249          "Not in range.");
4250 }
4251 
4252 #ifdef ASSERT
4253 void Threads::assert_all_threads_claimed() {
4254   ALL_JAVA_THREADS(p) {
4255     const int thread_parity = p-&gt;oops_do_parity();
4256     assert((thread_parity == _thread_claim_parity),
4257            "Thread " PTR_FORMAT " has incorrect parity %d != %d", p2i(p), thread_parity, _thread_claim_parity);
4258   }
4259 }
4260 #endif // ASSERT
4261 
4262 void Threads::possibly_parallel_oops_do(bool is_par, OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
4263   int cp = Threads::thread_claim_parity();
4264   ALL_JAVA_THREADS(p) {
4265     if (p-&gt;claim_oops_do(is_par, cp)) {
4266       p-&gt;oops_do(f, cld_f, cf);
4267     }
4268   }
4269   VMThread* vmt = VMThread::vm_thread();
4270   if (vmt-&gt;claim_oops_do(is_par, cp)) {
4271     vmt-&gt;oops_do(f, cld_f, cf);
4272   }
4273 }
4274 
4275 #if INCLUDE_ALL_GCS
4276 // Used by ParallelScavenge
4277 void Threads::create_thread_roots_tasks(GCTaskQueue* q) {
4278   ALL_JAVA_THREADS(p) {
4279     q-&gt;enqueue(new ThreadRootsTask(p));
4280   }
4281   q-&gt;enqueue(new ThreadRootsTask(VMThread::vm_thread()));
4282 }
4283 
4284 // Used by Parallel Old
4285 void Threads::create_thread_roots_marking_tasks(GCTaskQueue* q) {
4286   ALL_JAVA_THREADS(p) {
4287     q-&gt;enqueue(new ThreadRootsMarkingTask(p));
4288   }
4289   q-&gt;enqueue(new ThreadRootsMarkingTask(VMThread::vm_thread()));
4290 }
4291 #endif // INCLUDE_ALL_GCS
4292 
4293 void Threads::nmethods_do(CodeBlobClosure* cf) {
4294   ALL_JAVA_THREADS(p) {
4295     p-&gt;nmethods_do(cf);
4296   }
4297   VMThread::vm_thread()-&gt;nmethods_do(cf);
4298 }
4299 
4300 void Threads::metadata_do(void f(Metadata*)) {
4301   ALL_JAVA_THREADS(p) {
4302     p-&gt;metadata_do(f);
4303   }
4304 }
4305 
4306 class ThreadHandlesClosure : public ThreadClosure {
4307   void (*_f)(Metadata*);
4308  public:
4309   ThreadHandlesClosure(void f(Metadata*)) : _f(f) {}
4310   virtual void do_thread(Thread* thread) {
4311     thread-&gt;metadata_handles_do(_f);
4312   }
4313 };
4314 
4315 void Threads::metadata_handles_do(void f(Metadata*)) {
4316   // Only walk the Handles in Thread.
4317   ThreadHandlesClosure handles_closure(f);
4318   threads_do(&amp;handles_closure);
4319 }
4320 
4321 void Threads::deoptimized_wrt_marked_nmethods() {
4322   ALL_JAVA_THREADS(p) {
4323     p-&gt;deoptimized_wrt_marked_nmethods();
4324   }
4325 }
4326 
4327 
4328 // Get count Java threads that are waiting to enter the specified monitor.
4329 GrowableArray&lt;JavaThread*&gt;* Threads::get_pending_threads(int count,
4330                                                          address monitor,
4331                                                          bool doLock) {
4332   assert(doLock || SafepointSynchronize::is_at_safepoint(),
4333          "must grab Threads_lock or be at safepoint");
4334   GrowableArray&lt;JavaThread*&gt;* result = new GrowableArray&lt;JavaThread*&gt;(count);
4335 
4336   int i = 0;
4337   {
4338     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4339     ALL_JAVA_THREADS(p) {
4340       if (!p-&gt;can_call_java()) continue;
4341 
4342       address pending = (address)p-&gt;current_pending_monitor();
4343       if (pending == monitor) {             // found a match
4344         if (i &lt; count) result-&gt;append(p);   // save the first count matches
4345         i++;
4346       }
4347     }
4348   }
4349   return result;
4350 }
4351 
4352 
4353 JavaThread *Threads::owning_thread_from_monitor_owner(address owner,
4354                                                       bool doLock) {
4355   assert(doLock ||
4356          Threads_lock-&gt;owned_by_self() ||
4357          SafepointSynchronize::is_at_safepoint(),
4358          "must grab Threads_lock or be at safepoint");
4359 
4360   // NULL owner means not locked so we can skip the search
4361   if (owner == NULL) return NULL;
4362 
4363   {
4364     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4365     ALL_JAVA_THREADS(p) {
4366       // first, see if owner is the address of a Java thread
4367       if (owner == (address)p) return p;
4368     }
4369   }
4370   // Cannot assert on lack of success here since this function may be
4371   // used by code that is trying to report useful problem information
4372   // like deadlock detection.
4373   if (UseHeavyMonitors) return NULL;
4374 
4375   // If we didn't find a matching Java thread and we didn't force use of
4376   // heavyweight monitors, then the owner is the stack address of the
4377   // Lock Word in the owning Java thread's stack.
4378   //
4379   JavaThread* the_owner = NULL;
4380   {
4381     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4382     ALL_JAVA_THREADS(q) {
4383       if (q-&gt;is_lock_owned(owner)) {
4384         the_owner = q;
4385         break;
4386       }
4387     }
4388   }
4389   // cannot assert on lack of success here; see above comment
4390   return the_owner;
4391 }
4392 
4393 // Threads::print_on() is called at safepoint by VM_PrintThreads operation.
4394 void Threads::print_on(outputStream* st, bool print_stacks,
4395                        bool internal_format, bool print_concurrent_locks) {
4396   char buf[32];
4397   st-&gt;print_raw_cr(os::local_time_string(buf, sizeof(buf)));
4398 
4399   st-&gt;print_cr("Full thread dump %s (%s %s):",
4400                Abstract_VM_Version::vm_name(),
4401                Abstract_VM_Version::vm_release(),
4402                Abstract_VM_Version::vm_info_string());
4403   st-&gt;cr();
4404 
4405 #if INCLUDE_SERVICES
4406   // Dump concurrent locks
4407   ConcurrentLocksDump concurrent_locks;
4408   if (print_concurrent_locks) {
4409     concurrent_locks.dump_at_safepoint();
4410   }
4411 #endif // INCLUDE_SERVICES
4412 
4413   ALL_JAVA_THREADS(p) {
4414     ResourceMark rm;
4415     p-&gt;print_on(st);
4416     if (print_stacks) {
4417       if (internal_format) {
4418         p-&gt;trace_stack();
4419       } else {
4420         p-&gt;print_stack_on(st);
4421       }
4422     }
4423     st-&gt;cr();
4424 #if INCLUDE_SERVICES
4425     if (print_concurrent_locks) {
4426       concurrent_locks.print_locks_on(p, st);
4427     }
4428 #endif // INCLUDE_SERVICES
4429   }
4430 
4431   VMThread::vm_thread()-&gt;print_on(st);
4432   st-&gt;cr();
4433   Universe::heap()-&gt;print_gc_threads_on(st);
4434   WatcherThread* wt = WatcherThread::watcher_thread();
4435   if (wt != NULL) {
4436     wt-&gt;print_on(st);
4437     st-&gt;cr();
4438   }
4439   st-&gt;flush();
4440 }
4441 
4442 // Threads::print_on_error() is called by fatal error handler. It's possible
4443 // that VM is not at safepoint and/or current thread is inside signal handler.
4444 // Don't print stack trace, as the stack may not be walkable. Don't allocate
4445 // memory (even in resource area), it might deadlock the error handler.
4446 void Threads::print_on_error(outputStream* st, Thread* current, char* buf,
4447                              int buflen) {
4448   bool found_current = false;
4449   st-&gt;print_cr("Java Threads: ( =&gt; current thread )");
4450   ALL_JAVA_THREADS(thread) {
4451     bool is_current = (current == thread);
4452     found_current = found_current || is_current;
4453 
4454     st-&gt;print("%s", is_current ? "=&gt;" : "  ");
4455 
4456     st-&gt;print(PTR_FORMAT, p2i(thread));
4457     st-&gt;print(" ");
4458     thread-&gt;print_on_error(st, buf, buflen);
4459     st-&gt;cr();
4460   }
4461   st-&gt;cr();
4462 
4463   st-&gt;print_cr("Other Threads:");
4464   if (VMThread::vm_thread()) {
4465     bool is_current = (current == VMThread::vm_thread());
4466     found_current = found_current || is_current;
4467     st-&gt;print("%s", current == VMThread::vm_thread() ? "=&gt;" : "  ");
4468 
4469     st-&gt;print(PTR_FORMAT, p2i(VMThread::vm_thread()));
4470     st-&gt;print(" ");
4471     VMThread::vm_thread()-&gt;print_on_error(st, buf, buflen);
4472     st-&gt;cr();
4473   }
4474   WatcherThread* wt = WatcherThread::watcher_thread();
4475   if (wt != NULL) {
4476     bool is_current = (current == wt);
4477     found_current = found_current || is_current;
4478     st-&gt;print("%s", is_current ? "=&gt;" : "  ");
4479 
4480     st-&gt;print(PTR_FORMAT, p2i(wt));
4481     st-&gt;print(" ");
4482     wt-&gt;print_on_error(st, buf, buflen);
4483     st-&gt;cr();
4484   }
4485   if (!found_current) {
4486     st-&gt;cr();
4487     st-&gt;print("=&gt;" PTR_FORMAT " (exited) ", p2i(current));
4488     current-&gt;print_on_error(st, buf, buflen);
4489     st-&gt;cr();
4490   }
4491   st-&gt;cr();
4492   st-&gt;print_cr("Threads with active compile tasks:");
4493   print_threads_compiling(st, buf, buflen);
4494 }
4495 
4496 void Threads::print_threads_compiling(outputStream* st, char* buf, int buflen) {
4497   ALL_JAVA_THREADS(thread) {
4498     if (thread-&gt;is_Compiler_thread()) {
4499       CompilerThread* ct = (CompilerThread*) thread;
4500       if (ct-&gt;task() != NULL) {
4501         thread-&gt;print_name_on_error(st, buf, buflen);
4502         ct-&gt;task()-&gt;print(st, NULL, true, true);
4503       }
4504     }
4505   }
4506 }
4507 
4508 
4509 // Internal SpinLock and Mutex
4510 // Based on ParkEvent
4511 
4512 // Ad-hoc mutual exclusion primitives: SpinLock and Mux
4513 //
4514 // We employ SpinLocks _only for low-contention, fixed-length
4515 // short-duration critical sections where we're concerned
4516 // about native mutex_t or HotSpot Mutex:: latency.
4517 // The mux construct provides a spin-then-block mutual exclusion
4518 // mechanism.
4519 //
4520 // Testing has shown that contention on the ListLock guarding gFreeList
4521 // is common.  If we implement ListLock as a simple SpinLock it's common
4522 // for the JVM to devolve to yielding with little progress.  This is true
4523 // despite the fact that the critical sections protected by ListLock are
4524 // extremely short.
4525 //
4526 // TODO-FIXME: ListLock should be of type SpinLock.
4527 // We should make this a 1st-class type, integrated into the lock
4528 // hierarchy as leaf-locks.  Critically, the SpinLock structure
4529 // should have sufficient padding to avoid false-sharing and excessive
4530 // cache-coherency traffic.
4531 
4532 
4533 typedef volatile int SpinLockT;
4534 
4535 void Thread::SpinAcquire(volatile int * adr, const char * LockName) {
4536   if (Atomic::cmpxchg (1, adr, 0) == 0) {
4537     return;   // normal fast-path return
4538   }
4539 
4540   // Slow-path : We've encountered contention -- Spin/Yield/Block strategy.
4541   TEVENT(SpinAcquire - ctx);
4542   int ctr = 0;
4543   int Yields = 0;
4544   for (;;) {
4545     while (*adr != 0) {
4546       ++ctr;
4547       if ((ctr &amp; 0xFFF) == 0 || !os::is_MP()) {
4548         if (Yields &gt; 5) {
4549           os::naked_short_sleep(1);
4550         } else {
4551           os::naked_yield();
4552           ++Yields;
4553         }
4554       } else {
4555         SpinPause();
4556       }
4557     }
4558     if (Atomic::cmpxchg(1, adr, 0) == 0) return;
4559   }
4560 }
4561 
4562 void Thread::SpinRelease(volatile int * adr) {
4563   assert(*adr != 0, "invariant");
4564   OrderAccess::fence();      // guarantee at least release consistency.
4565   // Roach-motel semantics.
4566   // It's safe if subsequent LDs and STs float "up" into the critical section,
4567   // but prior LDs and STs within the critical section can't be allowed
4568   // to reorder or float past the ST that releases the lock.
4569   // Loads and stores in the critical section - which appear in program
4570   // order before the store that releases the lock - must also appear
4571   // before the store that releases the lock in memory visibility order.
4572   // Conceptually we need a #loadstore|#storestore "release" MEMBAR before
4573   // the ST of 0 into the lock-word which releases the lock, so fence
4574   // more than covers this on all platforms.
4575   *adr = 0;
4576 }
4577 
4578 // muxAcquire and muxRelease:
4579 //
4580 // *  muxAcquire and muxRelease support a single-word lock-word construct.
4581 //    The LSB of the word is set IFF the lock is held.
4582 //    The remainder of the word points to the head of a singly-linked list
4583 //    of threads blocked on the lock.
4584 //
4585 // *  The current implementation of muxAcquire-muxRelease uses its own
4586 //    dedicated Thread._MuxEvent instance.  If we're interested in
4587 //    minimizing the peak number of extant ParkEvent instances then
4588 //    we could eliminate _MuxEvent and "borrow" _ParkEvent as long
4589 //    as certain invariants were satisfied.  Specifically, care would need
4590 //    to be taken with regards to consuming unpark() "permits".
4591 //    A safe rule of thumb is that a thread would never call muxAcquire()
4592 //    if it's enqueued (cxq, EntryList, WaitList, etc) and will subsequently
4593 //    park().  Otherwise the _ParkEvent park() operation in muxAcquire() could
4594 //    consume an unpark() permit intended for monitorenter, for instance.
4595 //    One way around this would be to widen the restricted-range semaphore
4596 //    implemented in park().  Another alternative would be to provide
4597 //    multiple instances of the PlatformEvent() for each thread.  One
4598 //    instance would be dedicated to muxAcquire-muxRelease, for instance.
4599 //
4600 // *  Usage:
4601 //    -- Only as leaf locks
4602 //    -- for short-term locking only as muxAcquire does not perform
4603 //       thread state transitions.
4604 //
4605 // Alternatives:
4606 // *  We could implement muxAcquire and muxRelease with MCS or CLH locks
4607 //    but with parking or spin-then-park instead of pure spinning.
4608 // *  Use Taura-Oyama-Yonenzawa locks.
4609 // *  It's possible to construct a 1-0 lock if we encode the lockword as
4610 //    (List,LockByte).  Acquire will CAS the full lockword while Release
4611 //    will STB 0 into the LockByte.  The 1-0 scheme admits stranding, so
4612 //    acquiring threads use timers (ParkTimed) to detect and recover from
4613 //    the stranding window.  Thread/Node structures must be aligned on 256-byte
4614 //    boundaries by using placement-new.
4615 // *  Augment MCS with advisory back-link fields maintained with CAS().
4616 //    Pictorially:  LockWord -&gt; T1 &lt;-&gt; T2 &lt;-&gt; T3 &lt;-&gt; ... &lt;-&gt; Tn &lt;-&gt; Owner.
4617 //    The validity of the backlinks must be ratified before we trust the value.
4618 //    If the backlinks are invalid the exiting thread must back-track through the
4619 //    the forward links, which are always trustworthy.
4620 // *  Add a successor indication.  The LockWord is currently encoded as
4621 //    (List, LOCKBIT:1).  We could also add a SUCCBIT or an explicit _succ variable
4622 //    to provide the usual futile-wakeup optimization.
4623 //    See RTStt for details.
4624 // *  Consider schedctl.sc_nopreempt to cover the critical section.
4625 //
4626 
4627 
4628 typedef volatile intptr_t MutexT;      // Mux Lock-word
4629 enum MuxBits { LOCKBIT = 1 };
4630 
4631 void Thread::muxAcquire(volatile intptr_t * Lock, const char * LockName) {
4632   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4633   if (w == 0) return;
4634   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4635     return;
4636   }
4637 
4638   TEVENT(muxAcquire - Contention);
4639   ParkEvent * const Self = Thread::current()-&gt;_MuxEvent;
4640   assert((intptr_t(Self) &amp; LOCKBIT) == 0, "invariant");
4641   for (;;) {
4642     int its = (os::is_MP() ? 100 : 0) + 1;
4643 
4644     // Optional spin phase: spin-then-park strategy
4645     while (--its &gt;= 0) {
4646       w = *Lock;
4647       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4648         return;
4649       }
4650     }
4651 
4652     Self-&gt;reset();
4653     Self-&gt;OnList = intptr_t(Lock);
4654     // The following fence() isn't _strictly necessary as the subsequent
4655     // CAS() both serializes execution and ratifies the fetched *Lock value.
4656     OrderAccess::fence();
4657     for (;;) {
4658       w = *Lock;
4659       if ((w &amp; LOCKBIT) == 0) {
4660         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4661           Self-&gt;OnList = 0;   // hygiene - allows stronger asserts
4662           return;
4663         }
4664         continue;      // Interference -- *Lock changed -- Just retry
4665       }
4666       assert(w &amp; LOCKBIT, "invariant");
4667       Self-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4668       if (Atomic::cmpxchg_ptr(intptr_t(Self)|LOCKBIT, Lock, w) == w) break;
4669     }
4670 
4671     while (Self-&gt;OnList != 0) {
4672       Self-&gt;park();
4673     }
4674   }
4675 }
4676 
4677 void Thread::muxAcquireW(volatile intptr_t * Lock, ParkEvent * ev) {
4678   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4679   if (w == 0) return;
4680   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4681     return;
4682   }
4683 
4684   TEVENT(muxAcquire - Contention);
4685   ParkEvent * ReleaseAfter = NULL;
4686   if (ev == NULL) {
4687     ev = ReleaseAfter = ParkEvent::Allocate(NULL);
4688   }
4689   assert((intptr_t(ev) &amp; LOCKBIT) == 0, "invariant");
4690   for (;;) {
4691     guarantee(ev-&gt;OnList == 0, "invariant");
4692     int its = (os::is_MP() ? 100 : 0) + 1;
4693 
4694     // Optional spin phase: spin-then-park strategy
4695     while (--its &gt;= 0) {
4696       w = *Lock;
4697       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4698         if (ReleaseAfter != NULL) {
4699           ParkEvent::Release(ReleaseAfter);
4700         }
4701         return;
4702       }
4703     }
4704 
4705     ev-&gt;reset();
4706     ev-&gt;OnList = intptr_t(Lock);
4707     // The following fence() isn't _strictly necessary as the subsequent
4708     // CAS() both serializes execution and ratifies the fetched *Lock value.
4709     OrderAccess::fence();
4710     for (;;) {
4711       w = *Lock;
4712       if ((w &amp; LOCKBIT) == 0) {
4713         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4714           ev-&gt;OnList = 0;
4715           // We call ::Release while holding the outer lock, thus
4716           // artificially lengthening the critical section.
4717           // Consider deferring the ::Release() until the subsequent unlock(),
4718           // after we've dropped the outer lock.
4719           if (ReleaseAfter != NULL) {
4720             ParkEvent::Release(ReleaseAfter);
4721           }
4722           return;
4723         }
4724         continue;      // Interference -- *Lock changed -- Just retry
4725       }
4726       assert(w &amp; LOCKBIT, "invariant");
4727       ev-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4728       if (Atomic::cmpxchg_ptr(intptr_t(ev)|LOCKBIT, Lock, w) == w) break;
4729     }
4730 
4731     while (ev-&gt;OnList != 0) {
4732       ev-&gt;park();
4733     }
4734   }
4735 }
4736 
4737 // Release() must extract a successor from the list and then wake that thread.
4738 // It can "pop" the front of the list or use a detach-modify-reattach (DMR) scheme
4739 // similar to that used by ParkEvent::Allocate() and ::Release().  DMR-based
4740 // Release() would :
4741 // (A) CAS() or swap() null to *Lock, releasing the lock and detaching the list.
4742 // (B) Extract a successor from the private list "in-hand"
4743 // (C) attempt to CAS() the residual back into *Lock over null.
4744 //     If there were any newly arrived threads and the CAS() would fail.
4745 //     In that case Release() would detach the RATs, re-merge the list in-hand
4746 //     with the RATs and repeat as needed.  Alternately, Release() might
4747 //     detach and extract a successor, but then pass the residual list to the wakee.
4748 //     The wakee would be responsible for reattaching and remerging before it
4749 //     competed for the lock.
4750 //
4751 // Both "pop" and DMR are immune from ABA corruption -- there can be
4752 // multiple concurrent pushers, but only one popper or detacher.
4753 // This implementation pops from the head of the list.  This is unfair,
4754 // but tends to provide excellent throughput as hot threads remain hot.
4755 // (We wake recently run threads first).
4756 //
4757 // All paths through muxRelease() will execute a CAS.
4758 // Release consistency -- We depend on the CAS in muxRelease() to provide full
4759 // bidirectional fence/MEMBAR semantics, ensuring that all prior memory operations
4760 // executed within the critical section are complete and globally visible before the
4761 // store (CAS) to the lock-word that releases the lock becomes globally visible.
4762 void Thread::muxRelease(volatile intptr_t * Lock)  {
4763   for (;;) {
4764     const intptr_t w = Atomic::cmpxchg_ptr(0, Lock, LOCKBIT);
4765     assert(w &amp; LOCKBIT, "invariant");
4766     if (w == LOCKBIT) return;
4767     ParkEvent * const List = (ParkEvent *) (w &amp; ~LOCKBIT);
4768     assert(List != NULL, "invariant");
4769     assert(List-&gt;OnList == intptr_t(Lock), "invariant");
4770     ParkEvent * const nxt = List-&gt;ListNext;
4771     guarantee((intptr_t(nxt) &amp; LOCKBIT) == 0, "invariant");
4772 
4773     // The following CAS() releases the lock and pops the head element.
4774     // The CAS() also ratifies the previously fetched lock-word value.
4775     if (Atomic::cmpxchg_ptr (intptr_t(nxt), Lock, w) != w) {
4776       continue;
4777     }
4778     List-&gt;OnList = 0;
4779     OrderAccess::fence();
4780     List-&gt;unpark();
4781     return;
4782   }
4783 }
4784 
4785 
4786 void Threads::verify() {
4787   ALL_JAVA_THREADS(p) {
4788     p-&gt;verify();
4789   }
4790   VMThread* thread = VMThread::vm_thread();
4791   if (thread != NULL) thread-&gt;verify();
4792 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="3" type="hidden" /></form></body></html>
