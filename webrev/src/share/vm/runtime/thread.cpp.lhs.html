<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre></pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 #include "classfile/classLoader.hpp"
  27 #include "classfile/javaClasses.hpp"
  28 #include "classfile/systemDictionary.hpp"
  29 #include "classfile/vmSymbols.hpp"
<a name="1" id="anc1"></a>
  30 #include "code/codeCache.hpp"
  31 #include "code/codeCacheExtensions.hpp"
  32 #include "code/scopeDesc.hpp"
  33 #include "compiler/compileBroker.hpp"
  34 #include "compiler/compileTask.hpp"
  35 #include "gc/shared/gcId.hpp"
  36 #include "gc/shared/gcLocker.inline.hpp"
  37 #include "gc/shared/workgroup.hpp"
  38 #include "interpreter/interpreter.hpp"
  39 #include "interpreter/linkResolver.hpp"
  40 #include "interpreter/oopMapCache.hpp"
  41 #include "jvmtifiles/jvmtiEnv.hpp"
  42 #include "logging/log.hpp"
  43 #include "logging/logConfiguration.hpp"
  44 #include "memory/metaspaceShared.hpp"
  45 #include "memory/oopFactory.hpp"
  46 #include "memory/universe.inline.hpp"
  47 #include "oops/instanceKlass.hpp"
  48 #include "oops/objArrayOop.hpp"
  49 #include "oops/oop.inline.hpp"
  50 #include "oops/symbol.hpp"
  51 #include "oops/verifyOopClosure.hpp"
  52 #include "prims/jvm_misc.hpp"
  53 #include "prims/jvmtiExport.hpp"
  54 #include "prims/jvmtiThreadState.hpp"
  55 #include "prims/privilegedStack.hpp"
  56 #include "runtime/arguments.hpp"
  57 #include "runtime/atomic.inline.hpp"
  58 #include "runtime/biasedLocking.hpp"
  59 #include "runtime/commandLineFlagConstraintList.hpp"
  60 #include "runtime/commandLineFlagRangeList.hpp"
  61 #include "runtime/deoptimization.hpp"
  62 #include "runtime/fprofiler.hpp"
  63 #include "runtime/frame.inline.hpp"
  64 #include "runtime/globals.hpp"
  65 #include "runtime/init.hpp"
  66 #include "runtime/interfaceSupport.hpp"
  67 #include "runtime/java.hpp"
  68 #include "runtime/javaCalls.hpp"
  69 #include "runtime/jniPeriodicChecker.hpp"
  70 #include "runtime/logTimer.hpp"
  71 #include "runtime/memprofiler.hpp"
  72 #include "runtime/mutexLocker.hpp"
  73 #include "runtime/objectMonitor.hpp"
  74 #include "runtime/orderAccess.inline.hpp"
  75 #include "runtime/osThread.hpp"
  76 #include "runtime/safepoint.hpp"
  77 #include "runtime/sharedRuntime.hpp"
  78 #include "runtime/statSampler.hpp"
  79 #include "runtime/stubRoutines.hpp"
  80 #include "runtime/sweeper.hpp"
  81 #include "runtime/task.hpp"
  82 #include "runtime/thread.inline.hpp"
  83 #include "runtime/threadCritical.hpp"
  84 #include "runtime/vframe.hpp"
  85 #include "runtime/vframeArray.hpp"
  86 #include "runtime/vframe_hp.hpp"
  87 #include "runtime/vmThread.hpp"
  88 #include "runtime/vm_operations.hpp"
  89 #include "runtime/vm_version.hpp"
  90 #include "services/attachListener.hpp"
  91 #include "services/management.hpp"
  92 #include "services/memTracker.hpp"
  93 #include "services/threadService.hpp"
  94 #include "trace/traceMacros.hpp"
  95 #include "trace/tracing.hpp"
  96 #include "utilities/defaultStream.hpp"
  97 #include "utilities/dtrace.hpp"
  98 #include "utilities/events.hpp"
  99 #include "utilities/macros.hpp"
 100 #include "utilities/preserveException.hpp"
 101 #if INCLUDE_ALL_GCS
 102 #include "gc/cms/concurrentMarkSweepThread.hpp"
 103 #include "gc/g1/concurrentMarkThread.inline.hpp"
 104 #include "gc/parallel/pcTasks.hpp"
 105 #endif // INCLUDE_ALL_GCS
 106 #if INCLUDE_JVMCI
 107 #include "jvmci/jvmciCompiler.hpp"
 108 #include "jvmci/jvmciRuntime.hpp"
 109 #endif
 110 #ifdef COMPILER1
 111 #include "c1/c1_Compiler.hpp"
 112 #endif
 113 #ifdef COMPILER2
 114 #include "opto/c2compiler.hpp"
 115 #include "opto/idealGraphPrinter.hpp"
 116 #endif
 117 #if INCLUDE_RTM_OPT
 118 #include "runtime/rtmLocking.hpp"
 119 #endif
 120 
 121 #ifdef DTRACE_ENABLED
 122 
 123 // Only bother with this argument setup if dtrace is available
 124 
 125   #define HOTSPOT_THREAD_PROBE_start HOTSPOT_THREAD_START
 126   #define HOTSPOT_THREAD_PROBE_stop HOTSPOT_THREAD_STOP
 127 
 128   #define DTRACE_THREAD_PROBE(probe, javathread)                           \
 129     {                                                                      \
 130       ResourceMark rm(this);                                               \
 131       int len = 0;                                                         \
 132       const char* name = (javathread)-&gt;get_thread_name();                  \
 133       len = strlen(name);                                                  \
 134       HOTSPOT_THREAD_PROBE_##probe(/* probe = start, stop */               \
 135         (char *) name, len,                                                \
 136         java_lang_Thread::thread_id((javathread)-&gt;threadObj()),            \
 137         (uintptr_t) (javathread)-&gt;osthread()-&gt;thread_id(),                 \
 138         java_lang_Thread::is_daemon((javathread)-&gt;threadObj()));           \
 139     }
 140 
 141 #else //  ndef DTRACE_ENABLED
 142 
 143   #define DTRACE_THREAD_PROBE(probe, javathread)
 144 
 145 #endif // ndef DTRACE_ENABLED
 146 
 147 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 148 // Current thread is maintained as a thread-local variable
 149 THREAD_LOCAL_DECL Thread* Thread::_thr_current = NULL;
 150 #endif
 151 
 152 // Class hierarchy
 153 // - Thread
 154 //   - VMThread
 155 //   - WatcherThread
 156 //   - ConcurrentMarkSweepThread
 157 //   - JavaThread
 158 //     - CompilerThread
 159 
 160 // ======= Thread ========
 161 // Support for forcing alignment of thread objects for biased locking
 162 void* Thread::allocate(size_t size, bool throw_excpt, MEMFLAGS flags) {
 163   if (UseBiasedLocking) {
 164     const int alignment = markOopDesc::biased_lock_alignment;
 165     size_t aligned_size = size + (alignment - sizeof(intptr_t));
 166     void* real_malloc_addr = throw_excpt? AllocateHeap(aligned_size, flags, CURRENT_PC)
 167                                           : AllocateHeap(aligned_size, flags, CURRENT_PC,
 168                                                          AllocFailStrategy::RETURN_NULL);
 169     void* aligned_addr     = (void*) align_size_up((intptr_t) real_malloc_addr, alignment);
 170     assert(((uintptr_t) aligned_addr + (uintptr_t) size) &lt;=
 171            ((uintptr_t) real_malloc_addr + (uintptr_t) aligned_size),
 172            "JavaThread alignment code overflowed allocated storage");
 173     if (aligned_addr != real_malloc_addr) {
 174       log_info(biasedlocking)("Aligned thread " INTPTR_FORMAT " to " INTPTR_FORMAT,
 175                               p2i(real_malloc_addr),
 176                               p2i(aligned_addr));
 177     }
 178     ((Thread*) aligned_addr)-&gt;_real_malloc_address = real_malloc_addr;
 179     return aligned_addr;
 180   } else {
 181     return throw_excpt? AllocateHeap(size, flags, CURRENT_PC)
 182                        : AllocateHeap(size, flags, CURRENT_PC, AllocFailStrategy::RETURN_NULL);
 183   }
 184 }
 185 
 186 void Thread::operator delete(void* p) {
 187   if (UseBiasedLocking) {
 188     void* real_malloc_addr = ((Thread*) p)-&gt;_real_malloc_address;
 189     FreeHeap(real_malloc_addr);
 190   } else {
 191     FreeHeap(p);
 192   }
 193 }
 194 
 195 
 196 // Base class for all threads: VMThread, WatcherThread, ConcurrentMarkSweepThread,
 197 // JavaThread
 198 
 199 
 200 Thread::Thread() {
 201   // stack and get_thread
 202   set_stack_base(NULL);
 203   set_stack_size(0);
 204   set_self_raw_id(0);
 205   set_lgrp_id(-1);
 206   DEBUG_ONLY(clear_suspendible_thread();)
 207 
 208   // allocated data structures
 209   set_osthread(NULL);
 210   set_resource_area(new (mtThread)ResourceArea());
 211   DEBUG_ONLY(_current_resource_mark = NULL;)
 212   set_handle_area(new (mtThread) HandleArea(NULL));
 213   set_metadata_handles(new (ResourceObj::C_HEAP, mtClass) GrowableArray&lt;Metadata*&gt;(30, true));
 214   set_active_handles(NULL);
 215   set_free_handle_block(NULL);
 216   set_last_handle_mark(NULL);
 217 
 218   // This initial value ==&gt; never claimed.
 219   _oops_do_parity = 0;
 220 
 221   // the handle mark links itself to last_handle_mark
 222   new HandleMark(this);
 223 
 224   // plain initialization
 225   debug_only(_owned_locks = NULL;)
 226   debug_only(_allow_allocation_count = 0;)
 227   NOT_PRODUCT(_allow_safepoint_count = 0;)
 228   NOT_PRODUCT(_skip_gcalot = false;)
 229   _jvmti_env_iteration_count = 0;
 230   set_allocated_bytes(0);
 231   _vm_operation_started_count = 0;
 232   _vm_operation_completed_count = 0;
 233   _current_pending_monitor = NULL;
 234   _current_pending_monitor_is_from_java = true;
 235   _current_waiting_monitor = NULL;
 236   _num_nested_signal = 0;
 237   omFreeList = NULL;
 238   omFreeCount = 0;
 239   omFreeProvision = 32;
 240   omInUseList = NULL;
 241   omInUseCount = 0;
 242 
 243 #ifdef ASSERT
 244   _visited_for_critical_count = false;
 245 #endif
 246 
 247   _SR_lock = new Monitor(Mutex::suspend_resume, "SR_lock", true,
 248                          Monitor::_safepoint_check_sometimes);
 249   _suspend_flags = 0;
 250 
 251   // thread-specific hashCode stream generator state - Marsaglia shift-xor form
 252   _hashStateX = os::random();
 253   _hashStateY = 842502087;
 254   _hashStateZ = 0x8767;    // (int)(3579807591LL &amp; 0xffff) ;
 255   _hashStateW = 273326509;
 256 
 257   _OnTrap   = 0;
 258   _schedctl = NULL;
 259   _Stalled  = 0;
 260   _TypeTag  = 0x2BAD;
 261 
 262   // Many of the following fields are effectively final - immutable
 263   // Note that nascent threads can't use the Native Monitor-Mutex
 264   // construct until the _MutexEvent is initialized ...
 265   // CONSIDER: instead of using a fixed set of purpose-dedicated ParkEvents
 266   // we might instead use a stack of ParkEvents that we could provision on-demand.
 267   // The stack would act as a cache to avoid calls to ParkEvent::Allocate()
 268   // and ::Release()
 269   _ParkEvent   = ParkEvent::Allocate(this);
 270   _SleepEvent  = ParkEvent::Allocate(this);
 271   _MutexEvent  = ParkEvent::Allocate(this);
 272   _MuxEvent    = ParkEvent::Allocate(this);
 273 
 274 #ifdef CHECK_UNHANDLED_OOPS
 275   if (CheckUnhandledOops) {
 276     _unhandled_oops = new UnhandledOops(this);
 277   }
 278 #endif // CHECK_UNHANDLED_OOPS
 279 #ifdef ASSERT
 280   if (UseBiasedLocking) {
 281     assert((((uintptr_t) this) &amp; (markOopDesc::biased_lock_alignment - 1)) == 0, "forced alignment of thread object failed");
 282     assert(this == _real_malloc_address ||
 283            this == (void*) align_size_up((intptr_t) _real_malloc_address, markOopDesc::biased_lock_alignment),
 284            "bug in forced alignment of thread objects");
 285   }
 286 #endif // ASSERT
 287 }
 288 
 289 void Thread::initialize_thread_current() {
 290 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 291   assert(_thr_current == NULL, "Thread::current already initialized");
 292   _thr_current = this;
 293 #endif
 294   assert(ThreadLocalStorage::thread() == NULL, "ThreadLocalStorage::thread already initialized");
 295   ThreadLocalStorage::set_thread(this);
 296   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 297 }
 298 
 299 void Thread::clear_thread_current() {
 300   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 301 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 302   _thr_current = NULL;
 303 #endif
 304   ThreadLocalStorage::set_thread(NULL);
 305 }
 306 
 307 void Thread::record_stack_base_and_size() {
 308   set_stack_base(os::current_stack_base());
 309   set_stack_size(os::current_stack_size());
 310   // CR 7190089: on Solaris, primordial thread's stack is adjusted
 311   // in initialize_thread(). Without the adjustment, stack size is
 312   // incorrect if stack is set to unlimited (ulimit -s unlimited).
 313   // So far, only Solaris has real implementation of initialize_thread().
 314   //
 315   // set up any platform-specific state.
 316   os::initialize_thread(this);
 317 
 318   // Set stack limits after thread is initialized.
 319   if (is_Java_thread()) {
 320     ((JavaThread*) this)-&gt;set_stack_overflow_limit();
 321     ((JavaThread*) this)-&gt;set_reserved_stack_activation(stack_base());
 322   }
 323 #if INCLUDE_NMT
 324   // record thread's native stack, stack grows downward
 325   MemTracker::record_thread_stack(stack_end(), stack_size());
 326 #endif // INCLUDE_NMT
 327   log_debug(os, thread)("Thread " UINTX_FORMAT " stack dimensions: "
 328     PTR_FORMAT "-" PTR_FORMAT " (" SIZE_FORMAT "k).",
 329     os::current_thread_id(), p2i(stack_base() - stack_size()),
 330     p2i(stack_base()), stack_size()/1024);
 331 }
 332 
 333 
 334 Thread::~Thread() {
 335   // Reclaim the objectmonitors from the omFreeList of the moribund thread.
 336   ObjectSynchronizer::omFlush(this);
 337 
 338   EVENT_THREAD_DESTRUCT(this);
 339 
 340   // stack_base can be NULL if the thread is never started or exited before
 341   // record_stack_base_and_size called. Although, we would like to ensure
 342   // that all started threads do call record_stack_base_and_size(), there is
 343   // not proper way to enforce that.
 344 #if INCLUDE_NMT
 345   if (_stack_base != NULL) {
 346     MemTracker::release_thread_stack(stack_end(), stack_size());
 347 #ifdef ASSERT
 348     set_stack_base(NULL);
 349 #endif
 350   }
 351 #endif // INCLUDE_NMT
 352 
 353   // deallocate data structures
 354   delete resource_area();
 355   // since the handle marks are using the handle area, we have to deallocated the root
 356   // handle mark before deallocating the thread's handle area,
 357   assert(last_handle_mark() != NULL, "check we have an element");
 358   delete last_handle_mark();
 359   assert(last_handle_mark() == NULL, "check we have reached the end");
 360 
 361   // It's possible we can encounter a null _ParkEvent, etc., in stillborn threads.
 362   // We NULL out the fields for good hygiene.
 363   ParkEvent::Release(_ParkEvent); _ParkEvent   = NULL;
 364   ParkEvent::Release(_SleepEvent); _SleepEvent  = NULL;
 365   ParkEvent::Release(_MutexEvent); _MutexEvent  = NULL;
 366   ParkEvent::Release(_MuxEvent); _MuxEvent    = NULL;
 367 
 368   delete handle_area();
 369   delete metadata_handles();
 370 
 371   // osthread() can be NULL, if creation of thread failed.
 372   if (osthread() != NULL) os::free_thread(osthread());
 373 
 374   delete _SR_lock;
 375 
 376   // clear Thread::current if thread is deleting itself.
 377   // Needed to ensure JNI correctly detects non-attached threads.
 378   if (this == Thread::current()) {
 379     clear_thread_current();
 380   }
 381 
 382   CHECK_UNHANDLED_OOPS_ONLY(if (CheckUnhandledOops) delete unhandled_oops();)
 383 }
 384 
 385 // NOTE: dummy function for assertion purpose.
 386 void Thread::run() {
 387   ShouldNotReachHere();
 388 }
 389 
 390 #ifdef ASSERT
 391 // Private method to check for dangling thread pointer
 392 void check_for_dangling_thread_pointer(Thread *thread) {
 393   assert(!thread-&gt;is_Java_thread() || Thread::current() == thread || Threads_lock-&gt;owned_by_self(),
 394          "possibility of dangling Thread pointer");
 395 }
 396 #endif
 397 
 398 ThreadPriority Thread::get_priority(const Thread* const thread) {
 399   ThreadPriority priority;
 400   // Can return an error!
 401   (void)os::get_priority(thread, priority);
 402   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "non-Java priority found");
 403   return priority;
 404 }
 405 
 406 void Thread::set_priority(Thread* thread, ThreadPriority priority) {
 407   debug_only(check_for_dangling_thread_pointer(thread);)
 408   // Can return an error!
 409   (void)os::set_priority(thread, priority);
 410 }
 411 
 412 
 413 void Thread::start(Thread* thread) {
 414   // Start is different from resume in that its safety is guaranteed by context or
 415   // being called from a Java method synchronized on the Thread object.
 416   if (!DisableStartThread) {
 417     if (thread-&gt;is_Java_thread()) {
 418       // Initialize the thread state to RUNNABLE before starting this thread.
 419       // Can not set it after the thread started because we do not know the
 420       // exact thread state at that time. It could be in MONITOR_WAIT or
 421       // in SLEEPING or some other state.
 422       java_lang_Thread::set_thread_status(((JavaThread*)thread)-&gt;threadObj(),
 423                                           java_lang_Thread::RUNNABLE);
 424     }
 425     os::start_thread(thread);
 426   }
 427 }
 428 
 429 // Enqueue a VM_Operation to do the job for us - sometime later
 430 void Thread::send_async_exception(oop java_thread, oop java_throwable) {
 431   VM_ThreadStop* vm_stop = new VM_ThreadStop(java_thread, java_throwable);
 432   VMThread::execute(vm_stop);
 433 }
 434 
 435 
 436 // Check if an external suspend request has completed (or has been
 437 // cancelled). Returns true if the thread is externally suspended and
 438 // false otherwise.
 439 //
 440 // The bits parameter returns information about the code path through
 441 // the routine. Useful for debugging:
 442 //
 443 // set in is_ext_suspend_completed():
 444 // 0x00000001 - routine was entered
 445 // 0x00000010 - routine return false at end
 446 // 0x00000100 - thread exited (return false)
 447 // 0x00000200 - suspend request cancelled (return false)
 448 // 0x00000400 - thread suspended (return true)
 449 // 0x00001000 - thread is in a suspend equivalent state (return true)
 450 // 0x00002000 - thread is native and walkable (return true)
 451 // 0x00004000 - thread is native_trans and walkable (needed retry)
 452 //
 453 // set in wait_for_ext_suspend_completion():
 454 // 0x00010000 - routine was entered
 455 // 0x00020000 - suspend request cancelled before loop (return false)
 456 // 0x00040000 - thread suspended before loop (return true)
 457 // 0x00080000 - suspend request cancelled in loop (return false)
 458 // 0x00100000 - thread suspended in loop (return true)
 459 // 0x00200000 - suspend not completed during retry loop (return false)
 460 
 461 // Helper class for tracing suspend wait debug bits.
 462 //
 463 // 0x00000100 indicates that the target thread exited before it could
 464 // self-suspend which is not a wait failure. 0x00000200, 0x00020000 and
 465 // 0x00080000 each indicate a cancelled suspend request so they don't
 466 // count as wait failures either.
 467 #define DEBUG_FALSE_BITS (0x00000010 | 0x00200000)
 468 
 469 class TraceSuspendDebugBits : public StackObj {
 470  private:
 471   JavaThread * jt;
 472   bool         is_wait;
 473   bool         called_by_wait;  // meaningful when !is_wait
 474   uint32_t *   bits;
 475 
 476  public:
 477   TraceSuspendDebugBits(JavaThread *_jt, bool _is_wait, bool _called_by_wait,
 478                         uint32_t *_bits) {
 479     jt             = _jt;
 480     is_wait        = _is_wait;
 481     called_by_wait = _called_by_wait;
 482     bits           = _bits;
 483   }
 484 
 485   ~TraceSuspendDebugBits() {
 486     if (!is_wait) {
 487 #if 1
 488       // By default, don't trace bits for is_ext_suspend_completed() calls.
 489       // That trace is very chatty.
 490       return;
 491 #else
 492       if (!called_by_wait) {
 493         // If tracing for is_ext_suspend_completed() is enabled, then only
 494         // trace calls to it from wait_for_ext_suspend_completion()
 495         return;
 496       }
 497 #endif
 498     }
 499 
 500     if (AssertOnSuspendWaitFailure || TraceSuspendWaitFailures) {
 501       if (bits != NULL &amp;&amp; (*bits &amp; DEBUG_FALSE_BITS) != 0) {
 502         MutexLocker ml(Threads_lock);  // needed for get_thread_name()
 503         ResourceMark rm;
 504 
 505         tty-&gt;print_cr(
 506                       "Failed wait_for_ext_suspend_completion(thread=%s, debug_bits=%x)",
 507                       jt-&gt;get_thread_name(), *bits);
 508 
 509         guarantee(!AssertOnSuspendWaitFailure, "external suspend wait failed");
 510       }
 511     }
 512   }
 513 };
 514 #undef DEBUG_FALSE_BITS
 515 
 516 
 517 bool JavaThread::is_ext_suspend_completed(bool called_by_wait, int delay,
 518                                           uint32_t *bits) {
 519   TraceSuspendDebugBits tsdb(this, false /* !is_wait */, called_by_wait, bits);
 520 
 521   bool did_trans_retry = false;  // only do thread_in_native_trans retry once
 522   bool do_trans_retry;           // flag to force the retry
 523 
 524   *bits |= 0x00000001;
 525 
 526   do {
 527     do_trans_retry = false;
 528 
 529     if (is_exiting()) {
 530       // Thread is in the process of exiting. This is always checked
 531       // first to reduce the risk of dereferencing a freed JavaThread.
 532       *bits |= 0x00000100;
 533       return false;
 534     }
 535 
 536     if (!is_external_suspend()) {
 537       // Suspend request is cancelled. This is always checked before
 538       // is_ext_suspended() to reduce the risk of a rogue resume
 539       // confusing the thread that made the suspend request.
 540       *bits |= 0x00000200;
 541       return false;
 542     }
 543 
 544     if (is_ext_suspended()) {
 545       // thread is suspended
 546       *bits |= 0x00000400;
 547       return true;
 548     }
 549 
 550     // Now that we no longer do hard suspends of threads running
 551     // native code, the target thread can be changing thread state
 552     // while we are in this routine:
 553     //
 554     //   _thread_in_native -&gt; _thread_in_native_trans -&gt; _thread_blocked
 555     //
 556     // We save a copy of the thread state as observed at this moment
 557     // and make our decision about suspend completeness based on the
 558     // copy. This closes the race where the thread state is seen as
 559     // _thread_in_native_trans in the if-thread_blocked check, but is
 560     // seen as _thread_blocked in if-thread_in_native_trans check.
 561     JavaThreadState save_state = thread_state();
 562 
 563     if (save_state == _thread_blocked &amp;&amp; is_suspend_equivalent()) {
 564       // If the thread's state is _thread_blocked and this blocking
 565       // condition is known to be equivalent to a suspend, then we can
 566       // consider the thread to be externally suspended. This means that
 567       // the code that sets _thread_blocked has been modified to do
 568       // self-suspension if the blocking condition releases. We also
 569       // used to check for CONDVAR_WAIT here, but that is now covered by
 570       // the _thread_blocked with self-suspension check.
 571       //
 572       // Return true since we wouldn't be here unless there was still an
 573       // external suspend request.
 574       *bits |= 0x00001000;
 575       return true;
 576     } else if (save_state == _thread_in_native &amp;&amp; frame_anchor()-&gt;walkable()) {
 577       // Threads running native code will self-suspend on native==&gt;VM/Java
 578       // transitions. If its stack is walkable (should always be the case
 579       // unless this function is called before the actual java_suspend()
 580       // call), then the wait is done.
 581       *bits |= 0x00002000;
 582       return true;
 583     } else if (!called_by_wait &amp;&amp; !did_trans_retry &amp;&amp;
 584                save_state == _thread_in_native_trans &amp;&amp;
 585                frame_anchor()-&gt;walkable()) {
 586       // The thread is transitioning from thread_in_native to another
 587       // thread state. check_safepoint_and_suspend_for_native_trans()
 588       // will force the thread to self-suspend. If it hasn't gotten
 589       // there yet we may have caught the thread in-between the native
 590       // code check above and the self-suspend. Lucky us. If we were
 591       // called by wait_for_ext_suspend_completion(), then it
 592       // will be doing the retries so we don't have to.
 593       //
 594       // Since we use the saved thread state in the if-statement above,
 595       // there is a chance that the thread has already transitioned to
 596       // _thread_blocked by the time we get here. In that case, we will
 597       // make a single unnecessary pass through the logic below. This
 598       // doesn't hurt anything since we still do the trans retry.
 599 
 600       *bits |= 0x00004000;
 601 
 602       // Once the thread leaves thread_in_native_trans for another
 603       // thread state, we break out of this retry loop. We shouldn't
 604       // need this flag to prevent us from getting back here, but
 605       // sometimes paranoia is good.
 606       did_trans_retry = true;
 607 
 608       // We wait for the thread to transition to a more usable state.
 609       for (int i = 1; i &lt;= SuspendRetryCount; i++) {
 610         // We used to do an "os::yield_all(i)" call here with the intention
 611         // that yielding would increase on each retry. However, the parameter
 612         // is ignored on Linux which means the yield didn't scale up. Waiting
 613         // on the SR_lock below provides a much more predictable scale up for
 614         // the delay. It also provides a simple/direct point to check for any
 615         // safepoint requests from the VMThread
 616 
 617         // temporarily drops SR_lock while doing wait with safepoint check
 618         // (if we're a JavaThread - the WatcherThread can also call this)
 619         // and increase delay with each retry
 620         SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 621 
 622         // check the actual thread state instead of what we saved above
 623         if (thread_state() != _thread_in_native_trans) {
 624           // the thread has transitioned to another thread state so
 625           // try all the checks (except this one) one more time.
 626           do_trans_retry = true;
 627           break;
 628         }
 629       } // end retry loop
 630 
 631 
 632     }
 633   } while (do_trans_retry);
 634 
 635   *bits |= 0x00000010;
 636   return false;
 637 }
 638 
 639 // Wait for an external suspend request to complete (or be cancelled).
 640 // Returns true if the thread is externally suspended and false otherwise.
 641 //
 642 bool JavaThread::wait_for_ext_suspend_completion(int retries, int delay,
 643                                                  uint32_t *bits) {
 644   TraceSuspendDebugBits tsdb(this, true /* is_wait */,
 645                              false /* !called_by_wait */, bits);
 646 
 647   // local flag copies to minimize SR_lock hold time
 648   bool is_suspended;
 649   bool pending;
 650   uint32_t reset_bits;
 651 
 652   // set a marker so is_ext_suspend_completed() knows we are the caller
 653   *bits |= 0x00010000;
 654 
 655   // We use reset_bits to reinitialize the bits value at the top of
 656   // each retry loop. This allows the caller to make use of any
 657   // unused bits for their own marking purposes.
 658   reset_bits = *bits;
 659 
 660   {
 661     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
 662     is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 663                                             delay, bits);
 664     pending = is_external_suspend();
 665   }
 666   // must release SR_lock to allow suspension to complete
 667 
 668   if (!pending) {
 669     // A cancelled suspend request is the only false return from
 670     // is_ext_suspend_completed() that keeps us from entering the
 671     // retry loop.
 672     *bits |= 0x00020000;
 673     return false;
 674   }
 675 
 676   if (is_suspended) {
 677     *bits |= 0x00040000;
 678     return true;
 679   }
 680 
 681   for (int i = 1; i &lt;= retries; i++) {
 682     *bits = reset_bits;  // reinit to only track last retry
 683 
 684     // We used to do an "os::yield_all(i)" call here with the intention
 685     // that yielding would increase on each retry. However, the parameter
 686     // is ignored on Linux which means the yield didn't scale up. Waiting
 687     // on the SR_lock below provides a much more predictable scale up for
 688     // the delay. It also provides a simple/direct point to check for any
 689     // safepoint requests from the VMThread
 690 
 691     {
 692       MutexLocker ml(SR_lock());
 693       // wait with safepoint check (if we're a JavaThread - the WatcherThread
 694       // can also call this)  and increase delay with each retry
 695       SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 696 
 697       is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 698                                               delay, bits);
 699 
 700       // It is possible for the external suspend request to be cancelled
 701       // (by a resume) before the actual suspend operation is completed.
 702       // Refresh our local copy to see if we still need to wait.
 703       pending = is_external_suspend();
 704     }
 705 
 706     if (!pending) {
 707       // A cancelled suspend request is the only false return from
 708       // is_ext_suspend_completed() that keeps us from staying in the
 709       // retry loop.
 710       *bits |= 0x00080000;
 711       return false;
 712     }
 713 
 714     if (is_suspended) {
 715       *bits |= 0x00100000;
 716       return true;
 717     }
 718   } // end retry loop
 719 
 720   // thread did not suspend after all our retries
 721   *bits |= 0x00200000;
 722   return false;
 723 }
 724 
 725 #ifndef PRODUCT
 726 void JavaThread::record_jump(address target, address instr, const char* file,
 727                              int line) {
 728 
 729   // This should not need to be atomic as the only way for simultaneous
 730   // updates is via interrupts. Even then this should be rare or non-existent
 731   // and we don't care that much anyway.
 732 
 733   int index = _jmp_ring_index;
 734   _jmp_ring_index = (index + 1) &amp; (jump_ring_buffer_size - 1);
 735   _jmp_ring[index]._target = (intptr_t) target;
 736   _jmp_ring[index]._instruction = (intptr_t) instr;
 737   _jmp_ring[index]._file = file;
 738   _jmp_ring[index]._line = line;
 739 }
 740 #endif // PRODUCT
 741 
 742 // Called by flat profiler
 743 // Callers have already called wait_for_ext_suspend_completion
 744 // The assertion for that is currently too complex to put here:
 745 bool JavaThread::profile_last_Java_frame(frame* _fr) {
 746   bool gotframe = false;
 747   // self suspension saves needed state.
 748   if (has_last_Java_frame() &amp;&amp; _anchor.walkable()) {
 749     *_fr = pd_last_frame();
 750     gotframe = true;
 751   }
 752   return gotframe;
 753 }
 754 
 755 void Thread::interrupt(Thread* thread) {
 756   debug_only(check_for_dangling_thread_pointer(thread);)
 757   os::interrupt(thread);
 758 }
 759 
 760 bool Thread::is_interrupted(Thread* thread, bool clear_interrupted) {
 761   debug_only(check_for_dangling_thread_pointer(thread);)
 762   // Note:  If clear_interrupted==false, this simply fetches and
 763   // returns the value of the field osthread()-&gt;interrupted().
 764   return os::is_interrupted(thread, clear_interrupted);
 765 }
 766 
 767 
 768 // GC Support
 769 bool Thread::claim_oops_do_par_case(int strong_roots_parity) {
 770   jint thread_parity = _oops_do_parity;
 771   if (thread_parity != strong_roots_parity) {
 772     jint res = Atomic::cmpxchg(strong_roots_parity, &amp;_oops_do_parity, thread_parity);
 773     if (res == thread_parity) {
 774       return true;
 775     } else {
 776       guarantee(res == strong_roots_parity, "Or else what?");
 777       return false;
 778     }
 779   }
 780   return false;
 781 }
 782 
 783 void Thread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
 784   active_handles()-&gt;oops_do(f);
 785   // Do oop for ThreadShadow
 786   f-&gt;do_oop((oop*)&amp;_pending_exception);
 787   handle_area()-&gt;oops_do(f);
 788 }
 789 
 790 void Thread::nmethods_do(CodeBlobClosure* cf) {
 791   // no nmethods in a generic thread...
 792 }
 793 
 794 void Thread::metadata_handles_do(void f(Metadata*)) {
 795   // Only walk the Handles in Thread.
 796   if (metadata_handles() != NULL) {
 797     for (int i = 0; i&lt; metadata_handles()-&gt;length(); i++) {
 798       f(metadata_handles()-&gt;at(i));
 799     }
 800   }
 801 }
 802 
 803 void Thread::print_on(outputStream* st) const {
 804   // get_priority assumes osthread initialized
 805   if (osthread() != NULL) {
 806     int os_prio;
 807     if (os::get_native_priority(this, &amp;os_prio) == OS_OK) {
 808       st-&gt;print("os_prio=%d ", os_prio);
 809     }
 810     st-&gt;print("tid=" INTPTR_FORMAT " ", p2i(this));
 811     ext().print_on(st);
 812     osthread()-&gt;print_on(st);
 813   }
 814   debug_only(if (WizardMode) print_owned_locks_on(st);)
 815 }
 816 
 817 // Thread::print_on_error() is called by fatal error handler. Don't use
 818 // any lock or allocate memory.
 819 void Thread::print_on_error(outputStream* st, char* buf, int buflen) const {
 820   if (is_VM_thread())                 st-&gt;print("VMThread");
 821   else if (is_Compiler_thread())      st-&gt;print("CompilerThread");
 822   else if (is_Java_thread())          st-&gt;print("JavaThread");
 823   else if (is_GC_task_thread())       st-&gt;print("GCTaskThread");
 824   else if (is_Watcher_thread())       st-&gt;print("WatcherThread");
 825   else if (is_ConcurrentGC_thread())  st-&gt;print("ConcurrentGCThread");
 826   else                                st-&gt;print("Thread");
 827 
 828   st-&gt;print(" [stack: " PTR_FORMAT "," PTR_FORMAT "]",
 829             p2i(stack_end()), p2i(stack_base()));
 830 
 831   if (osthread()) {
 832     st-&gt;print(" [id=%d]", osthread()-&gt;thread_id());
 833   }
 834 }
 835 
 836 #ifdef ASSERT
 837 void Thread::print_owned_locks_on(outputStream* st) const {
 838   Monitor *cur = _owned_locks;
 839   if (cur == NULL) {
 840     st-&gt;print(" (no locks) ");
 841   } else {
 842     st-&gt;print_cr(" Locks owned:");
 843     while (cur) {
 844       cur-&gt;print_on(st);
 845       cur = cur-&gt;next();
 846     }
 847   }
 848 }
 849 
 850 static int ref_use_count  = 0;
 851 
 852 bool Thread::owns_locks_but_compiled_lock() const {
 853   for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 854     if (cur != Compile_lock) return true;
 855   }
 856   return false;
 857 }
 858 
 859 
 860 #endif
 861 
 862 #ifndef PRODUCT
 863 
 864 // The flag: potential_vm_operation notifies if this particular safepoint state could potential
 865 // invoke the vm-thread (i.e., and oop allocation). In that case, we also have to make sure that
 866 // no threads which allow_vm_block's are held
 867 void Thread::check_for_valid_safepoint_state(bool potential_vm_operation) {
 868   // Check if current thread is allowed to block at a safepoint
 869   if (!(_allow_safepoint_count == 0)) {
 870     fatal("Possible safepoint reached by thread that does not allow it");
 871   }
 872   if (is_Java_thread() &amp;&amp; ((JavaThread*)this)-&gt;thread_state() != _thread_in_vm) {
 873     fatal("LEAF method calling lock?");
 874   }
 875 
 876 #ifdef ASSERT
 877   if (potential_vm_operation &amp;&amp; is_Java_thread()
 878       &amp;&amp; !Universe::is_bootstrapping()) {
 879     // Make sure we do not hold any locks that the VM thread also uses.
 880     // This could potentially lead to deadlocks
 881     for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 882       // Threads_lock is special, since the safepoint synchronization will not start before this is
 883       // acquired. Hence, a JavaThread cannot be holding it at a safepoint. So is VMOperationRequest_lock,
 884       // since it is used to transfer control between JavaThreads and the VMThread
 885       // Do not *exclude* any locks unless you are absolutely sure it is correct. Ask someone else first!
 886       if ((cur-&gt;allow_vm_block() &amp;&amp;
 887            cur != Threads_lock &amp;&amp;
 888            cur != Compile_lock &amp;&amp;               // Temporary: should not be necessary when we get separate compilation
 889            cur != VMOperationRequest_lock &amp;&amp;
 890            cur != VMOperationQueue_lock) ||
 891            cur-&gt;rank() == Mutex::special) {
 892         fatal("Thread holding lock at safepoint that vm can block on: %s", cur-&gt;name());
 893       }
 894     }
 895   }
 896 
 897   if (GCALotAtAllSafepoints) {
 898     // We could enter a safepoint here and thus have a gc
 899     InterfaceSupport::check_gc_alot();
 900   }
 901 #endif
 902 }
 903 #endif
 904 
 905 bool Thread::is_in_stack(address adr) const {
 906   assert(Thread::current() == this, "is_in_stack can only be called from current thread");
 907   address end = os::current_stack_pointer();
 908   // Allow non Java threads to call this without stack_base
 909   if (_stack_base == NULL) return true;
 910   if (stack_base() &gt;= adr &amp;&amp; adr &gt;= end) return true;
 911 
 912   return false;
 913 }
 914 
 915 bool Thread::is_in_usable_stack(address adr) const {
 916   size_t stack_guard_size = os::uses_stack_guard_pages() ? JavaThread::stack_guard_zone_size() : 0;
 917   size_t usable_stack_size = _stack_size - stack_guard_size;
 918 
 919   return ((adr &lt; stack_base()) &amp;&amp; (adr &gt;= stack_base() - usable_stack_size));
 920 }
 921 
 922 
 923 // We had to move these methods here, because vm threads get into ObjectSynchronizer::enter
 924 // However, there is a note in JavaThread::is_lock_owned() about the VM threads not being
 925 // used for compilation in the future. If that change is made, the need for these methods
 926 // should be revisited, and they should be removed if possible.
 927 
 928 bool Thread::is_lock_owned(address adr) const {
 929   return on_local_stack(adr);
 930 }
 931 
 932 bool Thread::set_as_starting_thread() {
 933   // NOTE: this must be called inside the main thread.
 934   return os::create_main_thread((JavaThread*)this);
 935 }
 936 
 937 static void initialize_class(Symbol* class_name, TRAPS) {
 938   Klass* klass = SystemDictionary::resolve_or_fail(class_name, true, CHECK);
 939   InstanceKlass::cast(klass)-&gt;initialize(CHECK);
 940 }
 941 
 942 
 943 // Creates the initial ThreadGroup
 944 static Handle create_initial_thread_group(TRAPS) {
 945   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_ThreadGroup(), true, CHECK_NH);
 946   instanceKlassHandle klass (THREAD, k);
 947 
 948   Handle system_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 949   {
 950     JavaValue result(T_VOID);
 951     JavaCalls::call_special(&amp;result,
 952                             system_instance,
 953                             klass,
 954                             vmSymbols::object_initializer_name(),
 955                             vmSymbols::void_method_signature(),
 956                             CHECK_NH);
 957   }
 958   Universe::set_system_thread_group(system_instance());
 959 
 960   Handle main_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 961   {
 962     JavaValue result(T_VOID);
 963     Handle string = java_lang_String::create_from_str("main", CHECK_NH);
 964     JavaCalls::call_special(&amp;result,
 965                             main_instance,
 966                             klass,
 967                             vmSymbols::object_initializer_name(),
 968                             vmSymbols::threadgroup_string_void_signature(),
 969                             system_instance,
 970                             string,
 971                             CHECK_NH);
 972   }
 973   return main_instance;
 974 }
 975 
 976 // Creates the initial Thread
 977 static oop create_initial_thread(Handle thread_group, JavaThread* thread,
 978                                  TRAPS) {
 979   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK_NULL);
 980   instanceKlassHandle klass (THREAD, k);
 981   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK_NULL);
 982 
 983   java_lang_Thread::set_thread(thread_oop(), thread);
 984   java_lang_Thread::set_priority(thread_oop(), NormPriority);
 985   thread-&gt;set_threadObj(thread_oop());
 986 
 987   Handle string = java_lang_String::create_from_str("main", CHECK_NULL);
 988 
 989   JavaValue result(T_VOID);
 990   JavaCalls::call_special(&amp;result, thread_oop,
 991                           klass,
 992                           vmSymbols::object_initializer_name(),
 993                           vmSymbols::threadgroup_string_void_signature(),
 994                           thread_group,
 995                           string,
 996                           CHECK_NULL);
 997   return thread_oop();
 998 }
 999 
1000 static void call_initializeSystemClass(TRAPS) {
1001   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
1002   instanceKlassHandle klass (THREAD, k);
1003 
1004   JavaValue result(T_VOID);
1005   JavaCalls::call_static(&amp;result, klass, vmSymbols::initializeSystemClass_name(),
1006                          vmSymbols::void_method_signature(), CHECK);
1007 }
1008 
1009 char java_runtime_name[128] = "";
1010 char java_runtime_version[128] = "";
1011 
1012 // extract the JRE name from java.lang.VersionProps.java_runtime_name
1013 static const char* get_java_runtime_name(TRAPS) {
1014   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1015                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1016   fieldDescriptor fd;
1017   bool found = k != NULL &amp;&amp;
1018                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_name_name(),
1019                                                         vmSymbols::string_signature(), &amp;fd);
1020   if (found) {
1021     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1022     if (name_oop == NULL) {
1023       return NULL;
1024     }
1025     const char* name = java_lang_String::as_utf8_string(name_oop,
1026                                                         java_runtime_name,
1027                                                         sizeof(java_runtime_name));
1028     return name;
1029   } else {
1030     return NULL;
1031   }
1032 }
1033 
1034 // extract the JRE version from java.lang.VersionProps.java_runtime_version
1035 static const char* get_java_runtime_version(TRAPS) {
1036   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1037                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1038   fieldDescriptor fd;
1039   bool found = k != NULL &amp;&amp;
1040                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_version_name(),
1041                                                         vmSymbols::string_signature(), &amp;fd);
1042   if (found) {
1043     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1044     if (name_oop == NULL) {
1045       return NULL;
1046     }
1047     const char* name = java_lang_String::as_utf8_string(name_oop,
1048                                                         java_runtime_version,
1049                                                         sizeof(java_runtime_version));
1050     return name;
1051   } else {
1052     return NULL;
1053   }
1054 }
1055 
1056 // General purpose hook into Java code, run once when the VM is initialized.
1057 // The Java library method itself may be changed independently from the VM.
1058 static void call_postVMInitHook(TRAPS) {
1059   Klass* k = SystemDictionary::resolve_or_null(vmSymbols::sun_misc_PostVMInitHook(), THREAD);
1060   instanceKlassHandle klass (THREAD, k);
1061   if (klass.not_null()) {
1062     JavaValue result(T_VOID);
1063     JavaCalls::call_static(&amp;result, klass, vmSymbols::run_method_name(),
1064                            vmSymbols::void_method_signature(),
1065                            CHECK);
1066   }
1067 }
1068 
1069 static void reset_vm_info_property(TRAPS) {
1070   // the vm info string
1071   ResourceMark rm(THREAD);
1072   const char *vm_info = VM_Version::vm_info_string();
1073 
1074   // java.lang.System class
1075   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
1076   instanceKlassHandle klass (THREAD, k);
1077 
1078   // setProperty arguments
1079   Handle key_str    = java_lang_String::create_from_str("java.vm.info", CHECK);
1080   Handle value_str  = java_lang_String::create_from_str(vm_info, CHECK);
1081 
1082   // return value
1083   JavaValue r(T_OBJECT);
1084 
1085   // public static String setProperty(String key, String value);
1086   JavaCalls::call_static(&amp;r,
1087                          klass,
1088                          vmSymbols::setProperty_name(),
1089                          vmSymbols::string_string_string_signature(),
1090                          key_str,
1091                          value_str,
1092                          CHECK);
1093 }
1094 
1095 
1096 void JavaThread::allocate_threadObj(Handle thread_group, const char* thread_name,
1097                                     bool daemon, TRAPS) {
1098   assert(thread_group.not_null(), "thread group should be specified");
1099   assert(threadObj() == NULL, "should only create Java thread object once");
1100 
1101   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK);
1102   instanceKlassHandle klass (THREAD, k);
1103   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK);
1104 
1105   java_lang_Thread::set_thread(thread_oop(), this);
1106   java_lang_Thread::set_priority(thread_oop(), NormPriority);
1107   set_threadObj(thread_oop());
1108 
1109   JavaValue result(T_VOID);
1110   if (thread_name != NULL) {
1111     Handle name = java_lang_String::create_from_str(thread_name, CHECK);
1112     // Thread gets assigned specified name and null target
1113     JavaCalls::call_special(&amp;result,
1114                             thread_oop,
1115                             klass,
1116                             vmSymbols::object_initializer_name(),
1117                             vmSymbols::threadgroup_string_void_signature(),
1118                             thread_group, // Argument 1
1119                             name,         // Argument 2
1120                             THREAD);
1121   } else {
1122     // Thread gets assigned name "Thread-nnn" and null target
1123     // (java.lang.Thread doesn't have a constructor taking only a ThreadGroup argument)
1124     JavaCalls::call_special(&amp;result,
1125                             thread_oop,
1126                             klass,
1127                             vmSymbols::object_initializer_name(),
1128                             vmSymbols::threadgroup_runnable_void_signature(),
1129                             thread_group, // Argument 1
1130                             Handle(),     // Argument 2
1131                             THREAD);
1132   }
1133 
1134 
1135   if (daemon) {
1136     java_lang_Thread::set_daemon(thread_oop());
1137   }
1138 
1139   if (HAS_PENDING_EXCEPTION) {
1140     return;
1141   }
1142 
1143   KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass());
1144   Handle threadObj(THREAD, this-&gt;threadObj());
1145 
1146   JavaCalls::call_special(&amp;result,
1147                           thread_group,
1148                           group,
1149                           vmSymbols::add_method_name(),
1150                           vmSymbols::thread_void_signature(),
1151                           threadObj,          // Arg 1
1152                           THREAD);
1153 }
1154 
1155 // NamedThread --  non-JavaThread subclasses with multiple
1156 // uniquely named instances should derive from this.
1157 NamedThread::NamedThread() : Thread() {
1158   _name = NULL;
1159   _processed_thread = NULL;
1160   _gc_id = GCId::undefined();
1161 }
1162 
1163 NamedThread::~NamedThread() {
1164   if (_name != NULL) {
1165     FREE_C_HEAP_ARRAY(char, _name);
1166     _name = NULL;
1167   }
1168 }
1169 
1170 void NamedThread::set_name(const char* format, ...) {
1171   guarantee(_name == NULL, "Only get to set name once.");
1172   _name = NEW_C_HEAP_ARRAY(char, max_name_len, mtThread);
1173   guarantee(_name != NULL, "alloc failure");
1174   va_list ap;
1175   va_start(ap, format);
1176   jio_vsnprintf(_name, max_name_len, format, ap);
1177   va_end(ap);
1178 }
1179 
1180 void NamedThread::initialize_named_thread() {
1181   set_native_thread_name(name());
1182 }
1183 
1184 void NamedThread::print_on(outputStream* st) const {
1185   st-&gt;print("\"%s\" ", name());
1186   Thread::print_on(st);
1187   st-&gt;cr();
1188 }
1189 
1190 
1191 // ======= WatcherThread ========
1192 
1193 // The watcher thread exists to simulate timer interrupts.  It should
1194 // be replaced by an abstraction over whatever native support for
1195 // timer interrupts exists on the platform.
1196 
1197 WatcherThread* WatcherThread::_watcher_thread   = NULL;
1198 bool WatcherThread::_startable = false;
1199 volatile bool  WatcherThread::_should_terminate = false;
1200 
1201 WatcherThread::WatcherThread() : Thread(), _crash_protection(NULL) {
1202   assert(watcher_thread() == NULL, "we can only allocate one WatcherThread");
1203   if (os::create_thread(this, os::watcher_thread)) {
1204     _watcher_thread = this;
1205 
1206     // Set the watcher thread to the highest OS priority which should not be
1207     // used, unless a Java thread with priority java.lang.Thread.MAX_PRIORITY
1208     // is created. The only normal thread using this priority is the reference
1209     // handler thread, which runs for very short intervals only.
1210     // If the VMThread's priority is not lower than the WatcherThread profiling
1211     // will be inaccurate.
1212     os::set_priority(this, MaxPriority);
1213     if (!DisableStartThread) {
1214       os::start_thread(this);
1215     }
1216   }
1217 }
1218 
1219 int WatcherThread::sleep() const {
1220   // The WatcherThread does not participate in the safepoint protocol
1221   // for the PeriodicTask_lock because it is not a JavaThread.
1222   MutexLockerEx ml(PeriodicTask_lock, Mutex::_no_safepoint_check_flag);
1223 
1224   if (_should_terminate) {
1225     // check for termination before we do any housekeeping or wait
1226     return 0;  // we did not sleep.
1227   }
1228 
1229   // remaining will be zero if there are no tasks,
1230   // causing the WatcherThread to sleep until a task is
1231   // enrolled
1232   int remaining = PeriodicTask::time_to_wait();
1233   int time_slept = 0;
1234 
1235   // we expect this to timeout - we only ever get unparked when
1236   // we should terminate or when a new task has been enrolled
1237   OSThreadWaitState osts(this-&gt;osthread(), false /* not Object.wait() */);
1238 
1239   jlong time_before_loop = os::javaTimeNanos();
1240 
1241   while (true) {
1242     bool timedout = PeriodicTask_lock-&gt;wait(Mutex::_no_safepoint_check_flag,
1243                                             remaining);
1244     jlong now = os::javaTimeNanos();
1245 
1246     if (remaining == 0) {
1247       // if we didn't have any tasks we could have waited for a long time
1248       // consider the time_slept zero and reset time_before_loop
1249       time_slept = 0;
1250       time_before_loop = now;
1251     } else {
1252       // need to recalculate since we might have new tasks in _tasks
1253       time_slept = (int) ((now - time_before_loop) / 1000000);
1254     }
1255 
1256     // Change to task list or spurious wakeup of some kind
1257     if (timedout || _should_terminate) {
1258       break;
1259     }
1260 
1261     remaining = PeriodicTask::time_to_wait();
1262     if (remaining == 0) {
1263       // Last task was just disenrolled so loop around and wait until
1264       // another task gets enrolled
1265       continue;
1266     }
1267 
1268     remaining -= time_slept;
1269     if (remaining &lt;= 0) {
1270       break;
1271     }
1272   }
1273 
1274   return time_slept;
1275 }
1276 
1277 void WatcherThread::run() {
1278   assert(this == watcher_thread(), "just checking");
1279 
1280   this-&gt;record_stack_base_and_size();
1281   this-&gt;set_native_thread_name(this-&gt;name());
1282   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1283   while (true) {
1284     assert(watcher_thread() == Thread::current(), "thread consistency check");
1285     assert(watcher_thread() == this, "thread consistency check");
1286 
1287     // Calculate how long it'll be until the next PeriodicTask work
1288     // should be done, and sleep that amount of time.
1289     int time_waited = sleep();
1290 
1291     if (is_error_reported()) {
1292       // A fatal error has happened, the error handler(VMError::report_and_die)
1293       // should abort JVM after creating an error log file. However in some
1294       // rare cases, the error handler itself might deadlock. Here we try to
1295       // kill JVM if the fatal error handler fails to abort in 2 minutes.
1296       //
1297       // This code is in WatcherThread because WatcherThread wakes up
1298       // periodically so the fatal error handler doesn't need to do anything;
1299       // also because the WatcherThread is less likely to crash than other
1300       // threads.
1301 
1302       for (;;) {
1303         if (!ShowMessageBoxOnError
1304             &amp;&amp; (OnError == NULL || OnError[0] == '\0')
1305             &amp;&amp; Arguments::abort_hook() == NULL) {
1306           os::sleep(this, (jlong)ErrorLogTimeout * 1000, false); // in seconds
1307           fdStream err(defaultStream::output_fd());
1308           err.print_raw_cr("# [ timer expired, abort... ]");
1309           // skip atexit/vm_exit/vm_abort hooks
1310           os::die();
1311         }
1312 
1313         // Wake up 5 seconds later, the fatal handler may reset OnError or
1314         // ShowMessageBoxOnError when it is ready to abort.
1315         os::sleep(this, 5 * 1000, false);
1316       }
1317     }
1318 
1319     if (_should_terminate) {
1320       // check for termination before posting the next tick
1321       break;
1322     }
1323 
1324     PeriodicTask::real_time_tick(time_waited);
1325   }
1326 
1327   // Signal that it is terminated
1328   {
1329     MutexLockerEx mu(Terminator_lock, Mutex::_no_safepoint_check_flag);
1330     _watcher_thread = NULL;
1331     Terminator_lock-&gt;notify();
1332   }
1333 }
1334 
1335 void WatcherThread::start() {
1336   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1337 
1338   if (watcher_thread() == NULL &amp;&amp; _startable) {
1339     _should_terminate = false;
1340     // Create the single instance of WatcherThread
1341     new WatcherThread();
1342   }
1343 }
1344 
1345 void WatcherThread::make_startable() {
1346   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1347   _startable = true;
1348 }
1349 
1350 void WatcherThread::stop() {
1351   {
1352     // Follow normal safepoint aware lock enter protocol since the
1353     // WatcherThread is stopped by another JavaThread.
1354     MutexLocker ml(PeriodicTask_lock);
1355     _should_terminate = true;
1356 
1357     WatcherThread* watcher = watcher_thread();
1358     if (watcher != NULL) {
1359       // unpark the WatcherThread so it can see that it should terminate
1360       watcher-&gt;unpark();
1361     }
1362   }
1363 
1364   MutexLocker mu(Terminator_lock);
1365 
1366   while (watcher_thread() != NULL) {
1367     // This wait should make safepoint checks, wait without a timeout,
1368     // and wait as a suspend-equivalent condition.
1369     //
1370     // Note: If the FlatProfiler is running, then this thread is waiting
1371     // for the WatcherThread to terminate and the WatcherThread, via the
1372     // FlatProfiler task, is waiting for the external suspend request on
1373     // this thread to complete. wait_for_ext_suspend_completion() will
1374     // eventually timeout, but that takes time. Making this wait a
1375     // suspend-equivalent condition solves that timeout problem.
1376     //
1377     Terminator_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
1378                           Mutex::_as_suspend_equivalent_flag);
1379   }
1380 }
1381 
1382 void WatcherThread::unpark() {
1383   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1384   PeriodicTask_lock-&gt;notify();
1385 }
1386 
1387 void WatcherThread::print_on(outputStream* st) const {
1388   st-&gt;print("\"%s\" ", name());
1389   Thread::print_on(st);
1390   st-&gt;cr();
1391 }
1392 
1393 // ======= JavaThread ========
1394 
1395 #if INCLUDE_JVMCI
1396 
1397 jlong* JavaThread::_jvmci_old_thread_counters;
1398 
1399 bool jvmci_counters_include(JavaThread* thread) {
1400   oop threadObj = thread-&gt;threadObj();
1401   return !JVMCICountersExcludeCompiler || !thread-&gt;is_Compiler_thread();
1402 }
1403 
1404 void JavaThread::collect_counters(typeArrayOop array) {
1405   if (JVMCICounterSize &gt; 0) {
1406     MutexLocker tl(Threads_lock);
1407     for (int i = 0; i &lt; array-&gt;length(); i++) {
1408       array-&gt;long_at_put(i, _jvmci_old_thread_counters[i]);
1409     }
1410     for (JavaThread* tp = Threads::first(); tp != NULL; tp = tp-&gt;next()) {
1411       if (jvmci_counters_include(tp)) {
1412         for (int i = 0; i &lt; array-&gt;length(); i++) {
1413           array-&gt;long_at_put(i, array-&gt;long_at(i) + tp-&gt;_jvmci_counters[i]);
1414         }
1415       }
1416     }
1417   }
1418 }
1419 
1420 #endif // INCLUDE_JVMCI
1421 
1422 // A JavaThread is a normal Java thread
1423 
1424 void JavaThread::initialize() {
1425   // Initialize fields
1426 
1427   set_saved_exception_pc(NULL);
1428   set_threadObj(NULL);
1429   _anchor.clear();
1430   set_entry_point(NULL);
1431   set_jni_functions(jni_functions());
1432   set_callee_target(NULL);
1433   set_vm_result(NULL);
1434   set_vm_result_2(NULL);
1435   set_vframe_array_head(NULL);
1436   set_vframe_array_last(NULL);
1437   set_deferred_locals(NULL);
1438   set_deopt_mark(NULL);
1439   set_deopt_nmethod(NULL);
1440   clear_must_deopt_id();
1441   set_monitor_chunks(NULL);
1442   set_next(NULL);
1443   set_thread_state(_thread_new);
1444   _terminated = _not_terminated;
1445   _privileged_stack_top = NULL;
1446   _array_for_gc = NULL;
1447   _suspend_equivalent = false;
1448   _in_deopt_handler = 0;
1449   _doing_unsafe_access = false;
1450   _stack_guard_state = stack_guard_unused;
1451 #if INCLUDE_JVMCI
1452   _pending_monitorenter = false;
1453   _pending_deoptimization = -1;
1454   _pending_failed_speculation = NULL;
1455   _pending_transfer_to_interpreter = false;
1456   _jvmci._alternate_call_target = NULL;
1457   assert(_jvmci._implicit_exception_pc == NULL, "must be");
1458   if (JVMCICounterSize &gt; 0) {
1459     _jvmci_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
1460     memset(_jvmci_counters, 0, sizeof(jlong) * JVMCICounterSize);
1461   } else {
1462     _jvmci_counters = NULL;
1463   }
1464 #endif // INCLUDE_JVMCI
1465   _reserved_stack_activation = NULL;  // stack base not known yet
1466   (void)const_cast&lt;oop&amp;&gt;(_exception_oop = oop(NULL));
1467   _exception_pc  = 0;
1468   _exception_handler_pc = 0;
1469   _is_method_handle_return = 0;
1470   _jvmti_thread_state= NULL;
1471   _should_post_on_exceptions_flag = JNI_FALSE;
1472   _jvmti_get_loaded_classes_closure = NULL;
1473   _interp_only_mode    = 0;
1474   _special_runtime_exit_condition = _no_async_condition;
1475   _pending_async_exception = NULL;
1476   _thread_stat = NULL;
1477   _thread_stat = new ThreadStatistics();
1478   _blocked_on_compilation = false;
1479   _jni_active_critical = 0;
1480   _pending_jni_exception_check_fn = NULL;
1481   _do_not_unlock_if_synchronized = false;
1482   _cached_monitor_info = NULL;
1483   _parker = Parker::Allocate(this);
1484 
1485 #ifndef PRODUCT
1486   _jmp_ring_index = 0;
1487   for (int ji = 0; ji &lt; jump_ring_buffer_size; ji++) {
1488     record_jump(NULL, NULL, NULL, 0);
1489   }
1490 #endif // PRODUCT
1491 
1492   set_thread_profiler(NULL);
1493   if (FlatProfiler::is_active()) {
1494     // This is where we would decide to either give each thread it's own profiler
1495     // or use one global one from FlatProfiler,
1496     // or up to some count of the number of profiled threads, etc.
1497     ThreadProfiler* pp = new ThreadProfiler();
1498     pp-&gt;engage();
1499     set_thread_profiler(pp);
1500   }
1501 
1502   // Setup safepoint state info for this thread
1503   ThreadSafepointState::create(this);
1504 
1505   debug_only(_java_call_counter = 0);
1506 
1507   // JVMTI PopFrame support
1508   _popframe_condition = popframe_inactive;
1509   _popframe_preserved_args = NULL;
1510   _popframe_preserved_args_size = 0;
1511   _frames_to_pop_failed_realloc = 0;
1512 
1513   pd_initialize();
1514 }
1515 
1516 #if INCLUDE_ALL_GCS
1517 SATBMarkQueueSet JavaThread::_satb_mark_queue_set;
1518 DirtyCardQueueSet JavaThread::_dirty_card_queue_set;
1519 #endif // INCLUDE_ALL_GCS
1520 
1521 JavaThread::JavaThread(bool is_attaching_via_jni) :
1522                        Thread()
1523 #if INCLUDE_ALL_GCS
1524                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1525                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1526 #endif // INCLUDE_ALL_GCS
1527 {
1528   initialize();
1529   if (is_attaching_via_jni) {
1530     _jni_attach_state = _attaching_via_jni;
1531   } else {
1532     _jni_attach_state = _not_attaching_via_jni;
1533   }
1534   assert(deferred_card_mark().is_empty(), "Default MemRegion ctor");
1535 }
1536 
1537 bool JavaThread::reguard_stack(address cur_sp) {
1538   if (_stack_guard_state != stack_guard_yellow_reserved_disabled
1539       &amp;&amp; _stack_guard_state != stack_guard_reserved_disabled) {
1540     return true; // Stack already guarded or guard pages not needed.
1541   }
1542 
1543   if (register_stack_overflow()) {
1544     // For those architectures which have separate register and
1545     // memory stacks, we must check the register stack to see if
1546     // it has overflowed.
1547     return false;
1548   }
1549 
1550   // Java code never executes within the yellow zone: the latter is only
1551   // there to provoke an exception during stack banging.  If java code
1552   // is executing there, either StackShadowPages should be larger, or
1553   // some exception code in c1, c2 or the interpreter isn't unwinding
1554   // when it should.
1555   guarantee(cur_sp &gt; stack_reserved_zone_base(),
1556             "not enough space to reguard - increase StackShadowPages");
1557   if (_stack_guard_state == stack_guard_yellow_reserved_disabled) {
1558     enable_stack_yellow_reserved_zone();
1559     if (reserved_stack_activation() != stack_base()) {
1560       set_reserved_stack_activation(stack_base());
1561     }
1562   } else if (_stack_guard_state == stack_guard_reserved_disabled) {
1563     set_reserved_stack_activation(stack_base());
1564     enable_stack_reserved_zone();
1565   }
1566   return true;
1567 }
1568 
1569 bool JavaThread::reguard_stack(void) {
1570   return reguard_stack(os::current_stack_pointer());
1571 }
1572 
1573 
1574 void JavaThread::block_if_vm_exited() {
1575   if (_terminated == _vm_exited) {
1576     // _vm_exited is set at safepoint, and Threads_lock is never released
1577     // we will block here forever
1578     Threads_lock-&gt;lock_without_safepoint_check();
1579     ShouldNotReachHere();
1580   }
1581 }
1582 
1583 
1584 // Remove this ifdef when C1 is ported to the compiler interface.
1585 static void compiler_thread_entry(JavaThread* thread, TRAPS);
1586 static void sweeper_thread_entry(JavaThread* thread, TRAPS);
1587 
1588 JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) :
1589                        Thread()
1590 #if INCLUDE_ALL_GCS
1591                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1592                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1593 #endif // INCLUDE_ALL_GCS
1594 {
1595   initialize();
1596   _jni_attach_state = _not_attaching_via_jni;
1597   set_entry_point(entry_point);
1598   // Create the native thread itself.
1599   // %note runtime_23
1600   os::ThreadType thr_type = os::java_thread;
1601   thr_type = entry_point == &amp;compiler_thread_entry ? os::compiler_thread :
1602                                                      os::java_thread;
1603   os::create_thread(this, thr_type, stack_sz);
1604   // The _osthread may be NULL here because we ran out of memory (too many threads active).
1605   // We need to throw and OutOfMemoryError - however we cannot do this here because the caller
1606   // may hold a lock and all locks must be unlocked before throwing the exception (throwing
1607   // the exception consists of creating the exception object &amp; initializing it, initialization
1608   // will leave the VM via a JavaCall and then all locks must be unlocked).
1609   //
1610   // The thread is still suspended when we reach here. Thread must be explicit started
1611   // by creator! Furthermore, the thread must also explicitly be added to the Threads list
1612   // by calling Threads:add. The reason why this is not done here, is because the thread
1613   // object must be fully initialized (take a look at JVM_Start)
1614 }
1615 
1616 JavaThread::~JavaThread() {
1617 
1618   // JSR166 -- return the parker to the free list
1619   Parker::Release(_parker);
1620   _parker = NULL;
1621 
1622   // Free any remaining  previous UnrollBlock
1623   vframeArray* old_array = vframe_array_last();
1624 
1625   if (old_array != NULL) {
1626     Deoptimization::UnrollBlock* old_info = old_array-&gt;unroll_block();
1627     old_array-&gt;set_unroll_block(NULL);
1628     delete old_info;
1629     delete old_array;
1630   }
1631 
1632   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* deferred = deferred_locals();
1633   if (deferred != NULL) {
1634     // This can only happen if thread is destroyed before deoptimization occurs.
1635     assert(deferred-&gt;length() != 0, "empty array!");
1636     do {
1637       jvmtiDeferredLocalVariableSet* dlv = deferred-&gt;at(0);
1638       deferred-&gt;remove_at(0);
1639       // individual jvmtiDeferredLocalVariableSet are CHeapObj's
1640       delete dlv;
1641     } while (deferred-&gt;length() != 0);
1642     delete deferred;
1643   }
1644 
1645   // All Java related clean up happens in exit
1646   ThreadSafepointState::destroy(this);
1647   if (_thread_profiler != NULL) delete _thread_profiler;
1648   if (_thread_stat != NULL) delete _thread_stat;
1649 
1650 #if INCLUDE_JVMCI
1651   if (JVMCICounterSize &gt; 0) {
1652     if (jvmci_counters_include(this)) {
1653       for (int i = 0; i &lt; JVMCICounterSize; i++) {
1654         _jvmci_old_thread_counters[i] += _jvmci_counters[i];
1655       }
1656     }
1657     FREE_C_HEAP_ARRAY(jlong, _jvmci_counters);
1658   }
1659 #endif // INCLUDE_JVMCI
1660 }
1661 
1662 
1663 // The first routine called by a new Java thread
1664 void JavaThread::run() {
1665   // initialize thread-local alloc buffer related fields
1666   this-&gt;initialize_tlab();
1667 
1668   // used to test validity of stack trace backs
1669   this-&gt;record_base_of_stack_pointer();
1670 
1671   // Record real stack base and size.
1672   this-&gt;record_stack_base_and_size();
1673 
1674   this-&gt;create_stack_guard_pages();
1675 
1676   this-&gt;cache_global_variables();
1677 
1678   // Thread is now sufficient initialized to be handled by the safepoint code as being
1679   // in the VM. Change thread state from _thread_new to _thread_in_vm
1680   ThreadStateTransition::transition_and_fence(this, _thread_new, _thread_in_vm);
1681 
1682   assert(JavaThread::current() == this, "sanity check");
1683   assert(!Thread::current()-&gt;owns_locks(), "sanity check");
1684 
1685   DTRACE_THREAD_PROBE(start, this);
1686 
1687   // This operation might block. We call that after all safepoint checks for a new thread has
1688   // been completed.
1689   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1690 
1691   if (JvmtiExport::should_post_thread_life()) {
1692     JvmtiExport::post_thread_start(this);
1693   }
1694 
1695   EventThreadStart event;
1696   if (event.should_commit()) {
1697     event.set_thread(THREAD_TRACE_ID(this));
1698     event.commit();
1699   }
1700 
1701   // We call another function to do the rest so we are sure that the stack addresses used
1702   // from there will be lower than the stack base just computed
1703   thread_main_inner();
1704 
1705   // Note, thread is no longer valid at this point!
1706 }
1707 
1708 
1709 void JavaThread::thread_main_inner() {
1710   assert(JavaThread::current() == this, "sanity check");
1711   assert(this-&gt;threadObj() != NULL, "just checking");
1712 
1713   // Execute thread entry point unless this thread has a pending exception
1714   // or has been stopped before starting.
1715   // Note: Due to JVM_StopThread we can have pending exceptions already!
1716   if (!this-&gt;has_pending_exception() &amp;&amp;
1717       !java_lang_Thread::is_stillborn(this-&gt;threadObj())) {
1718     {
1719       ResourceMark rm(this);
1720       this-&gt;set_native_thread_name(this-&gt;get_thread_name());
1721     }
1722     HandleMark hm(this);
1723     this-&gt;entry_point()(this, this);
1724   }
1725 
1726   DTRACE_THREAD_PROBE(stop, this);
1727 
1728   this-&gt;exit(false);
1729   delete this;
1730 }
1731 
1732 
1733 static void ensure_join(JavaThread* thread) {
1734   // We do not need to grap the Threads_lock, since we are operating on ourself.
1735   Handle threadObj(thread, thread-&gt;threadObj());
1736   assert(threadObj.not_null(), "java thread object must exist");
1737   ObjectLocker lock(threadObj, thread);
1738   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1739   thread-&gt;clear_pending_exception();
1740   // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.
1741   java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);
1742   // Clear the native thread instance - this makes isAlive return false and allows the join()
1743   // to complete once we've done the notify_all below
1744   java_lang_Thread::set_thread(threadObj(), NULL);
1745   lock.notify_all(thread);
1746   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1747   thread-&gt;clear_pending_exception();
1748 }
1749 
1750 
1751 // For any new cleanup additions, please check to see if they need to be applied to
1752 // cleanup_failed_attach_current_thread as well.
1753 void JavaThread::exit(bool destroy_vm, ExitType exit_type) {
1754   assert(this == JavaThread::current(), "thread consistency check");
1755 
1756   HandleMark hm(this);
1757   Handle uncaught_exception(this, this-&gt;pending_exception());
1758   this-&gt;clear_pending_exception();
1759   Handle threadObj(this, this-&gt;threadObj());
1760   assert(threadObj.not_null(), "Java thread object should be created");
1761 
1762   if (get_thread_profiler() != NULL) {
1763     get_thread_profiler()-&gt;disengage();
1764     ResourceMark rm;
1765     get_thread_profiler()-&gt;print(get_thread_name());
1766   }
1767 
1768 
1769   // FIXIT: This code should be moved into else part, when reliable 1.2/1.3 check is in place
1770   {
1771     EXCEPTION_MARK;
1772 
1773     CLEAR_PENDING_EXCEPTION;
1774   }
1775   if (!destroy_vm) {
1776     if (uncaught_exception.not_null()) {
1777       EXCEPTION_MARK;
1778       // Call method Thread.dispatchUncaughtException().
1779       KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1780       JavaValue result(T_VOID);
1781       JavaCalls::call_virtual(&amp;result,
1782                               threadObj, thread_klass,
1783                               vmSymbols::dispatchUncaughtException_name(),
1784                               vmSymbols::throwable_void_signature(),
1785                               uncaught_exception,
1786                               THREAD);
1787       if (HAS_PENDING_EXCEPTION) {
1788         ResourceMark rm(this);
1789         jio_fprintf(defaultStream::error_stream(),
1790                     "\nException: %s thrown from the UncaughtExceptionHandler"
1791                     " in thread \"%s\"\n",
1792                     pending_exception()-&gt;klass()-&gt;external_name(),
1793                     get_thread_name());
1794         CLEAR_PENDING_EXCEPTION;
1795       }
1796     }
1797 
1798     // Called before the java thread exit since we want to read info
1799     // from java_lang_Thread object
1800     EventThreadEnd event;
1801     if (event.should_commit()) {
1802       event.set_thread(THREAD_TRACE_ID(this));
1803       event.commit();
1804     }
1805 
1806     // Call after last event on thread
1807     EVENT_THREAD_EXIT(this);
1808 
1809     // Call Thread.exit(). We try 3 times in case we got another Thread.stop during
1810     // the execution of the method. If that is not enough, then we don't really care. Thread.stop
1811     // is deprecated anyhow.
1812     if (!is_Compiler_thread()) {
1813       int count = 3;
1814       while (java_lang_Thread::threadGroup(threadObj()) != NULL &amp;&amp; (count-- &gt; 0)) {
1815         EXCEPTION_MARK;
1816         JavaValue result(T_VOID);
1817         KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1818         JavaCalls::call_virtual(&amp;result,
1819                                 threadObj, thread_klass,
1820                                 vmSymbols::exit_method_name(),
1821                                 vmSymbols::void_method_signature(),
1822                                 THREAD);
1823         CLEAR_PENDING_EXCEPTION;
1824       }
1825     }
1826     // notify JVMTI
1827     if (JvmtiExport::should_post_thread_life()) {
1828       JvmtiExport::post_thread_end(this);
1829     }
1830 
1831     // We have notified the agents that we are exiting, before we go on,
1832     // we must check for a pending external suspend request and honor it
1833     // in order to not surprise the thread that made the suspend request.
1834     while (true) {
1835       {
1836         MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1837         if (!is_external_suspend()) {
1838           set_terminated(_thread_exiting);
1839           ThreadService::current_thread_exiting(this);
1840           break;
1841         }
1842         // Implied else:
1843         // Things get a little tricky here. We have a pending external
1844         // suspend request, but we are holding the SR_lock so we
1845         // can't just self-suspend. So we temporarily drop the lock
1846         // and then self-suspend.
1847       }
1848 
1849       ThreadBlockInVM tbivm(this);
1850       java_suspend_self();
1851 
1852       // We're done with this suspend request, but we have to loop around
1853       // and check again. Eventually we will get SR_lock without a pending
1854       // external suspend request and will be able to mark ourselves as
1855       // exiting.
1856     }
1857     // no more external suspends are allowed at this point
1858   } else {
1859     // before_exit() has already posted JVMTI THREAD_END events
1860   }
1861 
1862   // Notify waiters on thread object. This has to be done after exit() is called
1863   // on the thread (if the thread is the last thread in a daemon ThreadGroup the
1864   // group should have the destroyed bit set before waiters are notified).
1865   ensure_join(this);
1866   assert(!this-&gt;has_pending_exception(), "ensure_join should have cleared");
1867 
1868   // 6282335 JNI DetachCurrentThread spec states that all Java monitors
1869   // held by this thread must be released. The spec does not distinguish
1870   // between JNI-acquired and regular Java monitors. We can only see
1871   // regular Java monitors here if monitor enter-exit matching is broken.
1872   //
1873   // Optionally release any monitors for regular JavaThread exits. This
1874   // is provided as a work around for any bugs in monitor enter-exit
1875   // matching. This can be expensive so it is not enabled by default.
1876   //
1877   // ensure_join() ignores IllegalThreadStateExceptions, and so does
1878   // ObjectSynchronizer::release_monitors_owned_by_thread().
1879   if (exit_type == jni_detach || ObjectMonitor::Knob_ExitRelease) {
1880     // Sanity check even though JNI DetachCurrentThread() would have
1881     // returned JNI_ERR if there was a Java frame. JavaThread exit
1882     // should be done executing Java code by the time we get here.
1883     assert(!this-&gt;has_last_Java_frame(),
1884            "should not have a Java frame when detaching or exiting");
1885     ObjectSynchronizer::release_monitors_owned_by_thread(this);
1886     assert(!this-&gt;has_pending_exception(), "release_monitors should have cleared");
1887   }
1888 
1889   // These things needs to be done while we are still a Java Thread. Make sure that thread
1890   // is in a consistent state, in case GC happens
1891   assert(_privileged_stack_top == NULL, "must be NULL when we get here");
1892 
1893   if (active_handles() != NULL) {
1894     JNIHandleBlock* block = active_handles();
1895     set_active_handles(NULL);
1896     JNIHandleBlock::release_block(block);
1897   }
1898 
1899   if (free_handle_block() != NULL) {
1900     JNIHandleBlock* block = free_handle_block();
1901     set_free_handle_block(NULL);
1902     JNIHandleBlock::release_block(block);
1903   }
1904 
1905   // These have to be removed while this is still a valid thread.
1906   remove_stack_guard_pages();
1907 
1908   if (UseTLAB) {
1909     tlab().make_parsable(true);  // retire TLAB
1910   }
1911 
1912   if (JvmtiEnv::environments_might_exist()) {
1913     JvmtiExport::cleanup_thread(this);
1914   }
1915 
1916   // We must flush any deferred card marks before removing a thread from
1917   // the list of active threads.
1918   Universe::heap()-&gt;flush_deferred_store_barrier(this);
1919   assert(deferred_card_mark().is_empty(), "Should have been flushed");
1920 
1921 #if INCLUDE_ALL_GCS
1922   // We must flush the G1-related buffers before removing a thread
1923   // from the list of active threads. We must do this after any deferred
1924   // card marks have been flushed (above) so that any entries that are
1925   // added to the thread's dirty card queue as a result are not lost.
1926   if (UseG1GC) {
1927     flush_barrier_queues();
1928   }
1929 #endif // INCLUDE_ALL_GCS
1930 
1931   log_info(os, thread)("JavaThread %s (tid: " UINTX_FORMAT ").",
1932     exit_type == JavaThread::normal_exit ? "exiting" : "detaching",
1933     os::current_thread_id());
1934 
1935   // Remove from list of active threads list, and notify VM thread if we are the last non-daemon thread
1936   Threads::remove(this);
1937 }
1938 
1939 #if INCLUDE_ALL_GCS
1940 // Flush G1-related queues.
1941 void JavaThread::flush_barrier_queues() {
1942   satb_mark_queue().flush();
1943   dirty_card_queue().flush();
1944 }
1945 
1946 void JavaThread::initialize_queues() {
1947   assert(!SafepointSynchronize::is_at_safepoint(),
1948          "we should not be at a safepoint");
1949 
1950   SATBMarkQueue&amp; satb_queue = satb_mark_queue();
1951   SATBMarkQueueSet&amp; satb_queue_set = satb_mark_queue_set();
1952   // The SATB queue should have been constructed with its active
1953   // field set to false.
1954   assert(!satb_queue.is_active(), "SATB queue should not be active");
1955   assert(satb_queue.is_empty(), "SATB queue should be empty");
1956   // If we are creating the thread during a marking cycle, we should
1957   // set the active field of the SATB queue to true.
1958   if (satb_queue_set.is_active()) {
1959     satb_queue.set_active(true);
1960   }
1961 
1962   DirtyCardQueue&amp; dirty_queue = dirty_card_queue();
1963   // The dirty card queue should have been constructed with its
1964   // active field set to true.
1965   assert(dirty_queue.is_active(), "dirty card queue should be active");
1966 }
1967 #endif // INCLUDE_ALL_GCS
1968 
1969 void JavaThread::cleanup_failed_attach_current_thread() {
1970   if (get_thread_profiler() != NULL) {
1971     get_thread_profiler()-&gt;disengage();
1972     ResourceMark rm;
1973     get_thread_profiler()-&gt;print(get_thread_name());
1974   }
1975 
1976   if (active_handles() != NULL) {
1977     JNIHandleBlock* block = active_handles();
1978     set_active_handles(NULL);
1979     JNIHandleBlock::release_block(block);
1980   }
1981 
1982   if (free_handle_block() != NULL) {
1983     JNIHandleBlock* block = free_handle_block();
1984     set_free_handle_block(NULL);
1985     JNIHandleBlock::release_block(block);
1986   }
1987 
1988   // These have to be removed while this is still a valid thread.
1989   remove_stack_guard_pages();
1990 
1991   if (UseTLAB) {
1992     tlab().make_parsable(true);  // retire TLAB, if any
1993   }
1994 
1995 #if INCLUDE_ALL_GCS
1996   if (UseG1GC) {
1997     flush_barrier_queues();
1998   }
1999 #endif // INCLUDE_ALL_GCS
2000 
2001   Threads::remove(this);
2002   delete this;
2003 }
2004 
2005 
2006 
2007 
2008 JavaThread* JavaThread::active() {
2009   Thread* thread = Thread::current();
2010   if (thread-&gt;is_Java_thread()) {
2011     return (JavaThread*) thread;
2012   } else {
2013     assert(thread-&gt;is_VM_thread(), "this must be a vm thread");
2014     VM_Operation* op = ((VMThread*) thread)-&gt;vm_operation();
2015     JavaThread *ret=op == NULL ? NULL : (JavaThread *)op-&gt;calling_thread();
2016     assert(ret-&gt;is_Java_thread(), "must be a Java thread");
2017     return ret;
2018   }
2019 }
2020 
2021 bool JavaThread::is_lock_owned(address adr) const {
2022   if (Thread::is_lock_owned(adr)) return true;
2023 
2024   for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2025     if (chunk-&gt;contains(adr)) return true;
2026   }
2027 
2028   return false;
2029 }
2030 
2031 
2032 void JavaThread::add_monitor_chunk(MonitorChunk* chunk) {
2033   chunk-&gt;set_next(monitor_chunks());
2034   set_monitor_chunks(chunk);
2035 }
2036 
2037 void JavaThread::remove_monitor_chunk(MonitorChunk* chunk) {
2038   guarantee(monitor_chunks() != NULL, "must be non empty");
2039   if (monitor_chunks() == chunk) {
2040     set_monitor_chunks(chunk-&gt;next());
2041   } else {
2042     MonitorChunk* prev = monitor_chunks();
2043     while (prev-&gt;next() != chunk) prev = prev-&gt;next();
2044     prev-&gt;set_next(chunk-&gt;next());
2045   }
2046 }
2047 
2048 // JVM support.
2049 
2050 // Note: this function shouldn't block if it's called in
2051 // _thread_in_native_trans state (such as from
2052 // check_special_condition_for_native_trans()).
2053 void JavaThread::check_and_handle_async_exceptions(bool check_unsafe_error) {
2054 
2055   if (has_last_Java_frame() &amp;&amp; has_async_condition()) {
2056     // If we are at a polling page safepoint (not a poll return)
2057     // then we must defer async exception because live registers
2058     // will be clobbered by the exception path. Poll return is
2059     // ok because the call we a returning from already collides
2060     // with exception handling registers and so there is no issue.
2061     // (The exception handling path kills call result registers but
2062     //  this is ok since the exception kills the result anyway).
2063 
2064     if (is_at_poll_safepoint()) {
2065       // if the code we are returning to has deoptimized we must defer
2066       // the exception otherwise live registers get clobbered on the
2067       // exception path before deoptimization is able to retrieve them.
2068       //
2069       RegisterMap map(this, false);
2070       frame caller_fr = last_frame().sender(&amp;map);
2071       assert(caller_fr.is_compiled_frame(), "what?");
2072       if (caller_fr.is_deoptimized_frame()) {
2073         log_info(exceptions)("deferred async exception at compiled safepoint");
2074         return;
2075       }
2076     }
2077   }
2078 
2079   JavaThread::AsyncRequests condition = clear_special_runtime_exit_condition();
2080   if (condition == _no_async_condition) {
2081     // Conditions have changed since has_special_runtime_exit_condition()
2082     // was called:
2083     // - if we were here only because of an external suspend request,
2084     //   then that was taken care of above (or cancelled) so we are done
2085     // - if we were here because of another async request, then it has
2086     //   been cleared between the has_special_runtime_exit_condition()
2087     //   and now so again we are done
2088     return;
2089   }
2090 
2091   // Check for pending async. exception
2092   if (_pending_async_exception != NULL) {
2093     // Only overwrite an already pending exception, if it is not a threadDeath.
2094     if (!has_pending_exception() || !pending_exception()-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2095 
2096       // We cannot call Exceptions::_throw(...) here because we cannot block
2097       set_pending_exception(_pending_async_exception, __FILE__, __LINE__);
2098 
2099       if (log_is_enabled(Info, exceptions)) {
2100         ResourceMark rm;
2101         outputStream* logstream = LogHandle(exceptions)::info_stream();
2102         logstream-&gt;print("Async. exception installed at runtime exit (" INTPTR_FORMAT ")", p2i(this));
2103           if (has_last_Java_frame()) {
2104             frame f = last_frame();
2105            logstream-&gt;print(" (pc: " INTPTR_FORMAT " sp: " INTPTR_FORMAT " )", p2i(f.pc()), p2i(f.sp()));
2106           }
2107         logstream-&gt;print_cr(" of type: %s", _pending_async_exception-&gt;klass()-&gt;external_name());
2108       }
2109       _pending_async_exception = NULL;
2110       clear_has_async_exception();
2111     }
2112   }
2113 
2114   if (check_unsafe_error &amp;&amp;
2115       condition == _async_unsafe_access_error &amp;&amp; !has_pending_exception()) {
2116     condition = _no_async_condition;  // done
2117     switch (thread_state()) {
2118     case _thread_in_vm: {
2119       JavaThread* THREAD = this;
2120       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2121     }
2122     case _thread_in_native: {
2123       ThreadInVMfromNative tiv(this);
2124       JavaThread* THREAD = this;
2125       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2126     }
2127     case _thread_in_Java: {
2128       ThreadInVMfromJava tiv(this);
2129       JavaThread* THREAD = this;
2130       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in a recent unsafe memory access operation in compiled Java code");
2131     }
2132     default:
2133       ShouldNotReachHere();
2134     }
2135   }
2136 
2137   assert(condition == _no_async_condition || has_pending_exception() ||
2138          (!check_unsafe_error &amp;&amp; condition == _async_unsafe_access_error),
2139          "must have handled the async condition, if no exception");
2140 }
2141 
2142 void JavaThread::handle_special_runtime_exit_condition(bool check_asyncs) {
2143   //
2144   // Check for pending external suspend. Internal suspend requests do
2145   // not use handle_special_runtime_exit_condition().
2146   // If JNIEnv proxies are allowed, don't self-suspend if the target
2147   // thread is not the current thread. In older versions of jdbx, jdbx
2148   // threads could call into the VM with another thread's JNIEnv so we
2149   // can be here operating on behalf of a suspended thread (4432884).
2150   bool do_self_suspend = is_external_suspend_with_lock();
2151   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || this == JavaThread::current())) {
2152     //
2153     // Because thread is external suspended the safepoint code will count
2154     // thread as at a safepoint. This can be odd because we can be here
2155     // as _thread_in_Java which would normally transition to _thread_blocked
2156     // at a safepoint. We would like to mark the thread as _thread_blocked
2157     // before calling java_suspend_self like all other callers of it but
2158     // we must then observe proper safepoint protocol. (We can't leave
2159     // _thread_blocked with a safepoint in progress). However we can be
2160     // here as _thread_in_native_trans so we can't use a normal transition
2161     // constructor/destructor pair because they assert on that type of
2162     // transition. We could do something like:
2163     //
2164     // JavaThreadState state = thread_state();
2165     // set_thread_state(_thread_in_vm);
2166     // {
2167     //   ThreadBlockInVM tbivm(this);
2168     //   java_suspend_self()
2169     // }
2170     // set_thread_state(_thread_in_vm_trans);
2171     // if (safepoint) block;
2172     // set_thread_state(state);
2173     //
2174     // but that is pretty messy. Instead we just go with the way the
2175     // code has worked before and note that this is the only path to
2176     // java_suspend_self that doesn't put the thread in _thread_blocked
2177     // mode.
2178 
2179     frame_anchor()-&gt;make_walkable(this);
2180     java_suspend_self();
2181 
2182     // We might be here for reasons in addition to the self-suspend request
2183     // so check for other async requests.
2184   }
2185 
2186   if (check_asyncs) {
2187     check_and_handle_async_exceptions();
2188   }
2189 }
2190 
2191 void JavaThread::send_thread_stop(oop java_throwable)  {
2192   assert(Thread::current()-&gt;is_VM_thread(), "should be in the vm thread");
2193   assert(Threads_lock-&gt;is_locked(), "Threads_lock should be locked by safepoint code");
2194   assert(SafepointSynchronize::is_at_safepoint(), "all threads are stopped");
2195 
2196   // Do not throw asynchronous exceptions against the compiler thread
2197   // (the compiler thread should not be a Java thread -- fix in 1.4.2)
2198   if (!can_call_java()) return;
2199 
2200   {
2201     // Actually throw the Throwable against the target Thread - however
2202     // only if there is no thread death exception installed already.
2203     if (_pending_async_exception == NULL || !_pending_async_exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2204       // If the topmost frame is a runtime stub, then we are calling into
2205       // OptoRuntime from compiled code. Some runtime stubs (new, monitor_exit..)
2206       // must deoptimize the caller before continuing, as the compiled  exception handler table
2207       // may not be valid
2208       if (has_last_Java_frame()) {
2209         frame f = last_frame();
2210         if (f.is_runtime_frame() || f.is_safepoint_blob_frame()) {
2211           // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2212           RegisterMap reg_map(this, UseBiasedLocking);
2213           frame compiled_frame = f.sender(&amp;reg_map);
2214           if (!StressCompiledExceptionHandlers &amp;&amp; compiled_frame.can_be_deoptimized()) {
2215             Deoptimization::deoptimize(this, compiled_frame, &amp;reg_map);
2216           }
2217         }
2218       }
2219 
2220       // Set async. pending exception in thread.
2221       set_pending_async_exception(java_throwable);
2222 
2223       if (log_is_enabled(Info, exceptions)) {
2224          ResourceMark rm;
2225         log_info(exceptions)("Pending Async. exception installed of type: %s",
2226                              InstanceKlass::cast(_pending_async_exception-&gt;klass())-&gt;external_name());
2227       }
2228       // for AbortVMOnException flag
2229       Exceptions::debug_check_abort(_pending_async_exception-&gt;klass()-&gt;external_name());
2230     }
2231   }
2232 
2233 
2234   // Interrupt thread so it will wake up from a potential wait()
2235   Thread::interrupt(this);
2236 }
2237 
2238 // External suspension mechanism.
2239 //
2240 // Tell the VM to suspend a thread when ever it knows that it does not hold on
2241 // to any VM_locks and it is at a transition
2242 // Self-suspension will happen on the transition out of the vm.
2243 // Catch "this" coming in from JNIEnv pointers when the thread has been freed
2244 //
2245 // Guarantees on return:
2246 //   + Target thread will not execute any new bytecode (that's why we need to
2247 //     force a safepoint)
2248 //   + Target thread will not enter any new monitors
2249 //
2250 void JavaThread::java_suspend() {
2251   { MutexLocker mu(Threads_lock);
2252     if (!Threads::includes(this) || is_exiting() || this-&gt;threadObj() == NULL) {
2253       return;
2254     }
2255   }
2256 
2257   { MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2258     if (!is_external_suspend()) {
2259       // a racing resume has cancelled us; bail out now
2260       return;
2261     }
2262 
2263     // suspend is done
2264     uint32_t debug_bits = 0;
2265     // Warning: is_ext_suspend_completed() may temporarily drop the
2266     // SR_lock to allow the thread to reach a stable thread state if
2267     // it is currently in a transient thread state.
2268     if (is_ext_suspend_completed(false /* !called_by_wait */,
2269                                  SuspendRetryDelay, &amp;debug_bits)) {
2270       return;
2271     }
2272   }
2273 
2274   VM_ForceSafepoint vm_suspend;
2275   VMThread::execute(&amp;vm_suspend);
2276 }
2277 
2278 // Part II of external suspension.
2279 // A JavaThread self suspends when it detects a pending external suspend
2280 // request. This is usually on transitions. It is also done in places
2281 // where continuing to the next transition would surprise the caller,
2282 // e.g., monitor entry.
2283 //
2284 // Returns the number of times that the thread self-suspended.
2285 //
2286 // Note: DO NOT call java_suspend_self() when you just want to block current
2287 //       thread. java_suspend_self() is the second stage of cooperative
2288 //       suspension for external suspend requests and should only be used
2289 //       to complete an external suspend request.
2290 //
2291 int JavaThread::java_suspend_self() {
2292   int ret = 0;
2293 
2294   // we are in the process of exiting so don't suspend
2295   if (is_exiting()) {
2296     clear_external_suspend();
2297     return ret;
2298   }
2299 
2300   assert(_anchor.walkable() ||
2301          (is_Java_thread() &amp;&amp; !((JavaThread*)this)-&gt;has_last_Java_frame()),
2302          "must have walkable stack");
2303 
2304   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2305 
2306   assert(!this-&gt;is_ext_suspended(),
2307          "a thread trying to self-suspend should not already be suspended");
2308 
2309   if (this-&gt;is_suspend_equivalent()) {
2310     // If we are self-suspending as a result of the lifting of a
2311     // suspend equivalent condition, then the suspend_equivalent
2312     // flag is not cleared until we set the ext_suspended flag so
2313     // that wait_for_ext_suspend_completion() returns consistent
2314     // results.
2315     this-&gt;clear_suspend_equivalent();
2316   }
2317 
2318   // A racing resume may have cancelled us before we grabbed SR_lock
2319   // above. Or another external suspend request could be waiting for us
2320   // by the time we return from SR_lock()-&gt;wait(). The thread
2321   // that requested the suspension may already be trying to walk our
2322   // stack and if we return now, we can change the stack out from under
2323   // it. This would be a "bad thing (TM)" and cause the stack walker
2324   // to crash. We stay self-suspended until there are no more pending
2325   // external suspend requests.
2326   while (is_external_suspend()) {
2327     ret++;
2328     this-&gt;set_ext_suspended();
2329 
2330     // _ext_suspended flag is cleared by java_resume()
2331     while (is_ext_suspended()) {
2332       this-&gt;SR_lock()-&gt;wait(Mutex::_no_safepoint_check_flag);
2333     }
2334   }
2335 
2336   return ret;
2337 }
2338 
2339 #ifdef ASSERT
2340 // verify the JavaThread has not yet been published in the Threads::list, and
2341 // hence doesn't need protection from concurrent access at this stage
2342 void JavaThread::verify_not_published() {
2343   if (!Threads_lock-&gt;owned_by_self()) {
2344     MutexLockerEx ml(Threads_lock,  Mutex::_no_safepoint_check_flag);
2345     assert(!Threads::includes(this),
2346            "java thread shouldn't have been published yet!");
2347   } else {
2348     assert(!Threads::includes(this),
2349            "java thread shouldn't have been published yet!");
2350   }
2351 }
2352 #endif
2353 
2354 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2355 // progress or when _suspend_flags is non-zero.
2356 // Current thread needs to self-suspend if there is a suspend request and/or
2357 // block if a safepoint is in progress.
2358 // Async exception ISN'T checked.
2359 // Note only the ThreadInVMfromNative transition can call this function
2360 // directly and when thread state is _thread_in_native_trans
2361 void JavaThread::check_safepoint_and_suspend_for_native_trans(JavaThread *thread) {
2362   assert(thread-&gt;thread_state() == _thread_in_native_trans, "wrong state");
2363 
2364   JavaThread *curJT = JavaThread::current();
2365   bool do_self_suspend = thread-&gt;is_external_suspend();
2366 
2367   assert(!curJT-&gt;has_last_Java_frame() || curJT-&gt;frame_anchor()-&gt;walkable(), "Unwalkable stack in native-&gt;vm transition");
2368 
2369   // If JNIEnv proxies are allowed, don't self-suspend if the target
2370   // thread is not the current thread. In older versions of jdbx, jdbx
2371   // threads could call into the VM with another thread's JNIEnv so we
2372   // can be here operating on behalf of a suspended thread (4432884).
2373   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || curJT == thread)) {
2374     JavaThreadState state = thread-&gt;thread_state();
2375 
2376     // We mark this thread_blocked state as a suspend-equivalent so
2377     // that a caller to is_ext_suspend_completed() won't be confused.
2378     // The suspend-equivalent state is cleared by java_suspend_self().
2379     thread-&gt;set_suspend_equivalent();
2380 
2381     // If the safepoint code sees the _thread_in_native_trans state, it will
2382     // wait until the thread changes to other thread state. There is no
2383     // guarantee on how soon we can obtain the SR_lock and complete the
2384     // self-suspend request. It would be a bad idea to let safepoint wait for
2385     // too long. Temporarily change the state to _thread_blocked to
2386     // let the VM thread know that this thread is ready for GC. The problem
2387     // of changing thread state is that safepoint could happen just after
2388     // java_suspend_self() returns after being resumed, and VM thread will
2389     // see the _thread_blocked state. We must check for safepoint
2390     // after restoring the state and make sure we won't leave while a safepoint
2391     // is in progress.
2392     thread-&gt;set_thread_state(_thread_blocked);
2393     thread-&gt;java_suspend_self();
2394     thread-&gt;set_thread_state(state);
2395     // Make sure new state is seen by VM thread
2396     if (os::is_MP()) {
2397       if (UseMembar) {
2398         // Force a fence between the write above and read below
2399         OrderAccess::fence();
2400       } else {
2401         // Must use this rather than serialization page in particular on Windows
2402         InterfaceSupport::serialize_memory(thread);
2403       }
2404     }
2405   }
2406 
2407   if (SafepointSynchronize::do_call_back()) {
2408     // If we are safepointing, then block the caller which may not be
2409     // the same as the target thread (see above).
2410     SafepointSynchronize::block(curJT);
2411   }
2412 
2413   if (thread-&gt;is_deopt_suspend()) {
2414     thread-&gt;clear_deopt_suspend();
2415     RegisterMap map(thread, false);
2416     frame f = thread-&gt;last_frame();
2417     while (f.id() != thread-&gt;must_deopt_id() &amp;&amp; ! f.is_first_frame()) {
2418       f = f.sender(&amp;map);
2419     }
2420     if (f.id() == thread-&gt;must_deopt_id()) {
2421       thread-&gt;clear_must_deopt_id();
2422       f.deoptimize(thread);
2423     } else {
2424       fatal("missed deoptimization!");
2425     }
2426   }
2427 }
2428 
2429 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2430 // progress or when _suspend_flags is non-zero.
2431 // Current thread needs to self-suspend if there is a suspend request and/or
2432 // block if a safepoint is in progress.
2433 // Also check for pending async exception (not including unsafe access error).
2434 // Note only the native==&gt;VM/Java barriers can call this function and when
2435 // thread state is _thread_in_native_trans.
2436 void JavaThread::check_special_condition_for_native_trans(JavaThread *thread) {
2437   check_safepoint_and_suspend_for_native_trans(thread);
2438 
2439   if (thread-&gt;has_async_exception()) {
2440     // We are in _thread_in_native_trans state, don't handle unsafe
2441     // access error since that may block.
2442     thread-&gt;check_and_handle_async_exceptions(false);
2443   }
2444 }
2445 
2446 // This is a variant of the normal
2447 // check_special_condition_for_native_trans with slightly different
2448 // semantics for use by critical native wrappers.  It does all the
2449 // normal checks but also performs the transition back into
2450 // thread_in_Java state.  This is required so that critical natives
2451 // can potentially block and perform a GC if they are the last thread
2452 // exiting the GCLocker.
2453 void JavaThread::check_special_condition_for_native_trans_and_transition(JavaThread *thread) {
2454   check_special_condition_for_native_trans(thread);
2455 
2456   // Finish the transition
2457   thread-&gt;set_thread_state(_thread_in_Java);
2458 
2459   if (thread-&gt;do_critical_native_unlock()) {
2460     ThreadInVMfromJavaNoAsyncException tiv(thread);
2461     GCLocker::unlock_critical(thread);
2462     thread-&gt;clear_critical_native_unlock();
2463   }
2464 }
2465 
2466 // We need to guarantee the Threads_lock here, since resumes are not
2467 // allowed during safepoint synchronization
2468 // Can only resume from an external suspension
2469 void JavaThread::java_resume() {
2470   assert_locked_or_safepoint(Threads_lock);
2471 
2472   // Sanity check: thread is gone, has started exiting or the thread
2473   // was not externally suspended.
2474   if (!Threads::includes(this) || is_exiting() || !is_external_suspend()) {
2475     return;
2476   }
2477 
2478   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2479 
2480   clear_external_suspend();
2481 
2482   if (is_ext_suspended()) {
2483     clear_ext_suspended();
2484     SR_lock()-&gt;notify_all();
2485   }
2486 }
2487 
2488 size_t JavaThread::_stack_red_zone_size = 0;
2489 size_t JavaThread::_stack_yellow_zone_size = 0;
2490 size_t JavaThread::_stack_reserved_zone_size = 0;
2491 size_t JavaThread::_stack_shadow_zone_size = 0;
2492 
2493 void JavaThread::create_stack_guard_pages() {
2494   if (!os::uses_stack_guard_pages() || _stack_guard_state != stack_guard_unused) { return; }
2495   address low_addr = stack_end();
2496   size_t len = stack_guard_zone_size();
2497 
2498   int allocate = os::allocate_stack_guard_pages();
2499   // warning("Guarding at " PTR_FORMAT " for len " SIZE_FORMAT "\n", low_addr, len);
2500 
2501   if (allocate &amp;&amp; !os::create_stack_guard_pages((char *) low_addr, len)) {
2502     log_warning(os, thread)("Attempt to allocate stack guard pages failed.");
2503     return;
2504   }
2505 
2506   if (os::guard_memory((char *) low_addr, len)) {
2507     _stack_guard_state = stack_guard_enabled;
2508   } else {
2509     log_warning(os, thread)("Attempt to protect stack guard pages failed ("
2510       PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2511     if (os::uncommit_memory((char *) low_addr, len)) {
2512       log_warning(os, thread)("Attempt to deallocate stack guard pages failed.");
2513     }
2514     return;
2515   }
2516 
2517   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages activated: "
2518     PTR_FORMAT "-" PTR_FORMAT ".",
2519     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2520 
2521 }
2522 
2523 void JavaThread::remove_stack_guard_pages() {
2524   assert(Thread::current() == this, "from different thread");
2525   if (_stack_guard_state == stack_guard_unused) return;
2526   address low_addr = stack_end();
2527   size_t len = stack_guard_zone_size();
2528 
2529   if (os::allocate_stack_guard_pages()) {
2530     if (os::remove_stack_guard_pages((char *) low_addr, len)) {
2531       _stack_guard_state = stack_guard_unused;
2532     } else {
2533       log_warning(os, thread)("Attempt to deallocate stack guard pages failed ("
2534         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2535       return;
2536     }
2537   } else {
2538     if (_stack_guard_state == stack_guard_unused) return;
2539     if (os::unguard_memory((char *) low_addr, len)) {
2540       _stack_guard_state = stack_guard_unused;
2541     } else {
2542       log_warning(os, thread)("Attempt to unprotect stack guard pages failed ("
2543         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2544       return;
2545     }
2546   }
2547 
2548   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages removed: "
2549     PTR_FORMAT "-" PTR_FORMAT ".",
2550     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2551 
2552 }
2553 
2554 void JavaThread::enable_stack_reserved_zone() {
2555   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2556   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2557 
2558   // The base notation is from the stack's point of view, growing downward.
2559   // We need to adjust it to work correctly with guard_memory()
2560   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2561 
2562   guarantee(base &lt; stack_base(),"Error calculating stack reserved zone");
2563   guarantee(base &lt; os::current_stack_pointer(),"Error calculating stack reserved zone");
2564 
2565   if (os::guard_memory((char *) base, stack_reserved_zone_size())) {
2566     _stack_guard_state = stack_guard_enabled;
2567   } else {
2568     warning("Attempt to guard stack reserved zone failed.");
2569   }
2570   enable_register_stack_guard();
2571 }
2572 
2573 void JavaThread::disable_stack_reserved_zone() {
2574   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2575   assert(_stack_guard_state != stack_guard_reserved_disabled, "already disabled");
2576 
2577   // Simply return if called for a thread that does not use guard pages.
2578   if (_stack_guard_state == stack_guard_unused) return;
2579 
2580   // The base notation is from the stack's point of view, growing downward.
2581   // We need to adjust it to work correctly with guard_memory()
2582   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2583 
2584   if (os::unguard_memory((char *)base, stack_reserved_zone_size())) {
2585     _stack_guard_state = stack_guard_reserved_disabled;
2586   } else {
2587     warning("Attempt to unguard stack reserved zone failed.");
2588   }
2589   disable_register_stack_guard();
2590 }
2591 
2592 void JavaThread::enable_stack_yellow_reserved_zone() {
2593   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2594   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2595 
2596   // The base notation is from the stacks point of view, growing downward.
2597   // We need to adjust it to work correctly with guard_memory()
2598   address base = stack_red_zone_base();
2599 
2600   guarantee(base &lt; stack_base(), "Error calculating stack yellow zone");
2601   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack yellow zone");
2602 
2603   if (os::guard_memory((char *) base, stack_yellow_reserved_zone_size())) {
2604     _stack_guard_state = stack_guard_enabled;
2605   } else {
2606     warning("Attempt to guard stack yellow zone failed.");
2607   }
2608   enable_register_stack_guard();
2609 }
2610 
2611 void JavaThread::disable_stack_yellow_reserved_zone() {
2612   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2613   assert(_stack_guard_state != stack_guard_yellow_reserved_disabled, "already disabled");
2614 
2615   // Simply return if called for a thread that does not use guard pages.
2616   if (_stack_guard_state == stack_guard_unused) return;
2617 
2618   // The base notation is from the stacks point of view, growing downward.
2619   // We need to adjust it to work correctly with guard_memory()
2620   address base = stack_red_zone_base();
2621 
2622   if (os::unguard_memory((char *)base, stack_yellow_reserved_zone_size())) {
2623     _stack_guard_state = stack_guard_yellow_reserved_disabled;
2624   } else {
2625     warning("Attempt to unguard stack yellow zone failed.");
2626   }
2627   disable_register_stack_guard();
2628 }
2629 
2630 void JavaThread::enable_stack_red_zone() {
2631   // The base notation is from the stacks point of view, growing downward.
2632   // We need to adjust it to work correctly with guard_memory()
2633   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2634   address base = stack_red_zone_base() - stack_red_zone_size();
2635 
2636   guarantee(base &lt; stack_base(), "Error calculating stack red zone");
2637   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack red zone");
2638 
2639   if (!os::guard_memory((char *) base, stack_red_zone_size())) {
2640     warning("Attempt to guard stack red zone failed.");
2641   }
2642 }
2643 
2644 void JavaThread::disable_stack_red_zone() {
2645   // The base notation is from the stacks point of view, growing downward.
2646   // We need to adjust it to work correctly with guard_memory()
2647   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2648   address base = stack_red_zone_base() - stack_red_zone_size();
2649   if (!os::unguard_memory((char *)base, stack_red_zone_size())) {
2650     warning("Attempt to unguard stack red zone failed.");
2651   }
2652 }
2653 
2654 void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {
2655   // ignore is there is no stack
2656   if (!has_last_Java_frame()) return;
2657   // traverse the stack frames. Starts from top frame.
2658   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2659     frame* fr = fst.current();
2660     f(fr, fst.register_map());
2661   }
2662 }
2663 
2664 
2665 #ifndef PRODUCT
2666 // Deoptimization
2667 // Function for testing deoptimization
2668 void JavaThread::deoptimize() {
2669   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2670   StackFrameStream fst(this, UseBiasedLocking);
2671   bool deopt = false;           // Dump stack only if a deopt actually happens.
2672   bool only_at = strlen(DeoptimizeOnlyAt) &gt; 0;
2673   // Iterate over all frames in the thread and deoptimize
2674   for (; !fst.is_done(); fst.next()) {
2675     if (fst.current()-&gt;can_be_deoptimized()) {
2676 
2677       if (only_at) {
2678         // Deoptimize only at particular bcis.  DeoptimizeOnlyAt
2679         // consists of comma or carriage return separated numbers so
2680         // search for the current bci in that string.
2681         address pc = fst.current()-&gt;pc();
2682         nmethod* nm =  (nmethod*) fst.current()-&gt;cb();
2683         ScopeDesc* sd = nm-&gt;scope_desc_at(pc);
2684         char buffer[8];
2685         jio_snprintf(buffer, sizeof(buffer), "%d", sd-&gt;bci());
2686         size_t len = strlen(buffer);
2687         const char * found = strstr(DeoptimizeOnlyAt, buffer);
2688         while (found != NULL) {
2689           if ((found[len] == ',' || found[len] == '\n' || found[len] == '\0') &amp;&amp;
2690               (found == DeoptimizeOnlyAt || found[-1] == ',' || found[-1] == '\n')) {
2691             // Check that the bci found is bracketed by terminators.
2692             break;
2693           }
2694           found = strstr(found + 1, buffer);
2695         }
2696         if (!found) {
2697           continue;
2698         }
2699       }
2700 
2701       if (DebugDeoptimization &amp;&amp; !deopt) {
2702         deopt = true; // One-time only print before deopt
2703         tty-&gt;print_cr("[BEFORE Deoptimization]");
2704         trace_frames();
2705         trace_stack();
2706       }
2707       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2708     }
2709   }
2710 
2711   if (DebugDeoptimization &amp;&amp; deopt) {
2712     tty-&gt;print_cr("[AFTER Deoptimization]");
2713     trace_frames();
2714   }
2715 }
2716 
2717 
2718 // Make zombies
2719 void JavaThread::make_zombies() {
2720   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2721     if (fst.current()-&gt;can_be_deoptimized()) {
2722       // it is a Java nmethod
2723       nmethod* nm = CodeCache::find_nmethod(fst.current()-&gt;pc());
2724       nm-&gt;make_not_entrant();
2725     }
2726   }
2727 }
2728 #endif // PRODUCT
2729 
2730 
2731 void JavaThread::deoptimized_wrt_marked_nmethods() {
2732   if (!has_last_Java_frame()) return;
2733   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2734   StackFrameStream fst(this, UseBiasedLocking);
2735   for (; !fst.is_done(); fst.next()) {
2736     if (fst.current()-&gt;should_be_deoptimized()) {
2737       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2738     }
2739   }
2740 }
2741 
2742 
2743 // If the caller is a NamedThread, then remember, in the current scope,
2744 // the given JavaThread in its _processed_thread field.
2745 class RememberProcessedThread: public StackObj {
2746   NamedThread* _cur_thr;
2747  public:
2748   RememberProcessedThread(JavaThread* jthr) {
2749     Thread* thread = Thread::current();
2750     if (thread-&gt;is_Named_thread()) {
2751       _cur_thr = (NamedThread *)thread;
2752       _cur_thr-&gt;set_processed_thread(jthr);
2753     } else {
2754       _cur_thr = NULL;
2755     }
2756   }
2757 
2758   ~RememberProcessedThread() {
2759     if (_cur_thr) {
2760       _cur_thr-&gt;set_processed_thread(NULL);
2761     }
2762   }
2763 };
2764 
2765 void JavaThread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
2766   // Verify that the deferred card marks have been flushed.
2767   assert(deferred_card_mark().is_empty(), "Should be empty during GC");
2768 
2769   // The ThreadProfiler oops_do is done from FlatProfiler::oops_do
2770   // since there may be more than one thread using each ThreadProfiler.
2771 
2772   // Traverse the GCHandles
2773   Thread::oops_do(f, cld_f, cf);
2774 
2775   JVMCI_ONLY(f-&gt;do_oop((oop*)&amp;_pending_failed_speculation);)
2776 
2777   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2778          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2779 
2780   if (has_last_Java_frame()) {
2781     // Record JavaThread to GC thread
2782     RememberProcessedThread rpt(this);
2783 
2784     // Traverse the privileged stack
2785     if (_privileged_stack_top != NULL) {
2786       _privileged_stack_top-&gt;oops_do(f);
2787     }
2788 
2789     // traverse the registered growable array
2790     if (_array_for_gc != NULL) {
2791       for (int index = 0; index &lt; _array_for_gc-&gt;length(); index++) {
2792         f-&gt;do_oop(_array_for_gc-&gt;adr_at(index));
2793       }
2794     }
2795 
2796     // Traverse the monitor chunks
2797     for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2798       chunk-&gt;oops_do(f);
2799     }
2800 
2801     // Traverse the execution stack
2802     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2803       fst.current()-&gt;oops_do(f, cld_f, cf, fst.register_map());
2804     }
2805   }
2806 
2807   // callee_target is never live across a gc point so NULL it here should
2808   // it still contain a methdOop.
2809 
2810   set_callee_target(NULL);
2811 
2812   assert(vframe_array_head() == NULL, "deopt in progress at a safepoint!");
2813   // If we have deferred set_locals there might be oops waiting to be
2814   // written
2815   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* list = deferred_locals();
2816   if (list != NULL) {
2817     for (int i = 0; i &lt; list-&gt;length(); i++) {
2818       list-&gt;at(i)-&gt;oops_do(f);
2819     }
2820   }
2821 
2822   // Traverse instance variables at the end since the GC may be moving things
2823   // around using this function
2824   f-&gt;do_oop((oop*) &amp;_threadObj);
2825   f-&gt;do_oop((oop*) &amp;_vm_result);
2826   f-&gt;do_oop((oop*) &amp;_exception_oop);
2827   f-&gt;do_oop((oop*) &amp;_pending_async_exception);
2828 
2829   if (jvmti_thread_state() != NULL) {
2830     jvmti_thread_state()-&gt;oops_do(f);
2831   }
2832 }
2833 
2834 void JavaThread::nmethods_do(CodeBlobClosure* cf) {
2835   Thread::nmethods_do(cf);  // (super method is a no-op)
2836 
2837   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2838          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2839 
2840   if (has_last_Java_frame()) {
2841     // Traverse the execution stack
2842     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2843       fst.current()-&gt;nmethods_do(cf);
2844     }
2845   }
2846 }
2847 
2848 void JavaThread::metadata_do(void f(Metadata*)) {
2849   if (has_last_Java_frame()) {
2850     // Traverse the execution stack to call f() on the methods in the stack
2851     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2852       fst.current()-&gt;metadata_do(f);
2853     }
2854   } else if (is_Compiler_thread()) {
2855     // need to walk ciMetadata in current compile tasks to keep alive.
2856     CompilerThread* ct = (CompilerThread*)this;
2857     if (ct-&gt;env() != NULL) {
2858       ct-&gt;env()-&gt;metadata_do(f);
2859     }
2860     if (ct-&gt;task() != NULL) {
2861       ct-&gt;task()-&gt;metadata_do(f);
2862     }
2863   }
2864 }
2865 
2866 // Printing
2867 const char* _get_thread_state_name(JavaThreadState _thread_state) {
2868   switch (_thread_state) {
2869   case _thread_uninitialized:     return "_thread_uninitialized";
2870   case _thread_new:               return "_thread_new";
2871   case _thread_new_trans:         return "_thread_new_trans";
2872   case _thread_in_native:         return "_thread_in_native";
2873   case _thread_in_native_trans:   return "_thread_in_native_trans";
2874   case _thread_in_vm:             return "_thread_in_vm";
2875   case _thread_in_vm_trans:       return "_thread_in_vm_trans";
2876   case _thread_in_Java:           return "_thread_in_Java";
2877   case _thread_in_Java_trans:     return "_thread_in_Java_trans";
2878   case _thread_blocked:           return "_thread_blocked";
2879   case _thread_blocked_trans:     return "_thread_blocked_trans";
2880   default:                        return "unknown thread state";
2881   }
2882 }
2883 
2884 #ifndef PRODUCT
2885 void JavaThread::print_thread_state_on(outputStream *st) const {
2886   st-&gt;print_cr("   JavaThread state: %s", _get_thread_state_name(_thread_state));
2887 };
2888 void JavaThread::print_thread_state() const {
2889   print_thread_state_on(tty);
2890 }
2891 #endif // PRODUCT
2892 
2893 // Called by Threads::print() for VM_PrintThreads operation
2894 void JavaThread::print_on(outputStream *st) const {
2895   st-&gt;print("\"%s\" ", get_thread_name());
2896   oop thread_oop = threadObj();
2897   if (thread_oop != NULL) {
2898     st-&gt;print("#" INT64_FORMAT " ", java_lang_Thread::thread_id(thread_oop));
2899     if (java_lang_Thread::is_daemon(thread_oop))  st-&gt;print("daemon ");
2900     st-&gt;print("prio=%d ", java_lang_Thread::priority(thread_oop));
2901   }
2902   Thread::print_on(st);
2903   // print guess for valid stack memory region (assume 4K pages); helps lock debugging
2904   st-&gt;print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &amp; ~right_n_bits(12));
2905   if (thread_oop != NULL) {
2906     st-&gt;print_cr("   java.lang.Thread.State: %s", java_lang_Thread::thread_status_name(thread_oop));
2907   }
2908 #ifndef PRODUCT
2909   print_thread_state_on(st);
2910   _safepoint_state-&gt;print_on(st);
2911 #endif // PRODUCT
2912   if (is_Compiler_thread()) {
2913     CompilerThread* ct = (CompilerThread*)this;
2914     if (ct-&gt;task() != NULL) {
2915       st-&gt;print("   Compiling: ");
2916       ct-&gt;task()-&gt;print(st, NULL, true, false);
2917     } else {
2918       st-&gt;print("   No compile task");
2919     }
2920     st-&gt;cr();
2921   }
2922 }
2923 
2924 void JavaThread::print_name_on_error(outputStream* st, char *buf, int buflen) const {
2925   st-&gt;print("%s", get_thread_name_string(buf, buflen));
2926 }
2927 
2928 // Called by fatal error handler. The difference between this and
2929 // JavaThread::print() is that we can't grab lock or allocate memory.
2930 void JavaThread::print_on_error(outputStream* st, char *buf, int buflen) const {
2931   st-&gt;print("JavaThread \"%s\"", get_thread_name_string(buf, buflen));
2932   oop thread_obj = threadObj();
2933   if (thread_obj != NULL) {
2934     if (java_lang_Thread::is_daemon(thread_obj)) st-&gt;print(" daemon");
2935   }
2936   st-&gt;print(" [");
2937   st-&gt;print("%s", _get_thread_state_name(_thread_state));
2938   if (osthread()) {
2939     st-&gt;print(", id=%d", osthread()-&gt;thread_id());
2940   }
2941   st-&gt;print(", stack(" PTR_FORMAT "," PTR_FORMAT ")",
2942             p2i(stack_end()), p2i(stack_base()));
2943   st-&gt;print("]");
2944   return;
2945 }
2946 
2947 // Verification
2948 
2949 static void frame_verify(frame* f, const RegisterMap *map) { f-&gt;verify(map); }
2950 
2951 void JavaThread::verify() {
2952   // Verify oops in the thread.
2953   oops_do(&amp;VerifyOopClosure::verify_oop, NULL, NULL);
2954 
2955   // Verify the stack frames.
2956   frames_do(frame_verify);
2957 }
2958 
2959 // CR 6300358 (sub-CR 2137150)
2960 // Most callers of this method assume that it can't return NULL but a
2961 // thread may not have a name whilst it is in the process of attaching to
2962 // the VM - see CR 6412693, and there are places where a JavaThread can be
2963 // seen prior to having it's threadObj set (eg JNI attaching threads and
2964 // if vm exit occurs during initialization). These cases can all be accounted
2965 // for such that this method never returns NULL.
2966 const char* JavaThread::get_thread_name() const {
2967 #ifdef ASSERT
2968   // early safepoints can hit while current thread does not yet have TLS
2969   if (!SafepointSynchronize::is_at_safepoint()) {
2970     Thread *cur = Thread::current();
2971     if (!(cur-&gt;is_Java_thread() &amp;&amp; cur == this)) {
2972       // Current JavaThreads are allowed to get their own name without
2973       // the Threads_lock.
2974       assert_locked_or_safepoint(Threads_lock);
2975     }
2976   }
2977 #endif // ASSERT
2978   return get_thread_name_string();
2979 }
2980 
2981 // Returns a non-NULL representation of this thread's name, or a suitable
2982 // descriptive string if there is no set name
2983 const char* JavaThread::get_thread_name_string(char* buf, int buflen) const {
2984   const char* name_str;
2985   oop thread_obj = threadObj();
2986   if (thread_obj != NULL) {
2987     oop name = java_lang_Thread::name(thread_obj);
2988     if (name != NULL) {
2989       if (buf == NULL) {
2990         name_str = java_lang_String::as_utf8_string(name);
2991       } else {
2992         name_str = java_lang_String::as_utf8_string(name, buf, buflen);
2993       }
2994     } else if (is_attaching_via_jni()) { // workaround for 6412693 - see 6404306
2995       name_str = "&lt;no-name - thread is attaching&gt;";
2996     } else {
2997       name_str = Thread::name();
2998     }
2999   } else {
3000     name_str = Thread::name();
3001   }
3002   assert(name_str != NULL, "unexpected NULL thread name");
3003   return name_str;
3004 }
3005 
3006 
3007 const char* JavaThread::get_threadgroup_name() const {
3008   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3009   oop thread_obj = threadObj();
3010   if (thread_obj != NULL) {
3011     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3012     if (thread_group != NULL) {
3013       // ThreadGroup.name can be null
3014       return java_lang_ThreadGroup::name(thread_group);
3015     }
3016   }
3017   return NULL;
3018 }
3019 
3020 const char* JavaThread::get_parent_name() const {
3021   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3022   oop thread_obj = threadObj();
3023   if (thread_obj != NULL) {
3024     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3025     if (thread_group != NULL) {
3026       oop parent = java_lang_ThreadGroup::parent(thread_group);
3027       if (parent != NULL) {
3028         // ThreadGroup.name can be null
3029         return java_lang_ThreadGroup::name(parent);
3030       }
3031     }
3032   }
3033   return NULL;
3034 }
3035 
3036 ThreadPriority JavaThread::java_priority() const {
3037   oop thr_oop = threadObj();
3038   if (thr_oop == NULL) return NormPriority; // Bootstrapping
3039   ThreadPriority priority = java_lang_Thread::priority(thr_oop);
3040   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "sanity check");
3041   return priority;
3042 }
3043 
3044 void JavaThread::prepare(jobject jni_thread, ThreadPriority prio) {
3045 
3046   assert(Threads_lock-&gt;owner() == Thread::current(), "must have threads lock");
3047   // Link Java Thread object &lt;-&gt; C++ Thread
3048 
3049   // Get the C++ thread object (an oop) from the JNI handle (a jthread)
3050   // and put it into a new Handle.  The Handle "thread_oop" can then
3051   // be used to pass the C++ thread object to other methods.
3052 
3053   // Set the Java level thread object (jthread) field of the
3054   // new thread (a JavaThread *) to C++ thread object using the
3055   // "thread_oop" handle.
3056 
3057   // Set the thread field (a JavaThread *) of the
3058   // oop representing the java_lang_Thread to the new thread (a JavaThread *).
3059 
3060   Handle thread_oop(Thread::current(),
3061                     JNIHandles::resolve_non_null(jni_thread));
3062   assert(InstanceKlass::cast(thread_oop-&gt;klass())-&gt;is_linked(),
3063          "must be initialized");
3064   set_threadObj(thread_oop());
3065   java_lang_Thread::set_thread(thread_oop(), this);
3066 
3067   if (prio == NoPriority) {
3068     prio = java_lang_Thread::priority(thread_oop());
3069     assert(prio != NoPriority, "A valid priority should be present");
3070   }
3071 
3072   // Push the Java priority down to the native thread; needs Threads_lock
3073   Thread::set_priority(this, prio);
3074 
3075   prepare_ext();
3076 
3077   // Add the new thread to the Threads list and set it in motion.
3078   // We must have threads lock in order to call Threads::add.
3079   // It is crucial that we do not block before the thread is
3080   // added to the Threads list for if a GC happens, then the java_thread oop
3081   // will not be visited by GC.
3082   Threads::add(this);
3083 }
3084 
3085 oop JavaThread::current_park_blocker() {
3086   // Support for JSR-166 locks
3087   oop thread_oop = threadObj();
3088   if (thread_oop != NULL &amp;&amp;
3089       JDK_Version::current().supports_thread_park_blocker()) {
3090     return java_lang_Thread::park_blocker(thread_oop);
3091   }
3092   return NULL;
3093 }
3094 
3095 
3096 void JavaThread::print_stack_on(outputStream* st) {
3097   if (!has_last_Java_frame()) return;
3098   ResourceMark rm;
3099   HandleMark   hm;
3100 
3101   RegisterMap reg_map(this);
3102   vframe* start_vf = last_java_vframe(&amp;reg_map);
3103   int count = 0;
3104   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3105     if (f-&gt;is_java_frame()) {
3106       javaVFrame* jvf = javaVFrame::cast(f);
3107       java_lang_Throwable::print_stack_element(st, jvf-&gt;method(), jvf-&gt;bci());
3108 
3109       // Print out lock information
3110       if (JavaMonitorsInStackTrace) {
3111         jvf-&gt;print_lock_info_on(st, count);
3112       }
3113     } else {
3114       // Ignore non-Java frames
3115     }
3116 
3117     // Bail-out case for too deep stacks
3118     count++;
3119     if (MaxJavaStackTraceDepth == count) return;
3120   }
3121 }
3122 
3123 
3124 // JVMTI PopFrame support
3125 void JavaThread::popframe_preserve_args(ByteSize size_in_bytes, void* start) {
3126   assert(_popframe_preserved_args == NULL, "should not wipe out old PopFrame preserved arguments");
3127   if (in_bytes(size_in_bytes) != 0) {
3128     _popframe_preserved_args = NEW_C_HEAP_ARRAY(char, in_bytes(size_in_bytes), mtThread);
3129     _popframe_preserved_args_size = in_bytes(size_in_bytes);
3130     Copy::conjoint_jbytes(start, _popframe_preserved_args, _popframe_preserved_args_size);
3131   }
3132 }
3133 
3134 void* JavaThread::popframe_preserved_args() {
3135   return _popframe_preserved_args;
3136 }
3137 
3138 ByteSize JavaThread::popframe_preserved_args_size() {
3139   return in_ByteSize(_popframe_preserved_args_size);
3140 }
3141 
3142 WordSize JavaThread::popframe_preserved_args_size_in_words() {
3143   int sz = in_bytes(popframe_preserved_args_size());
3144   assert(sz % wordSize == 0, "argument size must be multiple of wordSize");
3145   return in_WordSize(sz / wordSize);
3146 }
3147 
3148 void JavaThread::popframe_free_preserved_args() {
3149   assert(_popframe_preserved_args != NULL, "should not free PopFrame preserved arguments twice");
3150   FREE_C_HEAP_ARRAY(char, (char*) _popframe_preserved_args);
3151   _popframe_preserved_args = NULL;
3152   _popframe_preserved_args_size = 0;
3153 }
3154 
3155 #ifndef PRODUCT
3156 
3157 void JavaThread::trace_frames() {
3158   tty-&gt;print_cr("[Describe stack]");
3159   int frame_no = 1;
3160   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
3161     tty-&gt;print("  %d. ", frame_no++);
3162     fst.current()-&gt;print_value_on(tty, this);
3163     tty-&gt;cr();
3164   }
3165 }
3166 
3167 class PrintAndVerifyOopClosure: public OopClosure {
3168  protected:
3169   template &lt;class T&gt; inline void do_oop_work(T* p) {
3170     oop obj = oopDesc::load_decode_heap_oop(p);
3171     if (obj == NULL) return;
3172     tty-&gt;print(INTPTR_FORMAT ": ", p2i(p));
3173     if (obj-&gt;is_oop_or_null()) {
3174       if (obj-&gt;is_objArray()) {
3175         tty-&gt;print_cr("valid objArray: " INTPTR_FORMAT, p2i(obj));
3176       } else {
3177         obj-&gt;print();
3178       }
3179     } else {
3180       tty-&gt;print_cr("invalid oop: " INTPTR_FORMAT, p2i(obj));
3181     }
3182     tty-&gt;cr();
3183   }
3184  public:
3185   virtual void do_oop(oop* p) { do_oop_work(p); }
3186   virtual void do_oop(narrowOop* p)  { do_oop_work(p); }
3187 };
3188 
3189 
3190 static void oops_print(frame* f, const RegisterMap *map) {
3191   PrintAndVerifyOopClosure print;
3192   f-&gt;print_value();
3193   f-&gt;oops_do(&amp;print, NULL, NULL, (RegisterMap*)map);
3194 }
3195 
3196 // Print our all the locations that contain oops and whether they are
3197 // valid or not.  This useful when trying to find the oldest frame
3198 // where an oop has gone bad since the frame walk is from youngest to
3199 // oldest.
3200 void JavaThread::trace_oops() {
3201   tty-&gt;print_cr("[Trace oops]");
3202   frames_do(oops_print);
3203 }
3204 
3205 
3206 #ifdef ASSERT
3207 // Print or validate the layout of stack frames
3208 void JavaThread::print_frame_layout(int depth, bool validate_only) {
3209   ResourceMark rm;
3210   PRESERVE_EXCEPTION_MARK;
3211   FrameValues values;
3212   int frame_no = 0;
3213   for (StackFrameStream fst(this, false); !fst.is_done(); fst.next()) {
3214     fst.current()-&gt;describe(values, ++frame_no);
3215     if (depth == frame_no) break;
3216   }
3217   if (validate_only) {
3218     values.validate();
3219   } else {
3220     tty-&gt;print_cr("[Describe stack layout]");
3221     values.print(this);
3222   }
3223 }
3224 #endif
3225 
3226 void JavaThread::trace_stack_from(vframe* start_vf) {
3227   ResourceMark rm;
3228   int vframe_no = 1;
3229   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3230     if (f-&gt;is_java_frame()) {
3231       javaVFrame::cast(f)-&gt;print_activation(vframe_no++);
3232     } else {
3233       f-&gt;print();
3234     }
3235     if (vframe_no &gt; StackPrintLimit) {
3236       tty-&gt;print_cr("...&lt;more frames&gt;...");
3237       return;
3238     }
3239   }
3240 }
3241 
3242 
3243 void JavaThread::trace_stack() {
3244   if (!has_last_Java_frame()) return;
3245   ResourceMark rm;
3246   HandleMark   hm;
3247   RegisterMap reg_map(this);
3248   trace_stack_from(last_java_vframe(&amp;reg_map));
3249 }
3250 
3251 
3252 #endif // PRODUCT
3253 
3254 
3255 javaVFrame* JavaThread::last_java_vframe(RegisterMap *reg_map) {
3256   assert(reg_map != NULL, "a map must be given");
3257   frame f = last_frame();
3258   for (vframe* vf = vframe::new_vframe(&amp;f, reg_map, this); vf; vf = vf-&gt;sender()) {
3259     if (vf-&gt;is_java_frame()) return javaVFrame::cast(vf);
3260   }
3261   return NULL;
3262 }
3263 
3264 
3265 Klass* JavaThread::security_get_caller_class(int depth) {
3266   vframeStream vfst(this);
3267   vfst.security_get_caller_frame(depth);
3268   if (!vfst.at_end()) {
3269     return vfst.method()-&gt;method_holder();
3270   }
3271   return NULL;
3272 }
3273 
3274 static void compiler_thread_entry(JavaThread* thread, TRAPS) {
3275   assert(thread-&gt;is_Compiler_thread(), "must be compiler thread");
3276   CompileBroker::compiler_thread_loop();
3277 }
3278 
3279 static void sweeper_thread_entry(JavaThread* thread, TRAPS) {
3280   NMethodSweeper::sweeper_loop();
3281 }
3282 
3283 // Create a CompilerThread
3284 CompilerThread::CompilerThread(CompileQueue* queue,
3285                                CompilerCounters* counters)
3286                                : JavaThread(&amp;compiler_thread_entry) {
3287   _env   = NULL;
3288   _log   = NULL;
3289   _task  = NULL;
3290   _queue = queue;
3291   _counters = counters;
3292   _buffer_blob = NULL;
3293   _compiler = NULL;
3294 
3295 #ifndef PRODUCT
3296   _ideal_graph_printer = NULL;
3297 #endif
3298 }
3299 
3300 bool CompilerThread::can_call_java() const {
3301   return _compiler != NULL &amp;&amp; _compiler-&gt;is_jvmci();
3302 }
3303 
3304 // Create sweeper thread
3305 CodeCacheSweeperThread::CodeCacheSweeperThread()
3306 : JavaThread(&amp;sweeper_thread_entry) {
3307   _scanned_nmethod = NULL;
3308 }
3309 void CodeCacheSweeperThread::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
3310   JavaThread::oops_do(f, cld_f, cf);
3311   if (_scanned_nmethod != NULL &amp;&amp; cf != NULL) {
3312     // Safepoints can occur when the sweeper is scanning an nmethod so
3313     // process it here to make sure it isn't unloaded in the middle of
3314     // a scan.
3315     cf-&gt;do_code_blob(_scanned_nmethod);
3316   }
3317 }
3318 
3319 
3320 // ======= Threads ========
3321 
3322 // The Threads class links together all active threads, and provides
3323 // operations over all threads.  It is protected by its own Mutex
3324 // lock, which is also used in other contexts to protect thread
3325 // operations from having the thread being operated on from exiting
3326 // and going away unexpectedly (e.g., safepoint synchronization)
3327 
3328 JavaThread* Threads::_thread_list = NULL;
3329 int         Threads::_number_of_threads = 0;
3330 int         Threads::_number_of_non_daemon_threads = 0;
3331 int         Threads::_return_code = 0;
3332 int         Threads::_thread_claim_parity = 0;
3333 size_t      JavaThread::_stack_size_at_create = 0;
3334 #ifdef ASSERT
3335 bool        Threads::_vm_complete = false;
3336 #endif
3337 
3338 // All JavaThreads
3339 #define ALL_JAVA_THREADS(X) for (JavaThread* X = _thread_list; X; X = X-&gt;next())
3340 
3341 // All JavaThreads + all non-JavaThreads (i.e., every thread in the system)
3342 void Threads::threads_do(ThreadClosure* tc) {
3343   assert_locked_or_safepoint(Threads_lock);
3344   // ALL_JAVA_THREADS iterates through all JavaThreads
3345   ALL_JAVA_THREADS(p) {
3346     tc-&gt;do_thread(p);
3347   }
3348   // Someday we could have a table or list of all non-JavaThreads.
3349   // For now, just manually iterate through them.
3350   tc-&gt;do_thread(VMThread::vm_thread());
3351   Universe::heap()-&gt;gc_threads_do(tc);
3352   WatcherThread *wt = WatcherThread::watcher_thread();
3353   // Strictly speaking, the following NULL check isn't sufficient to make sure
3354   // the data for WatcherThread is still valid upon being examined. However,
3355   // considering that WatchThread terminates when the VM is on the way to
3356   // exit at safepoint, the chance of the above is extremely small. The right
3357   // way to prevent termination of WatcherThread would be to acquire
3358   // Terminator_lock, but we can't do that without violating the lock rank
3359   // checking in some cases.
3360   if (wt != NULL) {
3361     tc-&gt;do_thread(wt);
3362   }
3363 
3364   // If CompilerThreads ever become non-JavaThreads, add them here
3365 }
3366 
3367 void Threads::initialize_java_lang_classes(JavaThread* main_thread, TRAPS) {
3368   TraceStartupTime timer("Initialize java.lang classes");
3369 
3370   if (EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3371     create_vm_init_libraries();
3372   }
3373 
3374   initialize_class(vmSymbols::java_lang_String(), CHECK);
3375 
3376   // Inject CompactStrings value after the static initializers for String ran.
3377   java_lang_String::set_compact_strings(CompactStrings);
3378 
3379   // Initialize java_lang.System (needed before creating the thread)
3380   initialize_class(vmSymbols::java_lang_System(), CHECK);
3381   // The VM creates &amp; returns objects of this class. Make sure it's initialized.
3382   initialize_class(vmSymbols::java_lang_Class(), CHECK);
3383   initialize_class(vmSymbols::java_lang_ThreadGroup(), CHECK);
3384   Handle thread_group = create_initial_thread_group(CHECK);
3385   Universe::set_main_thread_group(thread_group());
3386   initialize_class(vmSymbols::java_lang_Thread(), CHECK);
3387   oop thread_object = create_initial_thread(thread_group, main_thread, CHECK);
3388   main_thread-&gt;set_threadObj(thread_object);
3389   // Set thread status to running since main thread has
3390   // been started and running.
3391   java_lang_Thread::set_thread_status(thread_object,
3392                                       java_lang_Thread::RUNNABLE);
3393 
3394   // The VM preresolves methods to these classes. Make sure that they get initialized
3395   initialize_class(vmSymbols::java_lang_reflect_Method(), CHECK);
3396   initialize_class(vmSymbols::java_lang_ref_Finalizer(), CHECK);
3397   call_initializeSystemClass(CHECK);
3398 
3399   // get the Java runtime name after java.lang.System is initialized
3400   JDK_Version::set_runtime_name(get_java_runtime_name(THREAD));
3401   JDK_Version::set_runtime_version(get_java_runtime_version(THREAD));
3402 
3403   // an instance of OutOfMemory exception has been allocated earlier
3404   initialize_class(vmSymbols::java_lang_OutOfMemoryError(), CHECK);
3405   initialize_class(vmSymbols::java_lang_NullPointerException(), CHECK);
3406   initialize_class(vmSymbols::java_lang_ClassCastException(), CHECK);
3407   initialize_class(vmSymbols::java_lang_ArrayStoreException(), CHECK);
3408   initialize_class(vmSymbols::java_lang_ArithmeticException(), CHECK);
3409   initialize_class(vmSymbols::java_lang_StackOverflowError(), CHECK);
3410   initialize_class(vmSymbols::java_lang_IllegalMonitorStateException(), CHECK);
3411   initialize_class(vmSymbols::java_lang_IllegalArgumentException(), CHECK);
3412 }
3413 
3414 void Threads::initialize_jsr292_core_classes(TRAPS) {
3415   TraceStartupTime timer("Initialize java.lang.invoke classes");
3416 
3417   initialize_class(vmSymbols::java_lang_invoke_MethodHandle(), CHECK);
3418   initialize_class(vmSymbols::java_lang_invoke_MemberName(), CHECK);
3419   initialize_class(vmSymbols::java_lang_invoke_MethodHandleNatives(), CHECK);
3420 }
3421 
3422 jint Threads::create_vm(JavaVMInitArgs* args, bool* canTryAgain) {
3423   extern void JDK_Version_init();
3424 
3425   // Preinitialize version info.
3426   VM_Version::early_initialize();
3427 
3428   // Check version
3429   if (!is_supported_jni_version(args-&gt;version)) return JNI_EVERSION;
3430 
3431   // Initialize library-based TLS
3432   ThreadLocalStorage::init();
3433 
3434   // Initialize the output stream module
3435   ostream_init();
3436 
3437   // Process java launcher properties.
3438   Arguments::process_sun_java_launcher_properties(args);
3439 
3440   // Initialize the os module
3441   os::init();
3442 
3443   // Record VM creation timing statistics
3444   TraceVmCreationTime create_vm_timer;
3445   create_vm_timer.start();
3446 
3447   // Initialize system properties.
3448   Arguments::init_system_properties();
3449 
3450   // So that JDK version can be used as a discriminator when parsing arguments
3451   JDK_Version_init();
3452 
3453   // Update/Initialize System properties after JDK version number is known
3454   Arguments::init_version_specific_system_properties();
3455 
3456   // Make sure to initialize log configuration *before* parsing arguments
3457   LogConfiguration::initialize(create_vm_timer.begin_time());
3458 
3459   // Parse arguments
3460   jint parse_result = Arguments::parse(args);
3461   if (parse_result != JNI_OK) return parse_result;
3462 
3463   os::init_before_ergo();
3464 
3465   jint ergo_result = Arguments::apply_ergo();
3466   if (ergo_result != JNI_OK) return ergo_result;
3467 
3468   // Final check of all ranges after ergonomics which may change values.
3469   if (!CommandLineFlagRangeList::check_ranges()) {
3470     return JNI_EINVAL;
3471   }
3472 
3473   // Final check of all 'AfterErgo' constraints after ergonomics which may change values.
3474   bool constraint_result = CommandLineFlagConstraintList::check_constraints(CommandLineFlagConstraint::AfterErgo);
3475   if (!constraint_result) {
3476     return JNI_EINVAL;
3477   }
3478 
3479   if (PauseAtStartup) {
3480     os::pause();
3481   }
3482 
3483   HOTSPOT_VM_INIT_BEGIN();
3484 
3485   // Timing (must come after argument parsing)
3486   TraceStartupTime timer("Create VM");
3487 
3488   // Initialize the os module after parsing the args
3489   jint os_init_2_result = os::init_2();
3490   if (os_init_2_result != JNI_OK) return os_init_2_result;
3491 
3492   jint adjust_after_os_result = Arguments::adjust_after_os();
3493   if (adjust_after_os_result != JNI_OK) return adjust_after_os_result;
3494 
3495   // Initialize output stream logging
3496   ostream_init_log();
3497 
3498   // Convert -Xrun to -agentlib: if there is no JVM_OnLoad
3499   // Must be before create_vm_init_agents()
3500   if (Arguments::init_libraries_at_startup()) {
3501     convert_vm_init_libraries_to_agents();
3502   }
3503 
3504   // Launch -agentlib/-agentpath and converted -Xrun agents
3505   if (Arguments::init_agents_at_startup()) {
3506     create_vm_init_agents();
3507   }
3508 
3509   // Initialize Threads state
3510   _thread_list = NULL;
3511   _number_of_threads = 0;
3512   _number_of_non_daemon_threads = 0;
3513 
3514   // Initialize global data structures and create system classes in heap
3515   vm_init_globals();
3516 
3517 #if INCLUDE_JVMCI
3518   if (JVMCICounterSize &gt; 0) {
3519     JavaThread::_jvmci_old_thread_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
3520     memset(JavaThread::_jvmci_old_thread_counters, 0, sizeof(jlong) * JVMCICounterSize);
3521   } else {
3522     JavaThread::_jvmci_old_thread_counters = NULL;
3523   }
3524 #endif // INCLUDE_JVMCI
3525 
3526   // Attach the main thread to this os thread
3527   JavaThread* main_thread = new JavaThread();
3528   main_thread-&gt;set_thread_state(_thread_in_vm);
3529   main_thread-&gt;initialize_thread_current();
3530   // must do this before set_active_handles
3531   main_thread-&gt;record_stack_base_and_size();
3532   main_thread-&gt;set_active_handles(JNIHandleBlock::allocate_block());
3533 
3534   if (!main_thread-&gt;set_as_starting_thread()) {
3535     vm_shutdown_during_initialization(
3536                                       "Failed necessary internal allocation. Out of swap space");
3537     delete main_thread;
3538     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3539     return JNI_ENOMEM;
3540   }
3541 
3542   // Enable guard page *after* os::create_main_thread(), otherwise it would
3543   // crash Linux VM, see notes in os_linux.cpp.
3544   main_thread-&gt;create_stack_guard_pages();
3545 
3546   // Initialize Java-Level synchronization subsystem
3547   ObjectMonitor::Initialize();
3548 
3549   // Initialize global modules
3550   jint status = init_globals();
3551   if (status != JNI_OK) {
3552     delete main_thread;
3553     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3554     return status;
3555   }
3556 
3557   if (TRACE_INITIALIZE() != JNI_OK) {
3558     vm_exit_during_initialization("Failed to initialize tracing backend");
3559   }
3560 
3561   // Should be done after the heap is fully created
3562   main_thread-&gt;cache_global_variables();
3563 
3564   HandleMark hm;
3565 
3566   { MutexLocker mu(Threads_lock);
3567     Threads::add(main_thread);
3568   }
3569 
3570   // Any JVMTI raw monitors entered in onload will transition into
3571   // real raw monitor. VM is setup enough here for raw monitor enter.
3572   JvmtiExport::transition_pending_onload_raw_monitors();
3573 
3574   // Create the VMThread
3575   { TraceStartupTime timer("Start VMThread");
3576 
3577   VMThread::create();
3578     Thread* vmthread = VMThread::vm_thread();
3579 
3580     if (!os::create_thread(vmthread, os::vm_thread)) {
3581       vm_exit_during_initialization("Cannot create VM thread. "
3582                                     "Out of system resources.");
3583     }
3584 
3585     // Wait for the VM thread to become ready, and VMThread::run to initialize
3586     // Monitors can have spurious returns, must always check another state flag
3587     {
3588       MutexLocker ml(Notify_lock);
3589       os::start_thread(vmthread);
3590       while (vmthread-&gt;active_handles() == NULL) {
3591         Notify_lock-&gt;wait();
3592       }
3593     }
3594   }
3595 
3596   assert(Universe::is_fully_initialized(), "not initialized");
3597   if (VerifyDuringStartup) {
3598     // Make sure we're starting with a clean slate.
3599     VM_Verify verify_op;
3600     VMThread::execute(&amp;verify_op);
3601   }
3602 
3603   Thread* THREAD = Thread::current();
3604 
3605   // At this point, the Universe is initialized, but we have not executed
3606   // any byte code.  Now is a good time (the only time) to dump out the
3607   // internal state of the JVM for sharing.
3608   if (DumpSharedSpaces) {
3609     MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);
3610     ShouldNotReachHere();
3611   }
3612 
3613   // Always call even when there are not JVMTI environments yet, since environments
3614   // may be attached late and JVMTI must track phases of VM execution
3615   JvmtiExport::enter_start_phase();
3616 
3617   // Notify JVMTI agents that VM has started (JNI is up) - nop if no agents.
3618   JvmtiExport::post_vm_start();
3619 
3620   initialize_java_lang_classes(main_thread, CHECK_JNI_ERR);
3621 
3622   // We need this for ClassDataSharing - the initial vm.info property is set
3623   // with the default value of CDS "sharing" which may be reset through
3624   // command line options.
3625   reset_vm_info_property(CHECK_JNI_ERR);
3626 
3627   quicken_jni_functions();
3628 
3629   // No more stub generation allowed after that point.
3630   StubCodeDesc::freeze();
3631 
3632   // Set flag that basic initialization has completed. Used by exceptions and various
3633   // debug stuff, that does not work until all basic classes have been initialized.
3634   set_init_completed();
3635 
3636   LogConfiguration::post_initialize();
3637   Metaspace::post_initialize();
3638 
3639   HOTSPOT_VM_INIT_END();
3640 
3641   // record VM initialization completion time
3642 #if INCLUDE_MANAGEMENT
3643   Management::record_vm_init_completed();
3644 #endif // INCLUDE_MANAGEMENT
3645 
3646   // Compute system loader. Note that this has to occur after set_init_completed, since
3647   // valid exceptions may be thrown in the process.
3648   // Note that we do not use CHECK_0 here since we are inside an EXCEPTION_MARK and
3649   // set_init_completed has just been called, causing exceptions not to be shortcut
3650   // anymore. We call vm_exit_during_initialization directly instead.
3651   SystemDictionary::compute_java_system_loader(CHECK_(JNI_ERR));
3652 
3653 #if INCLUDE_ALL_GCS
3654   // Support for ConcurrentMarkSweep. This should be cleaned up
3655   // and better encapsulated. The ugly nested if test would go away
3656   // once things are properly refactored. XXX YSR
3657   if (UseConcMarkSweepGC || UseG1GC) {
3658     if (UseConcMarkSweepGC) {
3659       ConcurrentMarkSweepThread::makeSurrogateLockerThread(CHECK_JNI_ERR);
3660     } else {
3661       ConcurrentMarkThread::makeSurrogateLockerThread(CHECK_JNI_ERR);
3662     }
3663   }
3664 #endif // INCLUDE_ALL_GCS
3665 
3666   // Always call even when there are not JVMTI environments yet, since environments
3667   // may be attached late and JVMTI must track phases of VM execution
3668   JvmtiExport::enter_live_phase();
3669 
3670   // Signal Dispatcher needs to be started before VMInit event is posted
3671   os::signal_init();
3672 
3673   // Start Attach Listener if +StartAttachListener or it can't be started lazily
3674   if (!DisableAttachMechanism) {
3675     AttachListener::vm_start();
3676     if (StartAttachListener || AttachListener::init_at_startup()) {
3677       AttachListener::init();
3678     }
3679   }
3680 
3681   // Launch -Xrun agents
3682   // Must be done in the JVMTI live phase so that for backward compatibility the JDWP
3683   // back-end can launch with -Xdebug -Xrunjdwp.
3684   if (!EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3685     create_vm_init_libraries();
3686   }
3687 
3688   // Notify JVMTI agents that VM initialization is complete - nop if no agents.
3689   JvmtiExport::post_vm_initialized();
3690 
3691   if (TRACE_START() != JNI_OK) {
3692     vm_exit_during_initialization("Failed to start tracing backend.");
3693   }
3694 
3695   if (CleanChunkPoolAsync) {
3696     Chunk::start_chunk_pool_cleaner_task();
3697   }
3698 
3699 #if INCLUDE_JVMCI
3700   if (EnableJVMCI) {
3701     const char* jvmciCompiler = Arguments::PropertyList_get_value(Arguments::system_properties(), "jvmci.compiler");
3702     if (jvmciCompiler != NULL) {
3703       JVMCIRuntime::save_compiler(jvmciCompiler);
3704     }
3705   }
3706 #endif // INCLUDE_JVMCI
3707 
3708   // initialize compiler(s)
3709 #if defined(COMPILER1) || defined(COMPILER2) || defined(SHARK) || INCLUDE_JVMCI
3710   CompileBroker::compilation_init(CHECK_JNI_ERR);
<a name="2" id="anc2"></a>



3711 #endif
3712 
3713   // Pre-initialize some JSR292 core classes to avoid deadlock during class loading.
3714   // It is done after compilers are initialized, because otherwise compilations of
3715   // signature polymorphic MH intrinsics can be missed
3716   // (see SystemDictionary::find_method_handle_intrinsic).
3717   initialize_jsr292_core_classes(CHECK_JNI_ERR);
3718 
3719 #if INCLUDE_MANAGEMENT
3720   Management::initialize(THREAD);
3721 
3722   if (HAS_PENDING_EXCEPTION) {
3723     // management agent fails to start possibly due to
3724     // configuration problem and is responsible for printing
3725     // stack trace if appropriate. Simply exit VM.
3726     vm_exit(1);
3727   }
3728 #endif // INCLUDE_MANAGEMENT
3729 
3730   if (Arguments::has_profile())       FlatProfiler::engage(main_thread, true);
3731   if (MemProfiling)                   MemProfiler::engage();
3732   StatSampler::engage();
3733   if (CheckJNICalls)                  JniPeriodicChecker::engage();
3734 
3735   BiasedLocking::init();
3736 
3737 #if INCLUDE_RTM_OPT
3738   RTMLockingCounters::init();
3739 #endif
3740 
3741   if (JDK_Version::current().post_vm_init_hook_enabled()) {
3742     call_postVMInitHook(THREAD);
3743     // The Java side of PostVMInitHook.run must deal with all
3744     // exceptions and provide means of diagnosis.
3745     if (HAS_PENDING_EXCEPTION) {
3746       CLEAR_PENDING_EXCEPTION;
3747     }
3748   }
3749 
3750   {
3751     MutexLocker ml(PeriodicTask_lock);
3752     // Make sure the WatcherThread can be started by WatcherThread::start()
3753     // or by dynamic enrollment.
3754     WatcherThread::make_startable();
3755     // Start up the WatcherThread if there are any periodic tasks
3756     // NOTE:  All PeriodicTasks should be registered by now. If they
3757     //   aren't, late joiners might appear to start slowly (we might
3758     //   take a while to process their first tick).
3759     if (PeriodicTask::num_tasks() &gt; 0) {
3760       WatcherThread::start();
3761     }
3762   }
3763 
3764   CodeCacheExtensions::complete_step(CodeCacheExtensionsSteps::CreateVM);
3765 
3766   create_vm_timer.end();
3767 #ifdef ASSERT
3768   _vm_complete = true;
3769 #endif
3770   return JNI_OK;
3771 }
3772 
3773 // type for the Agent_OnLoad and JVM_OnLoad entry points
3774 extern "C" {
3775   typedef jint (JNICALL *OnLoadEntry_t)(JavaVM *, char *, void *);
3776 }
3777 // Find a command line agent library and return its entry point for
3778 //         -agentlib:  -agentpath:   -Xrun
3779 // num_symbol_entries must be passed-in since only the caller knows the number of symbols in the array.
3780 static OnLoadEntry_t lookup_on_load(AgentLibrary* agent,
3781                                     const char *on_load_symbols[],
3782                                     size_t num_symbol_entries) {
3783   OnLoadEntry_t on_load_entry = NULL;
3784   void *library = NULL;
3785 
3786   if (!agent-&gt;valid()) {
3787     char buffer[JVM_MAXPATHLEN];
3788     char ebuf[1024] = "";
3789     const char *name = agent-&gt;name();
3790     const char *msg = "Could not find agent library ";
3791 
3792     // First check to see if agent is statically linked into executable
3793     if (os::find_builtin_agent(agent, on_load_symbols, num_symbol_entries)) {
3794       library = agent-&gt;os_lib();
3795     } else if (agent-&gt;is_absolute_path()) {
3796       library = os::dll_load(name, ebuf, sizeof ebuf);
3797       if (library == NULL) {
3798         const char *sub_msg = " in absolute path, with error: ";
3799         size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3800         char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3801         jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3802         // If we can't find the agent, exit.
3803         vm_exit_during_initialization(buf, NULL);
3804         FREE_C_HEAP_ARRAY(char, buf);
3805       }
3806     } else {
3807       // Try to load the agent from the standard dll directory
3808       if (os::dll_build_name(buffer, sizeof(buffer), Arguments::get_dll_dir(),
3809                              name)) {
3810         library = os::dll_load(buffer, ebuf, sizeof ebuf);
3811       }
3812       if (library == NULL) { // Try the local directory
3813         char ns[1] = {0};
3814         if (os::dll_build_name(buffer, sizeof(buffer), ns, name)) {
3815           library = os::dll_load(buffer, ebuf, sizeof ebuf);
3816         }
3817         if (library == NULL) {
3818           const char *sub_msg = " on the library path, with error: ";
3819           size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3820           char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3821           jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3822           // If we can't find the agent, exit.
3823           vm_exit_during_initialization(buf, NULL);
3824           FREE_C_HEAP_ARRAY(char, buf);
3825         }
3826       }
3827     }
3828     agent-&gt;set_os_lib(library);
3829     agent-&gt;set_valid();
3830   }
3831 
3832   // Find the OnLoad function.
3833   on_load_entry =
3834     CAST_TO_FN_PTR(OnLoadEntry_t, os::find_agent_function(agent,
3835                                                           false,
3836                                                           on_load_symbols,
3837                                                           num_symbol_entries));
3838   return on_load_entry;
3839 }
3840 
3841 // Find the JVM_OnLoad entry point
3842 static OnLoadEntry_t lookup_jvm_on_load(AgentLibrary* agent) {
3843   const char *on_load_symbols[] = JVM_ONLOAD_SYMBOLS;
3844   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3845 }
3846 
3847 // Find the Agent_OnLoad entry point
3848 static OnLoadEntry_t lookup_agent_on_load(AgentLibrary* agent) {
3849   const char *on_load_symbols[] = AGENT_ONLOAD_SYMBOLS;
3850   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3851 }
3852 
3853 // For backwards compatibility with -Xrun
3854 // Convert libraries with no JVM_OnLoad, but which have Agent_OnLoad to be
3855 // treated like -agentpath:
3856 // Must be called before agent libraries are created
3857 void Threads::convert_vm_init_libraries_to_agents() {
3858   AgentLibrary* agent;
3859   AgentLibrary* next;
3860 
3861   for (agent = Arguments::libraries(); agent != NULL; agent = next) {
3862     next = agent-&gt;next();  // cache the next agent now as this agent may get moved off this list
3863     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
3864 
3865     // If there is an JVM_OnLoad function it will get called later,
3866     // otherwise see if there is an Agent_OnLoad
3867     if (on_load_entry == NULL) {
3868       on_load_entry = lookup_agent_on_load(agent);
3869       if (on_load_entry != NULL) {
3870         // switch it to the agent list -- so that Agent_OnLoad will be called,
3871         // JVM_OnLoad won't be attempted and Agent_OnUnload will
3872         Arguments::convert_library_to_agent(agent);
3873       } else {
3874         vm_exit_during_initialization("Could not find JVM_OnLoad or Agent_OnLoad function in the library", agent-&gt;name());
3875       }
3876     }
3877   }
3878 }
3879 
3880 // Create agents for -agentlib:  -agentpath:  and converted -Xrun
3881 // Invokes Agent_OnLoad
3882 // Called very early -- before JavaThreads exist
3883 void Threads::create_vm_init_agents() {
3884   extern struct JavaVM_ main_vm;
3885   AgentLibrary* agent;
3886 
3887   JvmtiExport::enter_onload_phase();
3888 
3889   for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3890     OnLoadEntry_t  on_load_entry = lookup_agent_on_load(agent);
3891 
3892     if (on_load_entry != NULL) {
3893       // Invoke the Agent_OnLoad function
3894       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
3895       if (err != JNI_OK) {
3896         vm_exit_during_initialization("agent library failed to init", agent-&gt;name());
3897       }
3898     } else {
3899       vm_exit_during_initialization("Could not find Agent_OnLoad function in the agent library", agent-&gt;name());
3900     }
3901   }
3902   JvmtiExport::enter_primordial_phase();
3903 }
3904 
3905 extern "C" {
3906   typedef void (JNICALL *Agent_OnUnload_t)(JavaVM *);
3907 }
3908 
3909 void Threads::shutdown_vm_agents() {
3910   // Send any Agent_OnUnload notifications
3911   const char *on_unload_symbols[] = AGENT_ONUNLOAD_SYMBOLS;
3912   size_t num_symbol_entries = ARRAY_SIZE(on_unload_symbols);
3913   extern struct JavaVM_ main_vm;
3914   for (AgentLibrary* agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3915 
3916     // Find the Agent_OnUnload function.
3917     Agent_OnUnload_t unload_entry = CAST_TO_FN_PTR(Agent_OnUnload_t,
3918                                                    os::find_agent_function(agent,
3919                                                    false,
3920                                                    on_unload_symbols,
3921                                                    num_symbol_entries));
3922 
3923     // Invoke the Agent_OnUnload function
3924     if (unload_entry != NULL) {
3925       JavaThread* thread = JavaThread::current();
3926       ThreadToNativeFromVM ttn(thread);
3927       HandleMark hm(thread);
3928       (*unload_entry)(&amp;main_vm);
3929     }
3930   }
3931 }
3932 
3933 // Called for after the VM is initialized for -Xrun libraries which have not been converted to agent libraries
3934 // Invokes JVM_OnLoad
3935 void Threads::create_vm_init_libraries() {
3936   extern struct JavaVM_ main_vm;
3937   AgentLibrary* agent;
3938 
3939   for (agent = Arguments::libraries(); agent != NULL; agent = agent-&gt;next()) {
3940     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
3941 
3942     if (on_load_entry != NULL) {
3943       // Invoke the JVM_OnLoad function
3944       JavaThread* thread = JavaThread::current();
3945       ThreadToNativeFromVM ttn(thread);
3946       HandleMark hm(thread);
3947       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
3948       if (err != JNI_OK) {
3949         vm_exit_during_initialization("-Xrun library failed to init", agent-&gt;name());
3950       }
3951     } else {
3952       vm_exit_during_initialization("Could not find JVM_OnLoad function in -Xrun library", agent-&gt;name());
3953     }
3954   }
3955 }
3956 
3957 JavaThread* Threads::find_java_thread_from_java_tid(jlong java_tid) {
3958   assert(Threads_lock-&gt;owned_by_self(), "Must hold Threads_lock");
3959 
3960   JavaThread* java_thread = NULL;
3961   // Sequential search for now.  Need to do better optimization later.
3962   for (JavaThread* thread = Threads::first(); thread != NULL; thread = thread-&gt;next()) {
3963     oop tobj = thread-&gt;threadObj();
3964     if (!thread-&gt;is_exiting() &amp;&amp;
3965         tobj != NULL &amp;&amp;
3966         java_tid == java_lang_Thread::thread_id(tobj)) {
3967       java_thread = thread;
3968       break;
3969     }
3970   }
3971   return java_thread;
3972 }
3973 
3974 
3975 // Last thread running calls java.lang.Shutdown.shutdown()
3976 void JavaThread::invoke_shutdown_hooks() {
3977   HandleMark hm(this);
3978 
3979   // We could get here with a pending exception, if so clear it now.
3980   if (this-&gt;has_pending_exception()) {
3981     this-&gt;clear_pending_exception();
3982   }
3983 
3984   EXCEPTION_MARK;
3985   Klass* k =
3986     SystemDictionary::resolve_or_null(vmSymbols::java_lang_Shutdown(),
3987                                       THREAD);
3988   if (k != NULL) {
3989     // SystemDictionary::resolve_or_null will return null if there was
3990     // an exception.  If we cannot load the Shutdown class, just don't
3991     // call Shutdown.shutdown() at all.  This will mean the shutdown hooks
3992     // and finalizers (if runFinalizersOnExit is set) won't be run.
3993     // Note that if a shutdown hook was registered or runFinalizersOnExit
3994     // was called, the Shutdown class would have already been loaded
3995     // (Runtime.addShutdownHook and runFinalizersOnExit will load it).
3996     instanceKlassHandle shutdown_klass (THREAD, k);
3997     JavaValue result(T_VOID);
3998     JavaCalls::call_static(&amp;result,
3999                            shutdown_klass,
4000                            vmSymbols::shutdown_method_name(),
4001                            vmSymbols::void_method_signature(),
4002                            THREAD);
4003   }
4004   CLEAR_PENDING_EXCEPTION;
4005 }
4006 
4007 // Threads::destroy_vm() is normally called from jni_DestroyJavaVM() when
4008 // the program falls off the end of main(). Another VM exit path is through
4009 // vm_exit() when the program calls System.exit() to return a value or when
4010 // there is a serious error in VM. The two shutdown paths are not exactly
4011 // the same, but they share Shutdown.shutdown() at Java level and before_exit()
4012 // and VM_Exit op at VM level.
4013 //
4014 // Shutdown sequence:
4015 //   + Shutdown native memory tracking if it is on
4016 //   + Wait until we are the last non-daemon thread to execute
4017 //     &lt;-- every thing is still working at this moment --&gt;
4018 //   + Call java.lang.Shutdown.shutdown(), which will invoke Java level
4019 //        shutdown hooks, run finalizers if finalization-on-exit
4020 //   + Call before_exit(), prepare for VM exit
4021 //      &gt; run VM level shutdown hooks (they are registered through JVM_OnExit(),
4022 //        currently the only user of this mechanism is File.deleteOnExit())
4023 //      &gt; stop flat profiler, StatSampler, watcher thread, CMS threads,
4024 //        post thread end and vm death events to JVMTI,
4025 //        stop signal thread
4026 //   + Call JavaThread::exit(), it will:
4027 //      &gt; release JNI handle blocks, remove stack guard pages
4028 //      &gt; remove this thread from Threads list
4029 //     &lt;-- no more Java code from this thread after this point --&gt;
4030 //   + Stop VM thread, it will bring the remaining VM to a safepoint and stop
4031 //     the compiler threads at safepoint
4032 //     &lt;-- do not use anything that could get blocked by Safepoint --&gt;
4033 //   + Disable tracing at JNI/JVM barriers
4034 //   + Set _vm_exited flag for threads that are still running native code
4035 //   + Delete this thread
4036 //   + Call exit_globals()
4037 //      &gt; deletes tty
4038 //      &gt; deletes PerfMemory resources
4039 //   + Return to caller
4040 
4041 bool Threads::destroy_vm() {
4042   JavaThread* thread = JavaThread::current();
4043 
4044 #ifdef ASSERT
4045   _vm_complete = false;
4046 #endif
4047   // Wait until we are the last non-daemon thread to execute
4048   { MutexLocker nu(Threads_lock);
4049     while (Threads::number_of_non_daemon_threads() &gt; 1)
4050       // This wait should make safepoint checks, wait without a timeout,
4051       // and wait as a suspend-equivalent condition.
4052       //
4053       // Note: If the FlatProfiler is running and this thread is waiting
4054       // for another non-daemon thread to finish, then the FlatProfiler
4055       // is waiting for the external suspend request on this thread to
4056       // complete. wait_for_ext_suspend_completion() will eventually
4057       // timeout, but that takes time. Making this wait a suspend-
4058       // equivalent condition solves that timeout problem.
4059       //
4060       Threads_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
4061                          Mutex::_as_suspend_equivalent_flag);
4062   }
4063 
4064   // Hang forever on exit if we are reporting an error.
4065   if (ShowMessageBoxOnError &amp;&amp; is_error_reported()) {
4066     os::infinite_sleep();
4067   }
4068   os::wait_for_keypress_at_exit();
4069 
4070   // run Java level shutdown hooks
4071   thread-&gt;invoke_shutdown_hooks();
4072 
4073   before_exit(thread);
4074 
4075   thread-&gt;exit(true);
4076 
4077   // Stop VM thread.
4078   {
4079     // 4945125 The vm thread comes to a safepoint during exit.
4080     // GC vm_operations can get caught at the safepoint, and the
4081     // heap is unparseable if they are caught. Grab the Heap_lock
4082     // to prevent this. The GC vm_operations will not be able to
4083     // queue until after the vm thread is dead. After this point,
4084     // we'll never emerge out of the safepoint before the VM exits.
4085 
4086     MutexLocker ml(Heap_lock);
4087 
4088     VMThread::wait_for_vm_thread_exit();
4089     assert(SafepointSynchronize::is_at_safepoint(), "VM thread should exit at Safepoint");
4090     VMThread::destroy();
4091   }
4092 
4093   // clean up ideal graph printers
4094 #if defined(COMPILER2) &amp;&amp; !defined(PRODUCT)
4095   IdealGraphPrinter::clean_up();
4096 #endif
4097 
4098   // Now, all Java threads are gone except daemon threads. Daemon threads
4099   // running Java code or in VM are stopped by the Safepoint. However,
4100   // daemon threads executing native code are still running.  But they
4101   // will be stopped at native=&gt;Java/VM barriers. Note that we can't
4102   // simply kill or suspend them, as it is inherently deadlock-prone.
4103 
4104   VM_Exit::set_vm_exited();
4105 
4106   notify_vm_shutdown();
4107 
4108   delete thread;
4109 
4110 #if INCLUDE_JVMCI
4111   if (JVMCICounterSize &gt; 0) {
4112     FREE_C_HEAP_ARRAY(jlong, JavaThread::_jvmci_old_thread_counters);
4113   }
4114 #endif
4115 
4116   // exit_globals() will delete tty
4117   exit_globals();
4118 
4119   LogConfiguration::finalize();
4120 
4121   return true;
4122 }
4123 
4124 
4125 jboolean Threads::is_supported_jni_version_including_1_1(jint version) {
4126   if (version == JNI_VERSION_1_1) return JNI_TRUE;
4127   return is_supported_jni_version(version);
4128 }
4129 
4130 
4131 jboolean Threads::is_supported_jni_version(jint version) {
4132   if (version == JNI_VERSION_1_2) return JNI_TRUE;
4133   if (version == JNI_VERSION_1_4) return JNI_TRUE;
4134   if (version == JNI_VERSION_1_6) return JNI_TRUE;
4135   if (version == JNI_VERSION_1_8) return JNI_TRUE;
4136   if (version == JNI_VERSION_9) return JNI_TRUE;
4137   return JNI_FALSE;
4138 }
4139 
4140 
4141 void Threads::add(JavaThread* p, bool force_daemon) {
4142   // The threads lock must be owned at this point
4143   assert_locked_or_safepoint(Threads_lock);
4144 
4145   // See the comment for this method in thread.hpp for its purpose and
4146   // why it is called here.
4147   p-&gt;initialize_queues();
4148   p-&gt;set_next(_thread_list);
4149   _thread_list = p;
4150   _number_of_threads++;
4151   oop threadObj = p-&gt;threadObj();
4152   bool daemon = true;
4153   // Bootstrapping problem: threadObj can be null for initial
4154   // JavaThread (or for threads attached via JNI)
4155   if ((!force_daemon) &amp;&amp; (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj))) {
4156     _number_of_non_daemon_threads++;
4157     daemon = false;
4158   }
4159 
4160   ThreadService::add_thread(p, daemon);
4161 
4162   // Possible GC point.
4163   Events::log(p, "Thread added: " INTPTR_FORMAT, p2i(p));
4164 }
4165 
4166 void Threads::remove(JavaThread* p) {
4167   // Extra scope needed for Thread_lock, so we can check
4168   // that we do not remove thread without safepoint code notice
4169   { MutexLocker ml(Threads_lock);
4170 
4171     assert(includes(p), "p must be present");
4172 
4173     JavaThread* current = _thread_list;
4174     JavaThread* prev    = NULL;
4175 
4176     while (current != p) {
4177       prev    = current;
4178       current = current-&gt;next();
4179     }
4180 
4181     if (prev) {
4182       prev-&gt;set_next(current-&gt;next());
4183     } else {
4184       _thread_list = p-&gt;next();
4185     }
4186     _number_of_threads--;
4187     oop threadObj = p-&gt;threadObj();
4188     bool daemon = true;
4189     if (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj)) {
4190       _number_of_non_daemon_threads--;
4191       daemon = false;
4192 
4193       // Only one thread left, do a notify on the Threads_lock so a thread waiting
4194       // on destroy_vm will wake up.
4195       if (number_of_non_daemon_threads() == 1) {
4196         Threads_lock-&gt;notify_all();
4197       }
4198     }
4199     ThreadService::remove_thread(p, daemon);
4200 
4201     // Make sure that safepoint code disregard this thread. This is needed since
4202     // the thread might mess around with locks after this point. This can cause it
4203     // to do callbacks into the safepoint code. However, the safepoint code is not aware
4204     // of this thread since it is removed from the queue.
4205     p-&gt;set_terminated_value();
4206   } // unlock Threads_lock
4207 
4208   // Since Events::log uses a lock, we grab it outside the Threads_lock
4209   Events::log(p, "Thread exited: " INTPTR_FORMAT, p2i(p));
4210 }
4211 
4212 // Threads_lock must be held when this is called (or must be called during a safepoint)
4213 bool Threads::includes(JavaThread* p) {
4214   assert(Threads_lock-&gt;is_locked(), "sanity check");
4215   ALL_JAVA_THREADS(q) {
4216     if (q == p) {
4217       return true;
4218     }
4219   }
4220   return false;
4221 }
4222 
4223 // Operations on the Threads list for GC.  These are not explicitly locked,
4224 // but the garbage collector must provide a safe context for them to run.
4225 // In particular, these things should never be called when the Threads_lock
4226 // is held by some other thread. (Note: the Safepoint abstraction also
4227 // uses the Threads_lock to guarantee this property. It also makes sure that
4228 // all threads gets blocked when exiting or starting).
4229 
4230 void Threads::oops_do(OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
4231   ALL_JAVA_THREADS(p) {
4232     p-&gt;oops_do(f, cld_f, cf);
4233   }
4234   VMThread::vm_thread()-&gt;oops_do(f, cld_f, cf);
4235 }
4236 
4237 void Threads::change_thread_claim_parity() {
4238   // Set the new claim parity.
4239   assert(_thread_claim_parity &gt;= 0 &amp;&amp; _thread_claim_parity &lt;= 2,
4240          "Not in range.");
4241   _thread_claim_parity++;
4242   if (_thread_claim_parity == 3) _thread_claim_parity = 1;
4243   assert(_thread_claim_parity &gt;= 1 &amp;&amp; _thread_claim_parity &lt;= 2,
4244          "Not in range.");
4245 }
4246 
4247 #ifdef ASSERT
4248 void Threads::assert_all_threads_claimed() {
4249   ALL_JAVA_THREADS(p) {
4250     const int thread_parity = p-&gt;oops_do_parity();
4251     assert((thread_parity == _thread_claim_parity),
4252            "Thread " PTR_FORMAT " has incorrect parity %d != %d", p2i(p), thread_parity, _thread_claim_parity);
4253   }
4254 }
4255 #endif // ASSERT
4256 
4257 void Threads::possibly_parallel_oops_do(bool is_par, OopClosure* f, CLDClosure* cld_f, CodeBlobClosure* cf) {
4258   int cp = Threads::thread_claim_parity();
4259   ALL_JAVA_THREADS(p) {
4260     if (p-&gt;claim_oops_do(is_par, cp)) {
4261       p-&gt;oops_do(f, cld_f, cf);
4262     }
4263   }
4264   VMThread* vmt = VMThread::vm_thread();
4265   if (vmt-&gt;claim_oops_do(is_par, cp)) {
4266     vmt-&gt;oops_do(f, cld_f, cf);
4267   }
4268 }
4269 
4270 #if INCLUDE_ALL_GCS
4271 // Used by ParallelScavenge
4272 void Threads::create_thread_roots_tasks(GCTaskQueue* q) {
4273   ALL_JAVA_THREADS(p) {
4274     q-&gt;enqueue(new ThreadRootsTask(p));
4275   }
4276   q-&gt;enqueue(new ThreadRootsTask(VMThread::vm_thread()));
4277 }
4278 
4279 // Used by Parallel Old
4280 void Threads::create_thread_roots_marking_tasks(GCTaskQueue* q) {
4281   ALL_JAVA_THREADS(p) {
4282     q-&gt;enqueue(new ThreadRootsMarkingTask(p));
4283   }
4284   q-&gt;enqueue(new ThreadRootsMarkingTask(VMThread::vm_thread()));
4285 }
4286 #endif // INCLUDE_ALL_GCS
4287 
4288 void Threads::nmethods_do(CodeBlobClosure* cf) {
4289   ALL_JAVA_THREADS(p) {
4290     p-&gt;nmethods_do(cf);
4291   }
4292   VMThread::vm_thread()-&gt;nmethods_do(cf);
4293 }
4294 
4295 void Threads::metadata_do(void f(Metadata*)) {
4296   ALL_JAVA_THREADS(p) {
4297     p-&gt;metadata_do(f);
4298   }
4299 }
4300 
4301 class ThreadHandlesClosure : public ThreadClosure {
4302   void (*_f)(Metadata*);
4303  public:
4304   ThreadHandlesClosure(void f(Metadata*)) : _f(f) {}
4305   virtual void do_thread(Thread* thread) {
4306     thread-&gt;metadata_handles_do(_f);
4307   }
4308 };
4309 
4310 void Threads::metadata_handles_do(void f(Metadata*)) {
4311   // Only walk the Handles in Thread.
4312   ThreadHandlesClosure handles_closure(f);
4313   threads_do(&amp;handles_closure);
4314 }
4315 
4316 void Threads::deoptimized_wrt_marked_nmethods() {
4317   ALL_JAVA_THREADS(p) {
4318     p-&gt;deoptimized_wrt_marked_nmethods();
4319   }
4320 }
4321 
4322 
4323 // Get count Java threads that are waiting to enter the specified monitor.
4324 GrowableArray&lt;JavaThread*&gt;* Threads::get_pending_threads(int count,
4325                                                          address monitor,
4326                                                          bool doLock) {
4327   assert(doLock || SafepointSynchronize::is_at_safepoint(),
4328          "must grab Threads_lock or be at safepoint");
4329   GrowableArray&lt;JavaThread*&gt;* result = new GrowableArray&lt;JavaThread*&gt;(count);
4330 
4331   int i = 0;
4332   {
4333     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4334     ALL_JAVA_THREADS(p) {
4335       if (!p-&gt;can_call_java()) continue;
4336 
4337       address pending = (address)p-&gt;current_pending_monitor();
4338       if (pending == monitor) {             // found a match
4339         if (i &lt; count) result-&gt;append(p);   // save the first count matches
4340         i++;
4341       }
4342     }
4343   }
4344   return result;
4345 }
4346 
4347 
4348 JavaThread *Threads::owning_thread_from_monitor_owner(address owner,
4349                                                       bool doLock) {
4350   assert(doLock ||
4351          Threads_lock-&gt;owned_by_self() ||
4352          SafepointSynchronize::is_at_safepoint(),
4353          "must grab Threads_lock or be at safepoint");
4354 
4355   // NULL owner means not locked so we can skip the search
4356   if (owner == NULL) return NULL;
4357 
4358   {
4359     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4360     ALL_JAVA_THREADS(p) {
4361       // first, see if owner is the address of a Java thread
4362       if (owner == (address)p) return p;
4363     }
4364   }
4365   // Cannot assert on lack of success here since this function may be
4366   // used by code that is trying to report useful problem information
4367   // like deadlock detection.
4368   if (UseHeavyMonitors) return NULL;
4369 
4370   // If we didn't find a matching Java thread and we didn't force use of
4371   // heavyweight monitors, then the owner is the stack address of the
4372   // Lock Word in the owning Java thread's stack.
4373   //
4374   JavaThread* the_owner = NULL;
4375   {
4376     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4377     ALL_JAVA_THREADS(q) {
4378       if (q-&gt;is_lock_owned(owner)) {
4379         the_owner = q;
4380         break;
4381       }
4382     }
4383   }
4384   // cannot assert on lack of success here; see above comment
4385   return the_owner;
4386 }
4387 
4388 // Threads::print_on() is called at safepoint by VM_PrintThreads operation.
4389 void Threads::print_on(outputStream* st, bool print_stacks,
4390                        bool internal_format, bool print_concurrent_locks) {
4391   char buf[32];
4392   st-&gt;print_raw_cr(os::local_time_string(buf, sizeof(buf)));
4393 
4394   st-&gt;print_cr("Full thread dump %s (%s %s):",
4395                Abstract_VM_Version::vm_name(),
4396                Abstract_VM_Version::vm_release(),
4397                Abstract_VM_Version::vm_info_string());
4398   st-&gt;cr();
4399 
4400 #if INCLUDE_SERVICES
4401   // Dump concurrent locks
4402   ConcurrentLocksDump concurrent_locks;
4403   if (print_concurrent_locks) {
4404     concurrent_locks.dump_at_safepoint();
4405   }
4406 #endif // INCLUDE_SERVICES
4407 
4408   ALL_JAVA_THREADS(p) {
4409     ResourceMark rm;
4410     p-&gt;print_on(st);
4411     if (print_stacks) {
4412       if (internal_format) {
4413         p-&gt;trace_stack();
4414       } else {
4415         p-&gt;print_stack_on(st);
4416       }
4417     }
4418     st-&gt;cr();
4419 #if INCLUDE_SERVICES
4420     if (print_concurrent_locks) {
4421       concurrent_locks.print_locks_on(p, st);
4422     }
4423 #endif // INCLUDE_SERVICES
4424   }
4425 
4426   VMThread::vm_thread()-&gt;print_on(st);
4427   st-&gt;cr();
4428   Universe::heap()-&gt;print_gc_threads_on(st);
4429   WatcherThread* wt = WatcherThread::watcher_thread();
4430   if (wt != NULL) {
4431     wt-&gt;print_on(st);
4432     st-&gt;cr();
4433   }
4434   st-&gt;flush();
4435 }
4436 
4437 // Threads::print_on_error() is called by fatal error handler. It's possible
4438 // that VM is not at safepoint and/or current thread is inside signal handler.
4439 // Don't print stack trace, as the stack may not be walkable. Don't allocate
4440 // memory (even in resource area), it might deadlock the error handler.
4441 void Threads::print_on_error(outputStream* st, Thread* current, char* buf,
4442                              int buflen) {
4443   bool found_current = false;
4444   st-&gt;print_cr("Java Threads: ( =&gt; current thread )");
4445   ALL_JAVA_THREADS(thread) {
4446     bool is_current = (current == thread);
4447     found_current = found_current || is_current;
4448 
4449     st-&gt;print("%s", is_current ? "=&gt;" : "  ");
4450 
4451     st-&gt;print(PTR_FORMAT, p2i(thread));
4452     st-&gt;print(" ");
4453     thread-&gt;print_on_error(st, buf, buflen);
4454     st-&gt;cr();
4455   }
4456   st-&gt;cr();
4457 
4458   st-&gt;print_cr("Other Threads:");
4459   if (VMThread::vm_thread()) {
4460     bool is_current = (current == VMThread::vm_thread());
4461     found_current = found_current || is_current;
4462     st-&gt;print("%s", current == VMThread::vm_thread() ? "=&gt;" : "  ");
4463 
4464     st-&gt;print(PTR_FORMAT, p2i(VMThread::vm_thread()));
4465     st-&gt;print(" ");
4466     VMThread::vm_thread()-&gt;print_on_error(st, buf, buflen);
4467     st-&gt;cr();
4468   }
4469   WatcherThread* wt = WatcherThread::watcher_thread();
4470   if (wt != NULL) {
4471     bool is_current = (current == wt);
4472     found_current = found_current || is_current;
4473     st-&gt;print("%s", is_current ? "=&gt;" : "  ");
4474 
4475     st-&gt;print(PTR_FORMAT, p2i(wt));
4476     st-&gt;print(" ");
4477     wt-&gt;print_on_error(st, buf, buflen);
4478     st-&gt;cr();
4479   }
4480   if (!found_current) {
4481     st-&gt;cr();
4482     st-&gt;print("=&gt;" PTR_FORMAT " (exited) ", p2i(current));
4483     current-&gt;print_on_error(st, buf, buflen);
4484     st-&gt;cr();
4485   }
4486   st-&gt;cr();
4487   st-&gt;print_cr("Threads with active compile tasks:");
4488   print_threads_compiling(st, buf, buflen);
4489 }
4490 
4491 void Threads::print_threads_compiling(outputStream* st, char* buf, int buflen) {
4492   ALL_JAVA_THREADS(thread) {
4493     if (thread-&gt;is_Compiler_thread()) {
4494       CompilerThread* ct = (CompilerThread*) thread;
4495       if (ct-&gt;task() != NULL) {
4496         thread-&gt;print_name_on_error(st, buf, buflen);
4497         ct-&gt;task()-&gt;print(st, NULL, true, true);
4498       }
4499     }
4500   }
4501 }
4502 
4503 
4504 // Internal SpinLock and Mutex
4505 // Based on ParkEvent
4506 
4507 // Ad-hoc mutual exclusion primitives: SpinLock and Mux
4508 //
4509 // We employ SpinLocks _only for low-contention, fixed-length
4510 // short-duration critical sections where we're concerned
4511 // about native mutex_t or HotSpot Mutex:: latency.
4512 // The mux construct provides a spin-then-block mutual exclusion
4513 // mechanism.
4514 //
4515 // Testing has shown that contention on the ListLock guarding gFreeList
4516 // is common.  If we implement ListLock as a simple SpinLock it's common
4517 // for the JVM to devolve to yielding with little progress.  This is true
4518 // despite the fact that the critical sections protected by ListLock are
4519 // extremely short.
4520 //
4521 // TODO-FIXME: ListLock should be of type SpinLock.
4522 // We should make this a 1st-class type, integrated into the lock
4523 // hierarchy as leaf-locks.  Critically, the SpinLock structure
4524 // should have sufficient padding to avoid false-sharing and excessive
4525 // cache-coherency traffic.
4526 
4527 
4528 typedef volatile int SpinLockT;
4529 
4530 void Thread::SpinAcquire(volatile int * adr, const char * LockName) {
4531   if (Atomic::cmpxchg (1, adr, 0) == 0) {
4532     return;   // normal fast-path return
4533   }
4534 
4535   // Slow-path : We've encountered contention -- Spin/Yield/Block strategy.
4536   TEVENT(SpinAcquire - ctx);
4537   int ctr = 0;
4538   int Yields = 0;
4539   for (;;) {
4540     while (*adr != 0) {
4541       ++ctr;
4542       if ((ctr &amp; 0xFFF) == 0 || !os::is_MP()) {
4543         if (Yields &gt; 5) {
4544           os::naked_short_sleep(1);
4545         } else {
4546           os::naked_yield();
4547           ++Yields;
4548         }
4549       } else {
4550         SpinPause();
4551       }
4552     }
4553     if (Atomic::cmpxchg(1, adr, 0) == 0) return;
4554   }
4555 }
4556 
4557 void Thread::SpinRelease(volatile int * adr) {
4558   assert(*adr != 0, "invariant");
4559   OrderAccess::fence();      // guarantee at least release consistency.
4560   // Roach-motel semantics.
4561   // It's safe if subsequent LDs and STs float "up" into the critical section,
4562   // but prior LDs and STs within the critical section can't be allowed
4563   // to reorder or float past the ST that releases the lock.
4564   // Loads and stores in the critical section - which appear in program
4565   // order before the store that releases the lock - must also appear
4566   // before the store that releases the lock in memory visibility order.
4567   // Conceptually we need a #loadstore|#storestore "release" MEMBAR before
4568   // the ST of 0 into the lock-word which releases the lock, so fence
4569   // more than covers this on all platforms.
4570   *adr = 0;
4571 }
4572 
4573 // muxAcquire and muxRelease:
4574 //
4575 // *  muxAcquire and muxRelease support a single-word lock-word construct.
4576 //    The LSB of the word is set IFF the lock is held.
4577 //    The remainder of the word points to the head of a singly-linked list
4578 //    of threads blocked on the lock.
4579 //
4580 // *  The current implementation of muxAcquire-muxRelease uses its own
4581 //    dedicated Thread._MuxEvent instance.  If we're interested in
4582 //    minimizing the peak number of extant ParkEvent instances then
4583 //    we could eliminate _MuxEvent and "borrow" _ParkEvent as long
4584 //    as certain invariants were satisfied.  Specifically, care would need
4585 //    to be taken with regards to consuming unpark() "permits".
4586 //    A safe rule of thumb is that a thread would never call muxAcquire()
4587 //    if it's enqueued (cxq, EntryList, WaitList, etc) and will subsequently
4588 //    park().  Otherwise the _ParkEvent park() operation in muxAcquire() could
4589 //    consume an unpark() permit intended for monitorenter, for instance.
4590 //    One way around this would be to widen the restricted-range semaphore
4591 //    implemented in park().  Another alternative would be to provide
4592 //    multiple instances of the PlatformEvent() for each thread.  One
4593 //    instance would be dedicated to muxAcquire-muxRelease, for instance.
4594 //
4595 // *  Usage:
4596 //    -- Only as leaf locks
4597 //    -- for short-term locking only as muxAcquire does not perform
4598 //       thread state transitions.
4599 //
4600 // Alternatives:
4601 // *  We could implement muxAcquire and muxRelease with MCS or CLH locks
4602 //    but with parking or spin-then-park instead of pure spinning.
4603 // *  Use Taura-Oyama-Yonenzawa locks.
4604 // *  It's possible to construct a 1-0 lock if we encode the lockword as
4605 //    (List,LockByte).  Acquire will CAS the full lockword while Release
4606 //    will STB 0 into the LockByte.  The 1-0 scheme admits stranding, so
4607 //    acquiring threads use timers (ParkTimed) to detect and recover from
4608 //    the stranding window.  Thread/Node structures must be aligned on 256-byte
4609 //    boundaries by using placement-new.
4610 // *  Augment MCS with advisory back-link fields maintained with CAS().
4611 //    Pictorially:  LockWord -&gt; T1 &lt;-&gt; T2 &lt;-&gt; T3 &lt;-&gt; ... &lt;-&gt; Tn &lt;-&gt; Owner.
4612 //    The validity of the backlinks must be ratified before we trust the value.
4613 //    If the backlinks are invalid the exiting thread must back-track through the
4614 //    the forward links, which are always trustworthy.
4615 // *  Add a successor indication.  The LockWord is currently encoded as
4616 //    (List, LOCKBIT:1).  We could also add a SUCCBIT or an explicit _succ variable
4617 //    to provide the usual futile-wakeup optimization.
4618 //    See RTStt for details.
4619 // *  Consider schedctl.sc_nopreempt to cover the critical section.
4620 //
4621 
4622 
4623 typedef volatile intptr_t MutexT;      // Mux Lock-word
4624 enum MuxBits { LOCKBIT = 1 };
4625 
4626 void Thread::muxAcquire(volatile intptr_t * Lock, const char * LockName) {
4627   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4628   if (w == 0) return;
4629   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4630     return;
4631   }
4632 
4633   TEVENT(muxAcquire - Contention);
4634   ParkEvent * const Self = Thread::current()-&gt;_MuxEvent;
4635   assert((intptr_t(Self) &amp; LOCKBIT) == 0, "invariant");
4636   for (;;) {
4637     int its = (os::is_MP() ? 100 : 0) + 1;
4638 
4639     // Optional spin phase: spin-then-park strategy
4640     while (--its &gt;= 0) {
4641       w = *Lock;
4642       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4643         return;
4644       }
4645     }
4646 
4647     Self-&gt;reset();
4648     Self-&gt;OnList = intptr_t(Lock);
4649     // The following fence() isn't _strictly necessary as the subsequent
4650     // CAS() both serializes execution and ratifies the fetched *Lock value.
4651     OrderAccess::fence();
4652     for (;;) {
4653       w = *Lock;
4654       if ((w &amp; LOCKBIT) == 0) {
4655         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4656           Self-&gt;OnList = 0;   // hygiene - allows stronger asserts
4657           return;
4658         }
4659         continue;      // Interference -- *Lock changed -- Just retry
4660       }
4661       assert(w &amp; LOCKBIT, "invariant");
4662       Self-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4663       if (Atomic::cmpxchg_ptr(intptr_t(Self)|LOCKBIT, Lock, w) == w) break;
4664     }
4665 
4666     while (Self-&gt;OnList != 0) {
4667       Self-&gt;park();
4668     }
4669   }
4670 }
4671 
4672 void Thread::muxAcquireW(volatile intptr_t * Lock, ParkEvent * ev) {
4673   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4674   if (w == 0) return;
4675   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4676     return;
4677   }
4678 
4679   TEVENT(muxAcquire - Contention);
4680   ParkEvent * ReleaseAfter = NULL;
4681   if (ev == NULL) {
4682     ev = ReleaseAfter = ParkEvent::Allocate(NULL);
4683   }
4684   assert((intptr_t(ev) &amp; LOCKBIT) == 0, "invariant");
4685   for (;;) {
4686     guarantee(ev-&gt;OnList == 0, "invariant");
4687     int its = (os::is_MP() ? 100 : 0) + 1;
4688 
4689     // Optional spin phase: spin-then-park strategy
4690     while (--its &gt;= 0) {
4691       w = *Lock;
4692       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4693         if (ReleaseAfter != NULL) {
4694           ParkEvent::Release(ReleaseAfter);
4695         }
4696         return;
4697       }
4698     }
4699 
4700     ev-&gt;reset();
4701     ev-&gt;OnList = intptr_t(Lock);
4702     // The following fence() isn't _strictly necessary as the subsequent
4703     // CAS() both serializes execution and ratifies the fetched *Lock value.
4704     OrderAccess::fence();
4705     for (;;) {
4706       w = *Lock;
4707       if ((w &amp; LOCKBIT) == 0) {
4708         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4709           ev-&gt;OnList = 0;
4710           // We call ::Release while holding the outer lock, thus
4711           // artificially lengthening the critical section.
4712           // Consider deferring the ::Release() until the subsequent unlock(),
4713           // after we've dropped the outer lock.
4714           if (ReleaseAfter != NULL) {
4715             ParkEvent::Release(ReleaseAfter);
4716           }
4717           return;
4718         }
4719         continue;      // Interference -- *Lock changed -- Just retry
4720       }
4721       assert(w &amp; LOCKBIT, "invariant");
4722       ev-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4723       if (Atomic::cmpxchg_ptr(intptr_t(ev)|LOCKBIT, Lock, w) == w) break;
4724     }
4725 
4726     while (ev-&gt;OnList != 0) {
4727       ev-&gt;park();
4728     }
4729   }
4730 }
4731 
4732 // Release() must extract a successor from the list and then wake that thread.
4733 // It can "pop" the front of the list or use a detach-modify-reattach (DMR) scheme
4734 // similar to that used by ParkEvent::Allocate() and ::Release().  DMR-based
4735 // Release() would :
4736 // (A) CAS() or swap() null to *Lock, releasing the lock and detaching the list.
4737 // (B) Extract a successor from the private list "in-hand"
4738 // (C) attempt to CAS() the residual back into *Lock over null.
4739 //     If there were any newly arrived threads and the CAS() would fail.
4740 //     In that case Release() would detach the RATs, re-merge the list in-hand
4741 //     with the RATs and repeat as needed.  Alternately, Release() might
4742 //     detach and extract a successor, but then pass the residual list to the wakee.
4743 //     The wakee would be responsible for reattaching and remerging before it
4744 //     competed for the lock.
4745 //
4746 // Both "pop" and DMR are immune from ABA corruption -- there can be
4747 // multiple concurrent pushers, but only one popper or detacher.
4748 // This implementation pops from the head of the list.  This is unfair,
4749 // but tends to provide excellent throughput as hot threads remain hot.
4750 // (We wake recently run threads first).
4751 //
4752 // All paths through muxRelease() will execute a CAS.
4753 // Release consistency -- We depend on the CAS in muxRelease() to provide full
4754 // bidirectional fence/MEMBAR semantics, ensuring that all prior memory operations
4755 // executed within the critical section are complete and globally visible before the
4756 // store (CAS) to the lock-word that releases the lock becomes globally visible.
4757 void Thread::muxRelease(volatile intptr_t * Lock)  {
4758   for (;;) {
4759     const intptr_t w = Atomic::cmpxchg_ptr(0, Lock, LOCKBIT);
4760     assert(w &amp; LOCKBIT, "invariant");
4761     if (w == LOCKBIT) return;
4762     ParkEvent * const List = (ParkEvent *) (w &amp; ~LOCKBIT);
4763     assert(List != NULL, "invariant");
4764     assert(List-&gt;OnList == intptr_t(Lock), "invariant");
4765     ParkEvent * const nxt = List-&gt;ListNext;
4766     guarantee((intptr_t(nxt) &amp; LOCKBIT) == 0, "invariant");
4767 
4768     // The following CAS() releases the lock and pops the head element.
4769     // The CAS() also ratifies the previously fetched lock-word value.
4770     if (Atomic::cmpxchg_ptr (intptr_t(nxt), Lock, w) != w) {
4771       continue;
4772     }
4773     List-&gt;OnList = 0;
4774     OrderAccess::fence();
4775     List-&gt;unpark();
4776     return;
4777   }
4778 }
4779 
4780 
4781 void Threads::verify() {
4782   ALL_JAVA_THREADS(p) {
4783     p-&gt;verify();
4784   }
4785   VMThread* thread = VMThread::vm_thread();
4786   if (thread != NULL) thread-&gt;verify();
4787 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="3" type="hidden" /></form></body></html>
