<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/share/vm/opto/bytecodeInfo.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 1998, 2013, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 #include "ci/ciReplay.hpp"
  27 #include "ci/ciCacheReplay.hpp"
  28 #include "ci/ciCacheProfiles.hpp"
  29 #include "classfile/systemDictionary.hpp"
  30 #include "classfile/vmSymbols.hpp"
  31 #include "compiler/compileBroker.hpp"
  32 #include "compiler/compileLog.hpp"
  33 #include "interpreter/linkResolver.hpp"
  34 #include "oops/objArrayKlass.hpp"
  35 #include "opto/callGenerator.hpp"
  36 #include "opto/parse.hpp"
  37 #include "runtime/handles.inline.hpp"
  38 #include "utilities/events.hpp"
  39 
  40 //=============================================================================
  41 //------------------------------InlineTree-------------------------------------
  42 InlineTree::InlineTree(Compile* c,
  43                        const InlineTree *caller_tree, ciMethod* callee,
  44                        JVMState* caller_jvms, int caller_bci,
  45                        float site_invoke_ratio, int max_inline_level) :
  46   C(c),
  47   _caller_jvms(caller_jvms),
  48   _caller_tree((InlineTree*) caller_tree),
  49   _method(callee),
  50   _site_invoke_ratio(site_invoke_ratio),
  51   _max_inline_level(max_inline_level),
  52   _count_inline_bcs(method()-&gt;code_size_for_inlining()),
  53   _subtrees(c-&gt;comp_arena(), 2, 0, NULL),
  54   _msg(NULL)
  55 {
  56 #ifndef PRODUCT
  57   _count_inlines = 0;
  58   _forced_inline = false;
  59 #endif
  60   if (_caller_jvms != NULL) {
  61     // Keep a private copy of the caller_jvms:
  62     _caller_jvms = new (C) JVMState(caller_jvms-&gt;method(), caller_tree-&gt;caller_jvms());
  63     _caller_jvms-&gt;set_bci(caller_jvms-&gt;bci());
  64     assert(!caller_jvms-&gt;should_reexecute(), "there should be no reexecute bytecode with inlining");
  65   }
  66   assert(_caller_jvms-&gt;same_calls_as(caller_jvms), "consistent JVMS");
  67   assert((caller_tree == NULL ? 0 : caller_tree-&gt;stack_depth() + 1) == stack_depth(), "correct (redundant) depth parameter");
  68   assert(caller_bci == this-&gt;caller_bci(), "correct (redundant) bci parameter");
  69   // Update hierarchical counts, count_inline_bcs() and count_inlines()
  70   InlineTree *caller = (InlineTree *)caller_tree;
  71   for( ; caller != NULL; caller = ((InlineTree *)(caller-&gt;caller_tree())) ) {
  72     caller-&gt;_count_inline_bcs += count_inline_bcs();
  73     NOT_PRODUCT(caller-&gt;_count_inlines++;)
  74   }
  75 }
  76 
  77 /**
  78  *  Return true when EA is ON and a java constructor is called or
  79  *  a super constructor is called from an inlined java constructor.
  80  *  Also return true for boxing methods.
  81  */
  82 static bool is_init_with_ea(ciMethod* callee_method,
  83                             ciMethod* caller_method, Compile* C) {
  84   if (!C-&gt;do_escape_analysis() || !EliminateAllocations) {
  85     return false; // EA is off
  86   }
  87   if (callee_method-&gt;is_initializer()) {
  88     return true; // constuctor
  89   }
  90   if (caller_method-&gt;is_initializer() &amp;&amp;
  91       caller_method != C-&gt;method() &amp;&amp;
  92       caller_method-&gt;holder()-&gt;is_subclass_of(callee_method-&gt;holder())) {
  93     return true; // super constructor is called from inlined constructor
  94   }
  95   if (C-&gt;eliminate_boxing() &amp;&amp; callee_method-&gt;is_boxing_method()) {
  96     return true;
  97   }
  98   return false;
  99 }
 100 
 101 /**
 102  *  Force inlining unboxing accessor.
 103  */
 104 static bool is_unboxing_method(ciMethod* callee_method, Compile* C) {
 105   return C-&gt;eliminate_boxing() &amp;&amp; callee_method-&gt;is_unboxing_method();
 106 }
 107 
 108 // positive filter: should callee be inlined?
 109 bool InlineTree::should_inline(ciMethod* callee_method, ciMethod* caller_method,
 110                                int caller_bci, ciCallProfile&amp; profile,
 111                                WarmCallInfo* wci_result) {
 112   // Allows targeted inlining
 113   if (C-&gt;directive()-&gt;should_inline(callee_method)) {
 114     *wci_result = *(WarmCallInfo::always_hot());
 115     if (C-&gt;print_inlining() &amp;&amp; Verbose) {
 116       CompileTask::print_inline_indent(inline_level());
 117       tty-&gt;print_cr("Inlined method is hot: ");
 118     }
 119     set_msg("force inline by CompileCommand");
 120     _forced_inline = true;
 121     return true;
 122   }
 123 
 124   if (callee_method-&gt;force_inline()) {
 125       set_msg("force inline by annotation");
 126       _forced_inline = true;
 127       return true;
 128   }
 129   int inline_depth = inline_level()+1;
 130   if (ciCacheReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 131     set_msg("force inline by ciCacheReplay");
 132     _forced_inline = true;
 133     return true;
 134   }
 135 #ifndef PRODUCT
 136   if (ciReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 137     set_msg("force inline by ciReplay");
 138     _forced_inline = true;
 139     return true;
 140   }
 141 #endif
 142 
 143   int size = callee_method-&gt;code_size_for_inlining();
 144 
 145   // Check for too many throws (and not too huge)
 146   if(callee_method-&gt;interpreter_throwout_count() &gt; InlineThrowCount &amp;&amp;
 147      size &lt; InlineThrowMaxSize ) {
 148     wci_result-&gt;set_profit(wci_result-&gt;profit() * 100);
 149     if (C-&gt;print_inlining() &amp;&amp; Verbose) {
 150       CompileTask::print_inline_indent(inline_level());
 151       tty-&gt;print_cr("Inlined method with many throws (throws=%d):", callee_method-&gt;interpreter_throwout_count());
 152     }
 153     set_msg("many throws");
 154     return true;
 155   }
 156 
 157   int default_max_inline_size = C-&gt;max_inline_size();
 158   int inline_small_code_size  = InlineSmallCode / 4;
 159   int max_inline_size         = default_max_inline_size;
 160 
 161   int call_site_count  = method()-&gt;scale_count(profile.count());
 162   int invoke_count     = method()-&gt;interpreter_invocation_count();
 163 
 164   assert(invoke_count != 0, "require invocation count greater than zero");
 165   int freq = call_site_count / invoke_count;
 166 
 167   // bump the max size if the call is frequent
 168   if ((freq &gt;= InlineFrequencyRatio) ||
 169       (call_site_count &gt;= InlineFrequencyCount) ||
 170       is_unboxing_method(callee_method, C) ||
 171       is_init_with_ea(callee_method, caller_method, C)) {
 172 
 173     max_inline_size = C-&gt;freq_inline_size();
 174     if (size &lt;= max_inline_size &amp;&amp; TraceFrequencyInlining) {
 175       CompileTask::print_inline_indent(inline_level());
 176       tty-&gt;print_cr("Inlined frequent method (freq=%d count=%d):", freq, call_site_count);
 177       CompileTask::print_inline_indent(inline_level());
 178       callee_method-&gt;print();
 179       tty-&gt;cr();
 180     }
 181   } else {
 182     // Not hot.  Check for medium-sized pre-existing nmethod at cold sites.
 183     if (callee_method-&gt;has_compiled_code() &amp;&amp;
 184         callee_method-&gt;instructions_size() &gt; inline_small_code_size) {
 185           // we force inlining when the caller is cached (to make sure that we replay correctly)
 186           if (ciCacheProfiles::is_cached(caller_method-&gt;get_Method())) {
 187                 set_msg("force inline by ciCacheProfiles (over compiled into medium method)");
 188                 _forced_inline = true;
 189                 return true;
 190           }
 191       set_msg("already compiled into a medium method");
 192       return false;
 193     }
 194   }
 195   if (size &gt; max_inline_size) {
 196     if (max_inline_size &gt; default_max_inline_size) {
 197       set_msg("hot method too big");
 198     } else {
 199       set_msg("too big");
 200     }
 201     return false;
 202   }
 203   return true;
 204 }
 205 
 206 
 207 // negative filter: should callee NOT be inlined?
 208 bool InlineTree::should_not_inline(ciMethod *callee_method,
 209                                    ciMethod* caller_method,
 210                                    JVMState* jvms,
 211                                    WarmCallInfo* wci_result) {
 212 
 213   const char* fail_msg = NULL;
 214 
 215   // First check all inlining restrictions which are required for correctness
 216   if ( callee_method-&gt;is_abstract()) {
 217     fail_msg = "abstract method"; // // note: we allow ik-&gt;is_abstract()
 218   } else if (!callee_method-&gt;holder()-&gt;is_initialized()) {
 219     fail_msg = "method holder not initialized";
 220   } else if ( callee_method-&gt;is_native()) {
 221     fail_msg = "native method";
 222   } else if ( callee_method-&gt;dont_inline()) {
 223     fail_msg = "don't inline by annotation";
 224   }
 225 
 226   // one more inlining restriction
 227   if (fail_msg == NULL &amp;&amp; callee_method-&gt;has_unloaded_classes_in_signature()) {
 228     fail_msg = "unloaded signature classes";
 229   }
 230 
 231   if (fail_msg != NULL) {
 232     set_msg(fail_msg);
 233     return true;
 234   }
 235 
 236   // ignore heuristic controls on inlining
 237   if (C-&gt;directive()-&gt;should_inline(callee_method)) {
 238     set_msg("force inline by CompileCommand");
 239     return false;
 240   }
 241 
 242   if (C-&gt;directive()-&gt;should_not_inline(callee_method)) {
 243     set_msg("disallowed by CompileCommand");
 244     return true;
 245   }
 246   int caller_bci = jvms-&gt;bci();
 247   int inline_depth = inline_level()+1;
 248   if (ciCacheReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 249     set_msg("force inline by ciCacheReplay");
 250     return false;
 251   }
 252 
 253   if (ciCacheReplay::should_not_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 254     set_msg("disallowed by ciCacheReplay");
 255     return true;
 256   }
 257 
 258   if (ciCacheReplay::should_not_inline(callee_method)) {
 259     set_msg("disallowed by ciCacheReplay");
 260     return true;
 261   }
 262 #ifndef PRODUCT
 263   if (ciReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 264     set_msg("force inline by ciReplay");
 265     return false;
 266   }
 267 
 268   if (ciReplay::should_not_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 269     set_msg("disallowed by ciReplay");
 270     return true;
 271   }
 272 
 273   if (ciReplay::should_not_inline(callee_method)) {
 274     set_msg("disallowed by ciReplay");
 275     return true;
 276   }
 277 #endif
 278 
 279   if (callee_method-&gt;force_inline()) {
 280     set_msg("force inline by annotation");
 281     return false;
 282   }
 283 
 284   // Now perform checks which are heuristic
 285 
 286   if (is_unboxing_method(callee_method, C)) {
 287     // Inline unboxing methods.
 288     return false;
 289   }
 290 
 291   if (callee_method-&gt;has_compiled_code() &amp;&amp;
 292       callee_method-&gt;instructions_size() &gt; InlineSmallCode) {
 293     set_msg("already compiled into a big method");
 294     return true;
 295   }
 296 
 297   // don't inline exception code unless the top method belongs to an
 298   // exception class
 299   if (caller_tree() != NULL &amp;&amp;
 300       callee_method-&gt;holder()-&gt;is_subclass_of(C-&gt;env()-&gt;Throwable_klass())) {
 301     const InlineTree *top = this;
 302     while (top-&gt;caller_tree() != NULL) top = top-&gt;caller_tree();
 303     ciInstanceKlass* k = top-&gt;method()-&gt;holder();
 304     if (!k-&gt;is_subclass_of(C-&gt;env()-&gt;Throwable_klass())) {
 305       set_msg("exception method");
 306       return true;
 307     }
 308   }
 309 
 310   // use frequency-based objections only for non-trivial methods
 311   if (callee_method-&gt;code_size() &lt;= MaxTrivialSize) {
 312     return false;
 313   }
 314 
 315   // don't use counts with -Xcomp or CTW
 316   if (UseInterpreter &amp;&amp; !CompileTheWorld) {
 317 
 318     if (!callee_method-&gt;has_compiled_code() &amp;&amp;
 319         !callee_method-&gt;was_executed_more_than(0)) {
 320       set_msg("never executed");
 321       return true;
 322     }
 323 
 324     if (is_init_with_ea(callee_method, caller_method, C)) {
 325       // Escape Analysis: inline all executed constructors
 326       return false;
 327     } else {
 328       intx counter_high_value;
 329       // Tiered compilation uses a different "high value" than non-tiered compilation.
 330       // Determine the right value to use.
 331       if (TieredCompilation) {
 332         counter_high_value = InvocationCounter::count_limit / 2;
 333       } else {
 334         counter_high_value = CompileThreshold / 2;
 335       }
 336       if (!callee_method-&gt;was_executed_more_than(MIN2(MinInliningThreshold, counter_high_value))) {
 337         set_msg("executed &lt; MinInliningThreshold times");
 338         return true;
 339       }
 340     }
 341   }
 342 
 343   return false;
 344 }
 345 
 346 //-----------------------------try_to_inline-----------------------------------
 347 // return true if ok
 348 // Relocated from "InliningClosure::try_to_inline"
 349 bool InlineTree::try_to_inline(ciMethod* callee_method, ciMethod* caller_method,
 350                                int caller_bci, JVMState* jvms, ciCallProfile&amp; profile,
 351                                WarmCallInfo* wci_result, bool&amp; should_delay) {
 352 
 353   if (ClipInlining &amp;&amp; (int)count_inline_bcs() &gt;= DesiredMethodLimit) {
 354     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 355       set_msg("size &gt; DesiredMethodLimit");
 356       return false;
 357     } else if (!C-&gt;inlining_incrementally()) {
 358       should_delay = true;
 359     }
 360   }
 361 
 362   _forced_inline = false; // Reset
 363   if (!should_inline(callee_method, caller_method, caller_bci, profile,
 364                      wci_result)) {
 365     return false;
 366   }
 367   if (should_not_inline(callee_method, caller_method, jvms, wci_result)) {
 368     return false;
 369   }
 370 
 371   if (InlineAccessors &amp;&amp; callee_method-&gt;is_accessor()) {
 372     // accessor methods are not subject to any of the following limits.
 373     set_msg("accessor");
 374     return true;
 375   }
 376 
 377   // suppress a few checks for accessors and trivial methods
 378   if (callee_method-&gt;code_size() &gt; MaxTrivialSize) {
 379 
 380     // don't inline into giant methods
 381     if (C-&gt;over_inlining_cutoff()) {
 382       if ((!callee_method-&gt;force_inline() &amp;&amp; !caller_method-&gt;is_compiled_lambda_form())
 383           || !IncrementalInline) {
 384         set_msg("NodeCountInliningCutoff");
 385         return false;
 386       } else {
 387         should_delay = true;
 388       }
 389     }
 390 
 391     if ((!UseInterpreter || CompileTheWorld) &amp;&amp;
 392         is_init_with_ea(callee_method, caller_method, C)) {
 393       // Escape Analysis stress testing when running Xcomp or CTW:
 394       // inline constructors even if they are not reached.
 395     } else if (forced_inline()) {
 396       // Inlining was forced by CompilerOracle, ciReplay or annotation
 397     } else if (profile.count() == 0) {
 398       // don't inline unreached call sites
 399        set_msg("call site not reached");
 400        return false;
 401     }
 402   }
 403 
 404   if (!C-&gt;do_inlining() &amp;&amp; InlineAccessors) {
 405     set_msg("not an accessor");
 406     return false;
 407   }
 408 
 409   // Limit inlining depth in case inlining is forced or
 410   // _max_inline_level was increased to compensate for lambda forms.
 411   if (inline_level() &gt; MaxForceInlineLevel) {
 412     set_msg("MaxForceInlineLevel");
 413     return false;
 414   }
 415   if (inline_level() &gt; _max_inline_level) {
 416     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 417       set_msg("inlining too deep");
 418       return false;
 419     } else if (!C-&gt;inlining_incrementally()) {
 420       should_delay = true;
 421     }
 422   }
 423 
 424   // detect direct and indirect recursive inlining
 425   {
 426     // count the current method and the callee
 427     const bool is_compiled_lambda_form = callee_method-&gt;is_compiled_lambda_form();
 428     int inline_level = 0;
 429     if (!is_compiled_lambda_form) {
 430       if (method() == callee_method) {
 431         inline_level++;
 432       }
 433     }
 434     // count callers of current method and callee
 435     Node* callee_argument0 = is_compiled_lambda_form ? jvms-&gt;map()-&gt;argument(jvms, 0)-&gt;uncast() : NULL;
 436     for (JVMState* j = jvms-&gt;caller(); j != NULL &amp;&amp; j-&gt;has_method(); j = j-&gt;caller()) {
 437       if (j-&gt;method() == callee_method) {
 438         if (is_compiled_lambda_form) {
 439           // Since compiled lambda forms are heavily reused we allow recursive inlining.  If it is truly
 440           // a recursion (using the same "receiver") we limit inlining otherwise we can easily blow the
 441           // compiler stack.
 442           Node* caller_argument0 = j-&gt;map()-&gt;argument(j, 0)-&gt;uncast();
 443           if (caller_argument0 == callee_argument0) {
 444             inline_level++;
 445           }
 446         } else {
 447           inline_level++;
 448         }
 449       }
 450     }
 451     if (inline_level &gt; MaxRecursiveInlineLevel) {
 452       set_msg("recursive inlining is too deep");
 453       return false;
 454     }
 455   }
 456 
 457   int size = callee_method-&gt;code_size_for_inlining();
 458 
 459   if (ClipInlining &amp;&amp; (int)count_inline_bcs() + size &gt;= DesiredMethodLimit) {
 460     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 461       set_msg("size &gt; DesiredMethodLimit");
 462       return false;
 463     } else if (!C-&gt;inlining_incrementally()) {
 464       should_delay = true;
 465     }
 466   }
 467 
 468   // ok, inline this method
 469   return true;
 470 }
 471 
 472 //------------------------------pass_initial_checks----------------------------
 473 bool pass_initial_checks(ciMethod* caller_method, int caller_bci, ciMethod* callee_method) {
 474   ciInstanceKlass *callee_holder = callee_method ? callee_method-&gt;holder() : NULL;
 475   // Check if a callee_method was suggested
 476   if( callee_method == NULL )            return false;
 477   // Check if klass of callee_method is loaded
 478   if( !callee_holder-&gt;is_loaded() )      return false;
 479   if( !callee_holder-&gt;is_initialized() ) return false;
 480   if( !UseInterpreter || CompileTheWorld /* running Xcomp or CTW */ ) {
 481     // Checks that constant pool's call site has been visited
 482     // stricter than callee_holder-&gt;is_initialized()
 483     ciBytecodeStream iter(caller_method);
 484     iter.force_bci(caller_bci);
 485     Bytecodes::Code call_bc = iter.cur_bc();
 486     // An invokedynamic instruction does not have a klass.
 487     if (call_bc != Bytecodes::_invokedynamic) {
 488       int index = iter.get_index_u2_cpcache();
 489       if (!caller_method-&gt;is_klass_loaded(index, true)) {
 490         return false;
 491       }
 492       // Try to do constant pool resolution if running Xcomp
 493       if( !caller_method-&gt;check_call(index, call_bc == Bytecodes::_invokestatic) ) {
 494         return false;
 495       }
 496     }
 497   }
 498   return true;
 499 }
 500 
 501 //------------------------------check_can_parse--------------------------------
 502 const char* InlineTree::check_can_parse(ciMethod* callee) {
 503   // Certain methods cannot be parsed at all:
 504   if ( callee-&gt;is_native())                     return "native method";
 505   if ( callee-&gt;is_abstract())                   return "abstract method";
 506   if (!callee-&gt;can_be_compiled())               return "not compilable (disabled)";
 507   if (!callee-&gt;has_balanced_monitors())         return "not compilable (unbalanced monitors)";
 508   if ( callee-&gt;get_flow_analysis()-&gt;failing())  return "not compilable (flow analysis failed)";
 509   return NULL;
 510 }
 511 
 512 //------------------------------print_inlining---------------------------------
 513 void InlineTree::print_inlining(ciMethod* callee_method, int caller_bci,
 514                                 ciMethod* caller_method, bool success) const {
 515   const char* inline_msg = msg();
 516   assert(inline_msg != NULL, "just checking");
 517   if (C-&gt;log() != NULL) {
 518     if (success) {
 519       C-&gt;log()-&gt;inline_success(inline_msg);
 520     } else {
 521       C-&gt;log()-&gt;inline_fail(inline_msg);
 522     }
 523   }
 524   if (C-&gt;print_inlining()) {
 525     C-&gt;print_inlining(callee_method, inline_level(), caller_bci, inline_msg);
 526     if (callee_method == NULL) tty-&gt;print(" callee not monotonic or profiled");
 527     if (Verbose &amp;&amp; callee_method) {
 528       const InlineTree *top = this;
 529       while( top-&gt;caller_tree() != NULL ) { top = top-&gt;caller_tree(); }
 530       //tty-&gt;print("  bcs: %d+%d  invoked: %d", top-&gt;count_inline_bcs(), callee_method-&gt;code_size(), callee_method-&gt;interpreter_invocation_count());
 531     }
 532   }
 533 #if INCLUDE_TRACE
 534   EventCompilerInlining event;
 535   if (event.should_commit()) {
 536     event.set_compileID(C-&gt;compile_id());
 537     event.set_message(inline_msg);
 538     event.set_succeeded(success);
 539     event.set_bci(caller_bci);
 540     event.set_caller(caller_method-&gt;get_Method());
 541     event.set_callee(callee_method-&gt;to_trace_struct());
 542     event.commit();
 543   }
 544 #endif // INCLUDE_TRACE
 545 }
 546 
 547 //------------------------------ok_to_inline-----------------------------------
 548 WarmCallInfo* InlineTree::ok_to_inline(ciMethod* callee_method, JVMState* jvms, ciCallProfile&amp; profile, WarmCallInfo* initial_wci, bool&amp; should_delay) {
 549   assert(callee_method != NULL, "caller checks for optimized virtual!");
 550   assert(!should_delay, "should be initialized to false");
 551 #ifdef ASSERT
 552   // Make sure the incoming jvms has the same information content as me.
 553   // This means that we can eventually make this whole class AllStatic.
 554   if (jvms-&gt;caller() == NULL) {
 555     assert(_caller_jvms == NULL, "redundant instance state");
 556   } else {
 557     assert(_caller_jvms-&gt;same_calls_as(jvms-&gt;caller()), "redundant instance state");
 558   }
 559   assert(_method == jvms-&gt;method(), "redundant instance state");
 560 #endif
 561   int         caller_bci    = jvms-&gt;bci();
 562   ciMethod*   caller_method = jvms-&gt;method();
 563 
 564   // Do some initial checks.
 565   if (!pass_initial_checks(caller_method, caller_bci, callee_method)) {
 566     set_msg("failed initial checks");
 567     print_inlining(callee_method, caller_bci, caller_method, false /* !success */);
 568     return NULL;
 569   }
 570 
 571   // Do some parse checks.
 572   set_msg(check_can_parse(callee_method));
 573   if (msg() != NULL) {
 574     print_inlining(callee_method, caller_bci, caller_method, false /* !success */);
 575     return NULL;
 576   }
 577 
 578   // Check if inlining policy says no.
 579   WarmCallInfo wci = *(initial_wci);
 580   bool success = try_to_inline(callee_method, caller_method, caller_bci,
 581                                jvms, profile, &amp;wci, should_delay);
 582 
 583 #ifndef PRODUCT
 584   if (InlineWarmCalls &amp;&amp; (PrintOpto || C-&gt;print_inlining())) {
 585     bool cold = wci.is_cold();
 586     bool hot  = !cold &amp;&amp; wci.is_hot();
 587     bool old_cold = !success;
 588     if (old_cold != cold || (Verbose || WizardMode)) {
 589       if (msg() == NULL) {
 590         set_msg("OK");
 591       }
 592       tty-&gt;print("   OldInlining= %4s : %s\n           WCI=",
 593                  old_cold ? "cold" : "hot", msg());
 594       wci.print();
 595     }
 596   }
 597 #endif
 598   if (success) {
 599     wci = *(WarmCallInfo::always_hot());
 600   } else {
 601     wci = *(WarmCallInfo::always_cold());
 602   }
 603 
 604   if (!InlineWarmCalls) {
 605     if (!wci.is_cold() &amp;&amp; !wci.is_hot()) {
 606       // Do not inline the warm calls.
 607       wci = *(WarmCallInfo::always_cold());
 608     }
 609   }
 610 
 611   if (!wci.is_cold()) {
 612     // Inline!
 613     if (msg() == NULL) {
 614       set_msg("inline (hot)");
 615     }
 616     print_inlining(callee_method, caller_bci, caller_method, true /* success */);
 617     build_inline_tree_for_callee(callee_method, jvms, caller_bci);
 618     if (InlineWarmCalls &amp;&amp; !wci.is_hot()) {
 619       return new (C) WarmCallInfo(wci);  // copy to heap
 620     }
 621     return WarmCallInfo::always_hot();
 622   }
 623 
 624   // Do not inline
 625   if (msg() == NULL) {
 626     set_msg("too cold to inline");
 627   }
 628   print_inlining(callee_method, caller_bci, caller_method, false /* !success */ );
 629   return NULL;
 630 }
 631 
 632 //------------------------------compute_callee_frequency-----------------------
 633 float InlineTree::compute_callee_frequency( int caller_bci ) const {
 634   int count  = method()-&gt;interpreter_call_site_count(caller_bci);
 635   int invcnt = method()-&gt;interpreter_invocation_count();
 636   float freq = (float)count/(float)invcnt;
 637   // Call-site count / interpreter invocation count, scaled recursively.
 638   // Always between 0.0 and 1.0.  Represents the percentage of the method's
 639   // total execution time used at this call site.
 640 
 641   return freq;
 642 }
 643 
 644 //------------------------------build_inline_tree_for_callee-------------------
 645 InlineTree *InlineTree::build_inline_tree_for_callee( ciMethod* callee_method, JVMState* caller_jvms, int caller_bci) {
 646   float recur_frequency = _site_invoke_ratio * compute_callee_frequency(caller_bci);
 647   // Attempt inlining.
 648   InlineTree* old_ilt = callee_at(caller_bci, callee_method);
 649   if (old_ilt != NULL) {
 650     return old_ilt;
 651   }
 652   int max_inline_level_adjust = 0;
 653   if (caller_jvms-&gt;method() != NULL) {
 654     if (caller_jvms-&gt;method()-&gt;is_compiled_lambda_form()) {
 655       max_inline_level_adjust += 1;  // don't count actions in MH or indy adapter frames
 656     } else if (callee_method-&gt;is_method_handle_intrinsic() ||
 657                callee_method-&gt;is_compiled_lambda_form()) {
 658       max_inline_level_adjust += 1;  // don't count method handle calls from java.lang.invoke implementation
 659     }
 660     if (max_inline_level_adjust != 0 &amp;&amp; C-&gt;print_inlining() &amp;&amp; (Verbose || WizardMode)) {
 661       CompileTask::print_inline_indent(inline_level());
 662       tty-&gt;print_cr(" \\-&gt; discounting inline depth");
 663     }
 664     if (max_inline_level_adjust != 0 &amp;&amp; C-&gt;log()) {
 665       int id1 = C-&gt;log()-&gt;identify(caller_jvms-&gt;method());
 666       int id2 = C-&gt;log()-&gt;identify(callee_method);
 667       C-&gt;log()-&gt;elem("inline_level_discount caller='%d' callee='%d'", id1, id2);
 668     }
 669   }
 670   InlineTree* ilt = new InlineTree(C, this, callee_method, caller_jvms, caller_bci, recur_frequency, _max_inline_level + max_inline_level_adjust);
 671   _subtrees.append(ilt);
 672 
 673   NOT_PRODUCT( _count_inlines += 1; )
 674 
 675   return ilt;
 676 }
 677 
 678 
 679 //---------------------------------------callee_at-----------------------------
 680 InlineTree *InlineTree::callee_at(int bci, ciMethod* callee) const {
 681   for (int i = 0; i &lt; _subtrees.length(); i++) {
 682     InlineTree* sub = _subtrees.at(i);
 683     if (sub-&gt;caller_bci() == bci &amp;&amp; callee == sub-&gt;method()) {
 684       return sub;
 685     }
 686   }
 687   return NULL;
 688 }
 689 
 690 
 691 //------------------------------build_inline_tree_root-------------------------
 692 InlineTree *InlineTree::build_inline_tree_root() {
 693   Compile* C = Compile::current();
 694 
 695   // Root of inline tree
 696   InlineTree* ilt = new InlineTree(C, NULL, C-&gt;method(), NULL, -1, 1.0F, MaxInlineLevel);
 697 
 698   return ilt;
 699 }
 700 
 701 
 702 //-------------------------find_subtree_from_root-----------------------------
 703 // Given a jvms, which determines a call chain from the root method,
 704 // find the corresponding inline tree.
 705 // Note: This method will be removed or replaced as InlineTree goes away.
 706 InlineTree* InlineTree::find_subtree_from_root(InlineTree* root, JVMState* jvms, ciMethod* callee) {
 707   InlineTree* iltp = root;
 708   uint depth = jvms &amp;&amp; jvms-&gt;has_method() ? jvms-&gt;depth() : 0;
 709   for (uint d = 1; d &lt;= depth; d++) {
 710     JVMState* jvmsp  = jvms-&gt;of_depth(d);
 711     // Select the corresponding subtree for this bci.
 712     assert(jvmsp-&gt;method() == iltp-&gt;method(), "tree still in sync");
 713     ciMethod* d_callee = (d == depth) ? callee : jvms-&gt;of_depth(d+1)-&gt;method();
 714     InlineTree* sub = iltp-&gt;callee_at(jvmsp-&gt;bci(), d_callee);
 715     if (sub == NULL) {
 716       if (d == depth) {
 717         sub = iltp-&gt;build_inline_tree_for_callee(d_callee, jvmsp, jvmsp-&gt;bci());
 718       }
 719       guarantee(sub != NULL, "should be a sub-ilt here");
 720       return sub;
 721     }
 722     iltp = sub;
 723   }
 724   return iltp;
 725 }
 726 
 727 // Count number of nodes in this subtree
 728 int InlineTree::count() const {
 729   int result = 1;
 730   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 731     result += _subtrees.at(i)-&gt;count();
 732   }
 733   return result;
 734 }
 735 
 736 void InlineTree::dump_replay_data(outputStream* out) {
 737   out-&gt;print(" %d %d ", inline_level(), caller_bci());
 738   method()-&gt;dump_name_as_ascii(out);
 739   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 740     _subtrees.at(i)-&gt;dump_replay_data(out);
 741   }
 742 }
 743 
 744 
 745 #ifndef PRODUCT
 746 void InlineTree::print_impl(outputStream* st, int indent) const {
 747   for (int i = 0; i &lt; indent; i++) st-&gt;print(" ");
 748   st-&gt;print(" @ %d", caller_bci());
 749   method()-&gt;print_short_name(st);
 750   st-&gt;cr();
 751 
 752   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 753     _subtrees.at(i)-&gt;print_impl(st, indent + 2);
 754   }
 755 }
 756 
 757 void InlineTree::print_value_on(outputStream* st) const {
 758   print_impl(st, 2);
 759 }
 760 #endif
</pre></body></html>
