<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>Old src/share/vm/opto/bytecodeInfo.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 1998, 2013, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 #include "ci/ciReplay.hpp"
  27 #include "classfile/systemDictionary.hpp"
  28 #include "classfile/vmSymbols.hpp"
  29 #include "compiler/compileBroker.hpp"
  30 #include "compiler/compileLog.hpp"
  31 #include "interpreter/linkResolver.hpp"
  32 #include "oops/objArrayKlass.hpp"
  33 #include "opto/callGenerator.hpp"
  34 #include "opto/parse.hpp"
  35 #include "runtime/handles.inline.hpp"
  36 #include "utilities/events.hpp"
  37 
  38 //=============================================================================
  39 //------------------------------InlineTree-------------------------------------
  40 InlineTree::InlineTree(Compile* c,
  41                        const InlineTree *caller_tree, ciMethod* callee,
  42                        JVMState* caller_jvms, int caller_bci,
  43                        float site_invoke_ratio, int max_inline_level) :
  44   C(c),
  45   _caller_jvms(caller_jvms),
  46   _caller_tree((InlineTree*) caller_tree),
  47   _method(callee),
  48   _site_invoke_ratio(site_invoke_ratio),
  49   _max_inline_level(max_inline_level),
  50   _count_inline_bcs(method()-&gt;code_size_for_inlining()),
  51   _subtrees(c-&gt;comp_arena(), 2, 0, NULL),
  52   _msg(NULL)
  53 {
  54 #ifndef PRODUCT
  55   _count_inlines = 0;
  56   _forced_inline = false;
  57 #endif
  58   if (_caller_jvms != NULL) {
  59     // Keep a private copy of the caller_jvms:
  60     _caller_jvms = new (C) JVMState(caller_jvms-&gt;method(), caller_tree-&gt;caller_jvms());
  61     _caller_jvms-&gt;set_bci(caller_jvms-&gt;bci());
  62     assert(!caller_jvms-&gt;should_reexecute(), "there should be no reexecute bytecode with inlining");
  63   }
  64   assert(_caller_jvms-&gt;same_calls_as(caller_jvms), "consistent JVMS");
  65   assert((caller_tree == NULL ? 0 : caller_tree-&gt;stack_depth() + 1) == stack_depth(), "correct (redundant) depth parameter");
  66   assert(caller_bci == this-&gt;caller_bci(), "correct (redundant) bci parameter");
  67   // Update hierarchical counts, count_inline_bcs() and count_inlines()
  68   InlineTree *caller = (InlineTree *)caller_tree;
  69   for( ; caller != NULL; caller = ((InlineTree *)(caller-&gt;caller_tree())) ) {
  70     caller-&gt;_count_inline_bcs += count_inline_bcs();
  71     NOT_PRODUCT(caller-&gt;_count_inlines++;)
  72   }
  73 }
  74 
  75 /**
  76  *  Return true when EA is ON and a java constructor is called or
  77  *  a super constructor is called from an inlined java constructor.
  78  *  Also return true for boxing methods.
  79  */
  80 static bool is_init_with_ea(ciMethod* callee_method,
  81                             ciMethod* caller_method, Compile* C) {
  82   if (!C-&gt;do_escape_analysis() || !EliminateAllocations) {
  83     return false; // EA is off
  84   }
  85   if (callee_method-&gt;is_initializer()) {
  86     return true; // constuctor
  87   }
  88   if (caller_method-&gt;is_initializer() &amp;&amp;
  89       caller_method != C-&gt;method() &amp;&amp;
  90       caller_method-&gt;holder()-&gt;is_subclass_of(callee_method-&gt;holder())) {
  91     return true; // super constructor is called from inlined constructor
  92   }
  93   if (C-&gt;eliminate_boxing() &amp;&amp; callee_method-&gt;is_boxing_method()) {
  94     return true;
  95   }
  96   return false;
  97 }
  98 
  99 /**
 100  *  Force inlining unboxing accessor.
 101  */
 102 static bool is_unboxing_method(ciMethod* callee_method, Compile* C) {
 103   return C-&gt;eliminate_boxing() &amp;&amp; callee_method-&gt;is_unboxing_method();
 104 }
 105 
 106 // positive filter: should callee be inlined?
 107 bool InlineTree::should_inline(ciMethod* callee_method, ciMethod* caller_method,
 108                                int caller_bci, ciCallProfile&amp; profile,
 109                                WarmCallInfo* wci_result) {
 110   // Allows targeted inlining
 111   if (C-&gt;directive()-&gt;should_inline(callee_method)) {
 112     *wci_result = *(WarmCallInfo::always_hot());
 113     if (C-&gt;print_inlining() &amp;&amp; Verbose) {
 114       CompileTask::print_inline_indent(inline_level());
 115       tty-&gt;print_cr("Inlined method is hot: ");
 116     }
 117     set_msg("force inline by CompileCommand");
 118     _forced_inline = true;
 119     return true;
 120   }
 121 
 122   if (callee_method-&gt;force_inline()) {
 123       set_msg("force inline by annotation");
 124       _forced_inline = true;
 125       return true;
 126   }
 127 
 128 #ifndef PRODUCT
 129   int inline_depth = inline_level()+1;
 130   if (ciReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 131     set_msg("force inline by ciReplay");
 132     _forced_inline = true;
 133     return true;
 134   }
 135 #endif
 136 
 137   int size = callee_method-&gt;code_size_for_inlining();
 138 
 139   // Check for too many throws (and not too huge)
 140   if(callee_method-&gt;interpreter_throwout_count() &gt; InlineThrowCount &amp;&amp;
 141      size &lt; InlineThrowMaxSize ) {
 142     wci_result-&gt;set_profit(wci_result-&gt;profit() * 100);
 143     if (C-&gt;print_inlining() &amp;&amp; Verbose) {
 144       CompileTask::print_inline_indent(inline_level());
 145       tty-&gt;print_cr("Inlined method with many throws (throws=%d):", callee_method-&gt;interpreter_throwout_count());
 146     }
 147     set_msg("many throws");
 148     return true;
 149   }
 150 
 151   int default_max_inline_size = C-&gt;max_inline_size();
 152   int inline_small_code_size  = InlineSmallCode / 4;
 153   int max_inline_size         = default_max_inline_size;
 154 
 155   int call_site_count  = method()-&gt;scale_count(profile.count());
 156   int invoke_count     = method()-&gt;interpreter_invocation_count();
 157 
 158   assert(invoke_count != 0, "require invocation count greater than zero");
 159   int freq = call_site_count / invoke_count;
 160 
 161   // bump the max size if the call is frequent
 162   if ((freq &gt;= InlineFrequencyRatio) ||
 163       (call_site_count &gt;= InlineFrequencyCount) ||
 164       is_unboxing_method(callee_method, C) ||
 165       is_init_with_ea(callee_method, caller_method, C)) {
 166 
 167     max_inline_size = C-&gt;freq_inline_size();
 168     if (size &lt;= max_inline_size &amp;&amp; TraceFrequencyInlining) {
 169       CompileTask::print_inline_indent(inline_level());
 170       tty-&gt;print_cr("Inlined frequent method (freq=%d count=%d):", freq, call_site_count);
 171       CompileTask::print_inline_indent(inline_level());
 172       callee_method-&gt;print();
 173       tty-&gt;cr();
 174     }
 175   } else {
 176     // Not hot.  Check for medium-sized pre-existing nmethod at cold sites.
 177     if (callee_method-&gt;has_compiled_code() &amp;&amp;
 178         callee_method-&gt;instructions_size() &gt; inline_small_code_size) {
 179       set_msg("already compiled into a medium method");
 180       return false;
 181     }
 182   }
 183   if (size &gt; max_inline_size) {
 184     if (max_inline_size &gt; default_max_inline_size) {
 185       set_msg("hot method too big");
 186     } else {
 187       set_msg("too big");
 188     }
 189     return false;
 190   }
 191   return true;
 192 }
 193 
 194 
 195 // negative filter: should callee NOT be inlined?
 196 bool InlineTree::should_not_inline(ciMethod *callee_method,
 197                                    ciMethod* caller_method,
 198                                    JVMState* jvms,
 199                                    WarmCallInfo* wci_result) {
 200 
 201   const char* fail_msg = NULL;
 202 
 203   // First check all inlining restrictions which are required for correctness
 204   if ( callee_method-&gt;is_abstract()) {
 205     fail_msg = "abstract method"; // // note: we allow ik-&gt;is_abstract()
 206   } else if (!callee_method-&gt;holder()-&gt;is_initialized()) {
 207     fail_msg = "method holder not initialized";
 208   } else if ( callee_method-&gt;is_native()) {
 209     fail_msg = "native method";
 210   } else if ( callee_method-&gt;dont_inline()) {
 211     fail_msg = "don't inline by annotation";
 212   }
 213 
 214   // one more inlining restriction
 215   if (fail_msg == NULL &amp;&amp; callee_method-&gt;has_unloaded_classes_in_signature()) {
 216     fail_msg = "unloaded signature classes";
 217   }
 218 
 219   if (fail_msg != NULL) {
 220     set_msg(fail_msg);
 221     return true;
 222   }
 223 
 224   // ignore heuristic controls on inlining
 225   if (C-&gt;directive()-&gt;should_inline(callee_method)) {
 226     set_msg("force inline by CompileCommand");
 227     return false;
 228   }
 229 
 230   if (C-&gt;directive()-&gt;should_not_inline(callee_method)) {
 231     set_msg("disallowed by CompileCommand");
 232     return true;
 233   }
 234 
 235 #ifndef PRODUCT
 236   int caller_bci = jvms-&gt;bci();
 237   int inline_depth = inline_level()+1;
 238   if (ciReplay::should_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 239     set_msg("force inline by ciReplay");
 240     return false;
 241   }
 242 
 243   if (ciReplay::should_not_inline(C-&gt;replay_inline_data(), callee_method, caller_bci, inline_depth)) {
 244     set_msg("disallowed by ciReplay");
 245     return true;
 246   }
 247 
 248   if (ciReplay::should_not_inline(callee_method)) {
 249     set_msg("disallowed by ciReplay");
 250     return true;
 251   }
 252 #endif
 253 
 254   if (callee_method-&gt;force_inline()) {
 255     set_msg("force inline by annotation");
 256     return false;
 257   }
 258 
 259   // Now perform checks which are heuristic
 260 
 261   if (is_unboxing_method(callee_method, C)) {
 262     // Inline unboxing methods.
 263     return false;
 264   }
 265 
 266   if (callee_method-&gt;has_compiled_code() &amp;&amp;
 267       callee_method-&gt;instructions_size() &gt; InlineSmallCode) {
 268     set_msg("already compiled into a big method");
 269     return true;
 270   }
 271 
 272   // don't inline exception code unless the top method belongs to an
 273   // exception class
 274   if (caller_tree() != NULL &amp;&amp;
 275       callee_method-&gt;holder()-&gt;is_subclass_of(C-&gt;env()-&gt;Throwable_klass())) {
 276     const InlineTree *top = this;
 277     while (top-&gt;caller_tree() != NULL) top = top-&gt;caller_tree();
 278     ciInstanceKlass* k = top-&gt;method()-&gt;holder();
 279     if (!k-&gt;is_subclass_of(C-&gt;env()-&gt;Throwable_klass())) {
 280       set_msg("exception method");
 281       return true;
 282     }
 283   }
 284 
 285   // use frequency-based objections only for non-trivial methods
 286   if (callee_method-&gt;code_size() &lt;= MaxTrivialSize) {
 287     return false;
 288   }
 289 
 290   // don't use counts with -Xcomp or CTW
 291   if (UseInterpreter &amp;&amp; !CompileTheWorld) {
 292 
 293     if (!callee_method-&gt;has_compiled_code() &amp;&amp;
 294         !callee_method-&gt;was_executed_more_than(0)) {
 295       set_msg("never executed");
 296       return true;
 297     }
 298 
 299     if (is_init_with_ea(callee_method, caller_method, C)) {
 300       // Escape Analysis: inline all executed constructors
 301       return false;
 302     } else {
 303       intx counter_high_value;
 304       // Tiered compilation uses a different "high value" than non-tiered compilation.
 305       // Determine the right value to use.
 306       if (TieredCompilation) {
 307         counter_high_value = InvocationCounter::count_limit / 2;
 308       } else {
 309         counter_high_value = CompileThreshold / 2;
 310       }
 311       if (!callee_method-&gt;was_executed_more_than(MIN2(MinInliningThreshold, counter_high_value))) {
 312         set_msg("executed &lt; MinInliningThreshold times");
 313         return true;
 314       }
 315     }
 316   }
 317 
 318   return false;
 319 }
 320 
 321 //-----------------------------try_to_inline-----------------------------------
 322 // return true if ok
 323 // Relocated from "InliningClosure::try_to_inline"
 324 bool InlineTree::try_to_inline(ciMethod* callee_method, ciMethod* caller_method,
 325                                int caller_bci, JVMState* jvms, ciCallProfile&amp; profile,
 326                                WarmCallInfo* wci_result, bool&amp; should_delay) {
 327 
 328   if (ClipInlining &amp;&amp; (int)count_inline_bcs() &gt;= DesiredMethodLimit) {
 329     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 330       set_msg("size &gt; DesiredMethodLimit");
 331       return false;
 332     } else if (!C-&gt;inlining_incrementally()) {
 333       should_delay = true;
 334     }
 335   }
 336 
 337   _forced_inline = false; // Reset
 338   if (!should_inline(callee_method, caller_method, caller_bci, profile,
 339                      wci_result)) {
 340     return false;
 341   }
 342   if (should_not_inline(callee_method, caller_method, jvms, wci_result)) {
 343     return false;
 344   }
 345 
 346   if (InlineAccessors &amp;&amp; callee_method-&gt;is_accessor()) {
 347     // accessor methods are not subject to any of the following limits.
 348     set_msg("accessor");
 349     return true;
 350   }
 351 
 352   // suppress a few checks for accessors and trivial methods
 353   if (callee_method-&gt;code_size() &gt; MaxTrivialSize) {
 354 
 355     // don't inline into giant methods
 356     if (C-&gt;over_inlining_cutoff()) {
 357       if ((!callee_method-&gt;force_inline() &amp;&amp; !caller_method-&gt;is_compiled_lambda_form())
 358           || !IncrementalInline) {
 359         set_msg("NodeCountInliningCutoff");
 360         return false;
 361       } else {
 362         should_delay = true;
 363       }
 364     }
 365 
 366     if ((!UseInterpreter || CompileTheWorld) &amp;&amp;
 367         is_init_with_ea(callee_method, caller_method, C)) {
 368       // Escape Analysis stress testing when running Xcomp or CTW:
 369       // inline constructors even if they are not reached.
 370     } else if (forced_inline()) {
 371       // Inlining was forced by CompilerOracle, ciReplay or annotation
 372     } else if (profile.count() == 0) {
 373       // don't inline unreached call sites
 374        set_msg("call site not reached");
 375        return false;
 376     }
 377   }
 378 
 379   if (!C-&gt;do_inlining() &amp;&amp; InlineAccessors) {
 380     set_msg("not an accessor");
 381     return false;
 382   }
 383 
 384   // Limit inlining depth in case inlining is forced or
 385   // _max_inline_level was increased to compensate for lambda forms.
 386   if (inline_level() &gt; MaxForceInlineLevel) {
 387     set_msg("MaxForceInlineLevel");
 388     return false;
 389   }
 390   if (inline_level() &gt; _max_inline_level) {
 391     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 392       set_msg("inlining too deep");
 393       return false;
 394     } else if (!C-&gt;inlining_incrementally()) {
 395       should_delay = true;
 396     }
 397   }
 398 
 399   // detect direct and indirect recursive inlining
 400   {
 401     // count the current method and the callee
 402     const bool is_compiled_lambda_form = callee_method-&gt;is_compiled_lambda_form();
 403     int inline_level = 0;
 404     if (!is_compiled_lambda_form) {
 405       if (method() == callee_method) {
 406         inline_level++;
 407       }
 408     }
 409     // count callers of current method and callee
 410     Node* callee_argument0 = is_compiled_lambda_form ? jvms-&gt;map()-&gt;argument(jvms, 0)-&gt;uncast() : NULL;
 411     for (JVMState* j = jvms-&gt;caller(); j != NULL &amp;&amp; j-&gt;has_method(); j = j-&gt;caller()) {
 412       if (j-&gt;method() == callee_method) {
 413         if (is_compiled_lambda_form) {
 414           // Since compiled lambda forms are heavily reused we allow recursive inlining.  If it is truly
 415           // a recursion (using the same "receiver") we limit inlining otherwise we can easily blow the
 416           // compiler stack.
 417           Node* caller_argument0 = j-&gt;map()-&gt;argument(j, 0)-&gt;uncast();
 418           if (caller_argument0 == callee_argument0) {
 419             inline_level++;
 420           }
 421         } else {
 422           inline_level++;
 423         }
 424       }
 425     }
 426     if (inline_level &gt; MaxRecursiveInlineLevel) {
 427       set_msg("recursive inlining is too deep");
 428       return false;
 429     }
 430   }
 431 
 432   int size = callee_method-&gt;code_size_for_inlining();
 433 
 434   if (ClipInlining &amp;&amp; (int)count_inline_bcs() + size &gt;= DesiredMethodLimit) {
 435     if (!callee_method-&gt;force_inline() || !IncrementalInline) {
 436       set_msg("size &gt; DesiredMethodLimit");
 437       return false;
 438     } else if (!C-&gt;inlining_incrementally()) {
 439       should_delay = true;
 440     }
 441   }
 442 
 443   // ok, inline this method
 444   return true;
 445 }
 446 
 447 //------------------------------pass_initial_checks----------------------------
 448 bool pass_initial_checks(ciMethod* caller_method, int caller_bci, ciMethod* callee_method) {
 449   ciInstanceKlass *callee_holder = callee_method ? callee_method-&gt;holder() : NULL;
 450   // Check if a callee_method was suggested
 451   if( callee_method == NULL )            return false;
 452   // Check if klass of callee_method is loaded
 453   if( !callee_holder-&gt;is_loaded() )      return false;
 454   if( !callee_holder-&gt;is_initialized() ) return false;
 455   if( !UseInterpreter || CompileTheWorld /* running Xcomp or CTW */ ) {
 456     // Checks that constant pool's call site has been visited
 457     // stricter than callee_holder-&gt;is_initialized()
 458     ciBytecodeStream iter(caller_method);
 459     iter.force_bci(caller_bci);
 460     Bytecodes::Code call_bc = iter.cur_bc();
 461     // An invokedynamic instruction does not have a klass.
 462     if (call_bc != Bytecodes::_invokedynamic) {
 463       int index = iter.get_index_u2_cpcache();
 464       if (!caller_method-&gt;is_klass_loaded(index, true)) {
 465         return false;
 466       }
 467       // Try to do constant pool resolution if running Xcomp
 468       if( !caller_method-&gt;check_call(index, call_bc == Bytecodes::_invokestatic) ) {
 469         return false;
 470       }
 471     }
 472   }
 473   return true;
 474 }
 475 
 476 //------------------------------check_can_parse--------------------------------
 477 const char* InlineTree::check_can_parse(ciMethod* callee) {
 478   // Certain methods cannot be parsed at all:
 479   if ( callee-&gt;is_native())                     return "native method";
 480   if ( callee-&gt;is_abstract())                   return "abstract method";
 481   if (!callee-&gt;can_be_compiled())               return "not compilable (disabled)";
 482   if (!callee-&gt;has_balanced_monitors())         return "not compilable (unbalanced monitors)";
 483   if ( callee-&gt;get_flow_analysis()-&gt;failing())  return "not compilable (flow analysis failed)";
 484   return NULL;
 485 }
 486 
 487 //------------------------------print_inlining---------------------------------
 488 void InlineTree::print_inlining(ciMethod* callee_method, int caller_bci,
 489                                 ciMethod* caller_method, bool success) const {
 490   const char* inline_msg = msg();
 491   assert(inline_msg != NULL, "just checking");
 492   if (C-&gt;log() != NULL) {
 493     if (success) {
 494       C-&gt;log()-&gt;inline_success(inline_msg);
 495     } else {
 496       C-&gt;log()-&gt;inline_fail(inline_msg);
 497     }
 498   }
 499   if (C-&gt;print_inlining()) {
 500     C-&gt;print_inlining(callee_method, inline_level(), caller_bci, inline_msg);
 501     if (callee_method == NULL) tty-&gt;print(" callee not monotonic or profiled");
 502     if (Verbose &amp;&amp; callee_method) {
 503       const InlineTree *top = this;
 504       while( top-&gt;caller_tree() != NULL ) { top = top-&gt;caller_tree(); }
 505       //tty-&gt;print("  bcs: %d+%d  invoked: %d", top-&gt;count_inline_bcs(), callee_method-&gt;code_size(), callee_method-&gt;interpreter_invocation_count());
 506     }
 507   }
 508 #if INCLUDE_TRACE
 509   EventCompilerInlining event;
 510   if (event.should_commit()) {
 511     event.set_compileID(C-&gt;compile_id());
 512     event.set_message(inline_msg);
 513     event.set_succeeded(success);
 514     event.set_bci(caller_bci);
 515     event.set_caller(caller_method-&gt;get_Method());
 516     event.set_callee(callee_method-&gt;to_trace_struct());
 517     event.commit();
 518   }
 519 #endif // INCLUDE_TRACE
 520 }
 521 
 522 //------------------------------ok_to_inline-----------------------------------
 523 WarmCallInfo* InlineTree::ok_to_inline(ciMethod* callee_method, JVMState* jvms, ciCallProfile&amp; profile, WarmCallInfo* initial_wci, bool&amp; should_delay) {
 524   assert(callee_method != NULL, "caller checks for optimized virtual!");
 525   assert(!should_delay, "should be initialized to false");
 526 #ifdef ASSERT
 527   // Make sure the incoming jvms has the same information content as me.
 528   // This means that we can eventually make this whole class AllStatic.
 529   if (jvms-&gt;caller() == NULL) {
 530     assert(_caller_jvms == NULL, "redundant instance state");
 531   } else {
 532     assert(_caller_jvms-&gt;same_calls_as(jvms-&gt;caller()), "redundant instance state");
 533   }
 534   assert(_method == jvms-&gt;method(), "redundant instance state");
 535 #endif
 536   int         caller_bci    = jvms-&gt;bci();
 537   ciMethod*   caller_method = jvms-&gt;method();
 538 
 539   // Do some initial checks.
 540   if (!pass_initial_checks(caller_method, caller_bci, callee_method)) {
 541     set_msg("failed initial checks");
 542     print_inlining(callee_method, caller_bci, caller_method, false /* !success */);
 543     return NULL;
 544   }
 545 
 546   // Do some parse checks.
 547   set_msg(check_can_parse(callee_method));
 548   if (msg() != NULL) {
 549     print_inlining(callee_method, caller_bci, caller_method, false /* !success */);
 550     return NULL;
 551   }
 552 
 553   // Check if inlining policy says no.
 554   WarmCallInfo wci = *(initial_wci);
 555   bool success = try_to_inline(callee_method, caller_method, caller_bci,
 556                                jvms, profile, &amp;wci, should_delay);
 557 
 558 #ifndef PRODUCT
 559   if (InlineWarmCalls &amp;&amp; (PrintOpto || C-&gt;print_inlining())) {
 560     bool cold = wci.is_cold();
 561     bool hot  = !cold &amp;&amp; wci.is_hot();
 562     bool old_cold = !success;
 563     if (old_cold != cold || (Verbose || WizardMode)) {
 564       if (msg() == NULL) {
 565         set_msg("OK");
 566       }
 567       tty-&gt;print("   OldInlining= %4s : %s\n           WCI=",
 568                  old_cold ? "cold" : "hot", msg());
 569       wci.print();
 570     }
 571   }
 572 #endif
 573   if (success) {
 574     wci = *(WarmCallInfo::always_hot());
 575   } else {
 576     wci = *(WarmCallInfo::always_cold());
 577   }
 578 
 579   if (!InlineWarmCalls) {
 580     if (!wci.is_cold() &amp;&amp; !wci.is_hot()) {
 581       // Do not inline the warm calls.
 582       wci = *(WarmCallInfo::always_cold());
 583     }
 584   }
 585 
 586   if (!wci.is_cold()) {
 587     // Inline!
 588     if (msg() == NULL) {
 589       set_msg("inline (hot)");
 590     }
 591     print_inlining(callee_method, caller_bci, caller_method, true /* success */);
 592     build_inline_tree_for_callee(callee_method, jvms, caller_bci);
 593     if (InlineWarmCalls &amp;&amp; !wci.is_hot()) {
 594       return new (C) WarmCallInfo(wci);  // copy to heap
 595     }
 596     return WarmCallInfo::always_hot();
 597   }
 598 
 599   // Do not inline
 600   if (msg() == NULL) {
 601     set_msg("too cold to inline");
 602   }
 603   print_inlining(callee_method, caller_bci, caller_method, false /* !success */ );
 604   return NULL;
 605 }
 606 
 607 //------------------------------compute_callee_frequency-----------------------
 608 float InlineTree::compute_callee_frequency( int caller_bci ) const {
 609   int count  = method()-&gt;interpreter_call_site_count(caller_bci);
 610   int invcnt = method()-&gt;interpreter_invocation_count();
 611   float freq = (float)count/(float)invcnt;
 612   // Call-site count / interpreter invocation count, scaled recursively.
 613   // Always between 0.0 and 1.0.  Represents the percentage of the method's
 614   // total execution time used at this call site.
 615 
 616   return freq;
 617 }
 618 
 619 //------------------------------build_inline_tree_for_callee-------------------
 620 InlineTree *InlineTree::build_inline_tree_for_callee( ciMethod* callee_method, JVMState* caller_jvms, int caller_bci) {
 621   float recur_frequency = _site_invoke_ratio * compute_callee_frequency(caller_bci);
 622   // Attempt inlining.
 623   InlineTree* old_ilt = callee_at(caller_bci, callee_method);
 624   if (old_ilt != NULL) {
 625     return old_ilt;
 626   }
 627   int max_inline_level_adjust = 0;
 628   if (caller_jvms-&gt;method() != NULL) {
 629     if (caller_jvms-&gt;method()-&gt;is_compiled_lambda_form()) {
 630       max_inline_level_adjust += 1;  // don't count actions in MH or indy adapter frames
 631     } else if (callee_method-&gt;is_method_handle_intrinsic() ||
 632                callee_method-&gt;is_compiled_lambda_form()) {
 633       max_inline_level_adjust += 1;  // don't count method handle calls from java.lang.invoke implementation
 634     }
 635     if (max_inline_level_adjust != 0 &amp;&amp; C-&gt;print_inlining() &amp;&amp; (Verbose || WizardMode)) {
 636       CompileTask::print_inline_indent(inline_level());
 637       tty-&gt;print_cr(" \\-&gt; discounting inline depth");
 638     }
 639     if (max_inline_level_adjust != 0 &amp;&amp; C-&gt;log()) {
 640       int id1 = C-&gt;log()-&gt;identify(caller_jvms-&gt;method());
 641       int id2 = C-&gt;log()-&gt;identify(callee_method);
 642       C-&gt;log()-&gt;elem("inline_level_discount caller='%d' callee='%d'", id1, id2);
 643     }
 644   }
 645   InlineTree* ilt = new InlineTree(C, this, callee_method, caller_jvms, caller_bci, recur_frequency, _max_inline_level + max_inline_level_adjust);
 646   _subtrees.append(ilt);
 647 
 648   NOT_PRODUCT( _count_inlines += 1; )
 649 
 650   return ilt;
 651 }
 652 
 653 
 654 //---------------------------------------callee_at-----------------------------
 655 InlineTree *InlineTree::callee_at(int bci, ciMethod* callee) const {
 656   for (int i = 0; i &lt; _subtrees.length(); i++) {
 657     InlineTree* sub = _subtrees.at(i);
 658     if (sub-&gt;caller_bci() == bci &amp;&amp; callee == sub-&gt;method()) {
 659       return sub;
 660     }
 661   }
 662   return NULL;
 663 }
 664 
 665 
 666 //------------------------------build_inline_tree_root-------------------------
 667 InlineTree *InlineTree::build_inline_tree_root() {
 668   Compile* C = Compile::current();
 669 
 670   // Root of inline tree
 671   InlineTree* ilt = new InlineTree(C, NULL, C-&gt;method(), NULL, -1, 1.0F, MaxInlineLevel);
 672 
 673   return ilt;
 674 }
 675 
 676 
 677 //-------------------------find_subtree_from_root-----------------------------
 678 // Given a jvms, which determines a call chain from the root method,
 679 // find the corresponding inline tree.
 680 // Note: This method will be removed or replaced as InlineTree goes away.
 681 InlineTree* InlineTree::find_subtree_from_root(InlineTree* root, JVMState* jvms, ciMethod* callee) {
 682   InlineTree* iltp = root;
 683   uint depth = jvms &amp;&amp; jvms-&gt;has_method() ? jvms-&gt;depth() : 0;
 684   for (uint d = 1; d &lt;= depth; d++) {
 685     JVMState* jvmsp  = jvms-&gt;of_depth(d);
 686     // Select the corresponding subtree for this bci.
 687     assert(jvmsp-&gt;method() == iltp-&gt;method(), "tree still in sync");
 688     ciMethod* d_callee = (d == depth) ? callee : jvms-&gt;of_depth(d+1)-&gt;method();
 689     InlineTree* sub = iltp-&gt;callee_at(jvmsp-&gt;bci(), d_callee);
 690     if (sub == NULL) {
 691       if (d == depth) {
 692         sub = iltp-&gt;build_inline_tree_for_callee(d_callee, jvmsp, jvmsp-&gt;bci());
 693       }
 694       guarantee(sub != NULL, "should be a sub-ilt here");
 695       return sub;
 696     }
 697     iltp = sub;
 698   }
 699   return iltp;
 700 }
 701 
 702 // Count number of nodes in this subtree
 703 int InlineTree::count() const {
 704   int result = 1;
 705   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 706     result += _subtrees.at(i)-&gt;count();
 707   }
 708   return result;
 709 }
 710 
 711 void InlineTree::dump_replay_data(outputStream* out) {
 712   out-&gt;print(" %d %d ", inline_level(), caller_bci());
 713   method()-&gt;dump_name_as_ascii(out);
 714   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 715     _subtrees.at(i)-&gt;dump_replay_data(out);
 716   }
 717 }
 718 
 719 
 720 #ifndef PRODUCT
 721 void InlineTree::print_impl(outputStream* st, int indent) const {
 722   for (int i = 0; i &lt; indent; i++) st-&gt;print(" ");
 723   st-&gt;print(" @ %d", caller_bci());
 724   method()-&gt;print_short_name(st);
 725   st-&gt;cr();
 726 
 727   for (int i = 0 ; i &lt; _subtrees.length(); i++) {
 728     _subtrees.at(i)-&gt;print_impl(st, indent + 2);
 729   }
 730 }
 731 
 732 void InlineTree::print_value_on(outputStream* st) const {
 733   print_impl(st, 2);
 734 }
 735 #endif
</pre></body></html>
